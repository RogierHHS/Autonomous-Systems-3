{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4e982cc9",
   "metadata": {},
   "source": [
    "<div style=\"background-color:LightBlue; text-align:center; padding:20px;\">\n",
    "    <h2 style=\"color:black; font-family: Verdana, sans-serif;\"><strong>Multi-Agent Reinforcement Learning Project - Atari</strong></h2>\n",
    "    <p style=\"font-size: 14px; color: black; font-family: Verdana, sans-serif;\"> \n",
    "        <table style=\"margin: auto; border-collapse: collapse; color: black;\">\n",
    "            <tr>\n",
    "                <th style=\"border: 0;\">Names</th>\n",
    "                <th style=\"border: 0;\">GitHub Username</th>\n",
    "            </tr>\n",
    "            <tr>\n",
    "                <td style=\"border: 0;\">Rogier Gernaat</td>\n",
    "                <td style=\"border: 0;\">RogierHHS</td>\n",
    "            </tr>\n",
    "            <tr>\n",
    "                <td style=\"border: 0;\">Daan Eising</td>\n",
    "                <td style=\"border: 0;\">DaanEising</td>\n",
    "            </tr>\n",
    "            <tr>\n",
    "                <td style=\"border: 0;\">Julia Boschman</td>\n",
    "                <td style=\"border: 0;\">JuliaBoschman</td>\n",
    "            </tr>\n",
    "            <tr>\n",
    "                <td style=\"border: 0;\">Jort dihhhoek</td>\n",
    "                <td style=\"border: 0;\">Homoboi-kankerboi</td>\n",
    "            </tr>\n",
    "        </table>\n",
    "    </p></div>\n",
    "\n",
    "<div style=\"display: flex; justify-content: center; align-items: center; margin-top: 10px;\">\n",
    "    <img src=\"\" alt=\"fotoj van onze opdracht\" style=\"width: 1000px; height: auto;\">\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0851f3ab",
   "metadata": {},
   "source": [
    "- ***Docent***: Vikram Radhakrishnan\n",
    "- ***Datum***: 08-04-2025"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57553bbf",
   "metadata": {},
   "source": [
    "\n",
    "---\n",
    "<div style=\"background-color:LightBlue; text-align:center; vertical-align:middle; padding:50px 0; margin-top:5px; margin-bottom:5px\">\n",
    "    <h2 id=\"eda-title\" style=\"color:black; font-family: Verdana, sans-serif; font-size: 25px;\"><strong> Inhoudsopgave (Prototype morgen kunnen we hem nog ff aanpassen of anders indelen) </strong></h2>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7dc902d",
   "metadata": {},
   "source": [
    "## **Inhoudsopgave**\n",
    "\n",
    "1. [H1: Inleiding](#1.0)\n",
    "   - [&sect;1.1: Imports en Setup](#1.1)  \n",
    "  \n",
    "2. [H2: Kiezen van Algoritme](#2.0)  \n",
    "   - [&sect;2.1: Kiezen van RL-Algoritme](#2.1)    \n",
    "   - [&sect;2.3: Kiezen van Trainingsstrategie](#2.3)  \n",
    "\n",
    "3. [H3: Probleemdefinitie](#3.0)  \n",
    "   - [&sect;3.1: Wat is het probleem?](#3.1)   \n",
    "\n",
    "4. [H4: Ontwerp en Implementatie](#4.0)  \n",
    "   - [&sect;4.1: Baseline strategie ontwikkelen](#4.1)  \n",
    "   - [&sect;4.2: Selectie van DRL algoritme en frameworks](#4.2)   \n",
    "   - [&sect;4.3: Implementatie MARL-agent](#4.3)  \n",
    "\n",
    "5. [H5: Training en Hyperparameter Search](#5.0)  \n",
    "   - [&sect;5.1: Training](#5.1)  \n",
    "   - [&sect;5.2: Selectie en tuning van hyperparameters](#5.2)  \n",
    "\n",
    "6. [H6: Evaluatie en Vergelijking](#6.0)  \n",
    "   - [&sect;6.1: Evaluatie t.o.v. baseline](#6.1)  \n",
    "   - [&sect;6.2: Analyse met metrics](#6.2)  \n",
    "   - [&sect;6.3: Visualisatie van resultaten](#6.3)  \n",
    "\n",
    "7. [H7: Rapportage en Reflectie](#7.0)  \n",
    "   - [&sect;7.1: Methodologie en aanpak](#7.1)  \n",
    "   - [&sect;7.2: Samenvatting van resultaten](#7.2)  \n",
    "   - [&sect;7.3: Reflectie op model, prestaties en uitbreidingsmogelijkheden](#7.3)  \n",
    "\n",
    "8. [H8: Literatuurlijst](#8.0)  \n",
    "\n",
    "9. [H9: Beoordelingscriteria](#9.0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b59f4614",
   "metadata": {},
   "source": [
    "\n",
    "---\n",
    "<div style=\"background-color:LightBlue; text-align:center; vertical-align:middle; padding:50px 0; margin-top:5px; margin-bottom:5px\">\n",
    "    <h2 id=\"eda-title\" style=\"color:black; font-family: Verdana, sans-serif; font-size: 25px;\"><strong>H1: Inleiding </strong></h2>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4151918",
   "metadata": {},
   "source": [
    "## inleiding bladiebladiebla"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7cc6769",
   "metadata": {},
   "source": [
    "<a name='1.1'></a>\n",
    "<h3>&sect;1.1: Imports en Setup</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12e99777",
   "metadata": {},
   "source": [
    "<div style=\"background-color:white; color:black; padding: 10px;\">\n",
    "    <strong>Importeren van de library's</strong>\n",
    "</div>\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "593b2447",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "438c13d8",
   "metadata": {},
   "source": [
    "\n",
    "---\n",
    "<div style=\"background-color:LightBlue; text-align:center; vertical-align:middle; padding:50px 0; margin-top:5px; margin-bottom:5px\">\n",
    "    <h2 id=\"eda-title\" style=\"color:black; font-family: Verdana, sans-serif; font-size: 25px;\"><strong>H2: Kiezen van Algoritme </strong></h2>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "732b4263",
   "metadata": {},
   "source": [
    "<a name='1.1'></a>\n",
    "<h3>&sect;2.1: Kiezen van RL-Algoritme</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c1c9536",
   "metadata": {},
   "source": [
    "a.\tJouw agent zal deelnemen en interacten met andere agenten in de Atari-omgeving \"Warlords\"."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9d941ae",
   "metadata": {},
   "source": [
    "<a name='1.1'></a>\n",
    "<h3>&sect;2.3: Kiezen van Trainingsstrategie</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b7196ea",
   "metadata": {},
   "source": [
    "b.\tKies een geschikt RL-algoritme en trainingsstrategie voor je agent. Beschrijf en motiveer je keuzes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6107d561",
   "metadata": {},
   "source": [
    "\n",
    "---\n",
    "<div style=\"background-color:LightBlue; text-align:center; vertical-align:middle; padding:50px 0; margin-top:5px; margin-bottom:5px\">\n",
    "    <h2 id=\"eda-title\" style=\"color:black; font-family: Verdana, sans-serif; font-size: 25px;\"><strong>H3: Probleemdefinitie </strong></h2>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bcbb909",
   "metadata": {},
   "source": [
    "<a name='1.1'></a>\n",
    "<h3>&sect;3.1: Wat is het probleem?</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31d9d8c7",
   "metadata": {},
   "source": [
    "c.\tResultaat: Een helder uitgewerkte motivatie in je rapport (“Inleiding & Probleemanalyse”)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ae0d36e",
   "metadata": {},
   "source": [
    "#### Probleemanalyse\n",
    "De opkomst van multi-agent omgevingen in toepassingen zoals robotica, games en logistiek vraagt om slimme algoritmes die kunnen concurreren én samenwerken. In de praktijk betekent dit dat agents hun strategieën continu moeten bijstellen op basis van het gedrag van andere agents in hun omgeving. In de Atari-game Warlords komen vier agents tegelijkertijd in actie, waarbij hun succes afhankelijk is van zowel hun eigen keuzes als die van hun tegenstanders.\n",
    "\n",
    "Single-agent reinforcement learning is onvoldoende, omdat hierbij wordt aangenomen dat de omgeving stationair is (niet verandert door anderen). In multi-agent settings verandert de omgeving echter continu, omdat andere agents ook leren en hun gedrag aanpassen. Dit vraagt om een benadering waarbij agents niet alleen leren van hun eigen ervaringen, maar ook van de interacties met anderen.\n",
    "\n",
    "Met multi-agent reinforcement learning (MARL) kunnen agents hun beleid optimaliseren terwijl ze rekening houden met de strategieën van anderen. Hierdoor ontstaan vaak complexe en onverwachte gedragingen die in single-agent settings niet mogelijk zijn. Bovendien kunnen MARL-methoden worden ingezet om situaties te modelleren waarin competitie, samenwerking of beide tegelijk nodig zijn.\n",
    "\n",
    "##### Relevantie van het probleem\n",
    "- In veel echte omgevingen zijn meerdere autonome beslissers actief (bijvoorbeeld zelfrijdende auto's in verkeer).\n",
    "- Het ontwerpen van robuuste agents in zulke settings helpt bij het ontwikkelen van realistische, schaalbare en adaptieve AI-systemen.\n",
    "- In de context van games als Warlords kan MARL inzichten bieden in hoe intelligente strategieën en tegenstrategieën ontstaan in competitieve settings.\n",
    "\n",
    "##### Samenvatting probleemstelling (één zin):\n",
    "\"Hoe kunnen we effectieve, lerende agents ontwikkelen die optimaal presteren in een competitieve multi-agent omgeving, waarbij rekening wordt gehouden met de voortdurende interactie en dynamiek tussen verschillende agents?\"\n",
    "\n",
    "Scharwächter (2024)\n",
    "\n",
    "#### Doelstelling\n",
    "Het doel van deze opdracht is om een multi-agent reinforcement learning systeem te ontwerpen, implementeren en evalueren voor de Atari Warlords-omgeving. Dit gebeurt door vier verschillende MARL-algoritmes (PPO, MADDPG, [keuze Peet] en [keuze Jort]) te trainen en hun prestaties te vergelijken met een baseline. Het eindresultaat is een reproduceerbaar systeem en een rapport met een diepgaande analyse van de werking en effectiviteit van de gekozen algoritmen."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18f470aa",
   "metadata": {},
   "source": [
    "\n",
    "---\n",
    "<div style=\"background-color:LightBlue; text-align:center; vertical-align:middle; padding:50px 0; margin-top:5px; margin-bottom:5px\">\n",
    "    <h2 id=\"eda-title\" style=\"color:black; font-family: Verdana, sans-serif; font-size: 25px;\"><strong>H4: Ontwerp en Implementatie</strong></h2>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "086bad36",
   "metadata": {},
   "source": [
    "<a name='1.1'></a>\n",
    "<h3>&sect;4.1: Baseline strategie ontwikkelen</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cffc336",
   "metadata": {},
   "source": [
    "a.\tOntwikkel een baseline zoals bijvoorbeeld een rule-based policy een random policy of een andere simpele heuristiek.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b41eef89",
   "metadata": {},
   "source": [
    "<a name='1.1'></a>\n",
    "<h3>&sect;4.2: Selectie van DRL algoritme en frameworks</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e23682d",
   "metadata": {},
   "source": [
    "b.\tKies een passend DRL-algoritme, die geschikt is voor een multi-agent setting. Kies geschikte packages en frameworks. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e51ff2f0",
   "metadata": {},
   "source": [
    "<a name='1.1'></a>\n",
    "<h3>&sect;4.3: Implementatie MARL-agent</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "327a104c",
   "metadata": {},
   "source": [
    "d.\tResultaat: Een werkend MARL-systeem dat klaar is voor training en evaluatie."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "210914e9",
   "metadata": {},
   "source": [
    "\n",
    "---\n",
    "<div style=\"background-color:LightBlue; text-align:center; vertical-align:middle; padding:50px 0; margin-top:5px; margin-bottom:5px\">\n",
    "    <h2 id=\"eda-title\" style=\"color:black; font-family: Verdana, sans-serif; font-size: 25px;\"><strong>H5: Training en Hyperparameter Search</strong></h2>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c0e45d6",
   "metadata": {},
   "source": [
    "<a name='1.1'></a>\n",
    "<h3>&sect;5.1: Training</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "459b8c33",
   "metadata": {},
   "source": [
    "<a name='1.1'></a>\n",
    "<h3>&sect;5.2: Selectie en tuning van hyperparameters</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27eb948f",
   "metadata": {},
   "source": [
    "a.\tExperimenteer met hyperparameters (zoals bijvoorbeeld learning rates of exploration-exploitation afwegingen). Documenteer dit ook."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3eff6630",
   "metadata": {},
   "source": [
    "\n",
    "---\n",
    "<div style=\"background-color:LightBlue; text-align:center; vertical-align:middle; padding:50px 0; margin-top:5px; margin-bottom:5px\">\n",
    "    <h2 id=\"eda-title\" style=\"color:black; font-family: Verdana, sans-serif; font-size: 25px;\"><strong>H6: Evaluatie en Vergelijking</strong></h2>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b824fae3",
   "metadata": {},
   "source": [
    "<a name='1.1'></a>\n",
    "<h3>&sect;6.1: Evaluatie t.o.v. baseline</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc781412",
   "metadata": {},
   "source": [
    "b.\tEvalueer de prestaties van je model en vergelijk deze – indien mogelijk – met een baseline. Welke voordelen biedt RL in dit specifieke scenario?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5faffea",
   "metadata": {},
   "source": [
    "<a name='1.1'></a>\n",
    "<h3>&sect;6.2: Analyse met metrics</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e09b4659",
   "metadata": {},
   "source": [
    "c.\tVisualiseer de resultaten met grafieken en andere tools. Denk bijvoorbeeld aan reward-curves en stabiliteit van training."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "248de22d",
   "metadata": {},
   "source": [
    "<a name='1.1'></a>\n",
    "<h3>&sect;6.3: Visualisatie van resultaten</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f653d2a0",
   "metadata": {},
   "source": [
    "c.\tVisualiseer de resultaten met grafieken en andere tools. Denk bijvoorbeeld aan reward-curves en stabiliteit van training."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "935cd0bd",
   "metadata": {},
   "source": [
    "\n",
    "---\n",
    "<div style=\"background-color:LightBlue; text-align:center; vertical-align:middle; padding:50px 0; margin-top:5px; margin-bottom:5px\">\n",
    "    <h2 id=\"eda-title\" style=\"color:black; font-family: Verdana, sans-serif; font-size: 25px;\"><strong>H7: Rapportage en Reflectie</strong></h2>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "067d398a",
   "metadata": {},
   "source": [
    "<a name='1.1'></a>\n",
    "<h3>&sect;7.1: Methodologie en aanpak</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c40607f0",
   "metadata": {},
   "source": [
    "<a name='1.1'></a>\n",
    "<h3>&sect;7.2: Samenvatting van resultaten</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bc393ce",
   "metadata": {},
   "source": [
    "<a name='1.1'></a>\n",
    "<h3>&sect;7.3: Reflectie op model, prestaties en uitbreidingsmogelijkheden</h3>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a36e0de",
   "metadata": {},
   "source": [
    "a.\tSchrijf een rapport waarin je je probleemstelling, aanpak, resultaten en conclusies presenteert. Reflecteer op mogelijke uitbreidingen."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43cf89fe",
   "metadata": {},
   "source": [
    "\n",
    "---\n",
    "<div style=\"background-color:LightBlue; text-align:center; vertical-align:middle; padding:50px 0; margin-top:5px; margin-bottom:5px\">\n",
    "    <h2 id=\"eda-title\" style=\"color:black; font-family: Verdana, sans-serif; font-size: 25px;\"><strong>H8: Literatuurlijst</strong></h2>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "600d5377",
   "metadata": {},
   "source": [
    "- Scharwächter, V. (2024, 15 juli). *Probleemanalyse maken voor je scriptie | Betekenis & Voorbeeld.* Scribbr. https://www.scribbr.nl/starten-met-je-scriptie/probleemanalyse/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c2bc62c",
   "metadata": {},
   "source": [
    "\n",
    "---\n",
    "<div style=\"background-color:LightBlue; text-align:center; vertical-align:middle; padding:50px 0; margin-top:5px; margin-bottom:5px\">\n",
    "    <h2 id=\"eda-title\" style=\"color:black; font-family: Verdana, sans-serif; font-size: 25px;\"><strong>H9: Beoordelingscriteria</strong></h2>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e61bf377",
   "metadata": {},
   "source": [
    "ER ZIJN NOG GEEN RUBRIEKEN DUS DIT IS DE BEOORDELING TOT NU TOE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31b69975",
   "metadata": {},
   "source": [
    "Je werk wordt beoordeeld op de volgende aspecten:\n",
    "1.\t**Keuze van algoritme en trainingsstrategie**: Is het gekozen algoritme geschikt voor de omgeving? Is de trainingsmethode van de agent relevant voor deze setting? Wordt er rekening gehouden met de aanwezigheid van meerdere agenten?\n",
    "2.\t**Technische diepgang**: Worden neural network-componenten (indien van toepassing) correct toegepast? Is er aandacht voor alle cruciale onderdelen van de DRL-pijplijn (zoals experience replay en policy updates)?\n",
    "3.\t**Implementatie en testen**: Is het multi-agent Reinforcement Learning-algoritme correct geïmplementeerd, met goed gestructureerde en werkende code? Is het getest in een multi-agentomgeving?\n",
    "4.\t**Rapportage**: Zijn de methodologie en keuzes goed onderbouwd met wetenschappelijke literatuur? Is het rapport helder en gestructureerd?\n",
    "5.\t**Reproduceerbaarheid**: Is de code duidelijk, goed gedocumenteerd en eenvoudig te reproduceren?\n",
    "6.\t**Bonuspunten**: Aan het einde van het project neemt je agent het in een toernooi op tegen je klasgenoten. (De details hierover volgen later.) Het winnende team van het toernooi krijgt 5 bonuspunten bovenop het aantal behaalde punten met de opdracht.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d06c3ecc",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
