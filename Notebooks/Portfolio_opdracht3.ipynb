{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "4e982cc9",
      "metadata": {
        "id": "4e982cc9"
      },
      "source": [
        "<div style=\"background-color:LightBlue; text-align:center; padding:20px;\">\n",
        "    <h2 style=\"color:black; font-family: Verdana, sans-serif;\"><strong>Multi-Agent Reinforcement Learning Project - Atari</strong></h2>\n",
        "    <p style=\"font-size: 14px; color: black; font-family: Verdana, sans-serif;\">\n",
        "        <table style=\"margin: auto; border-collapse: collapse; color: black;\">\n",
        "            <tr>\n",
        "                <th style=\"border: 0;\">Names</th>\n",
        "                <th style=\"border: 0;\">GitHub Username</th>\n",
        "            </tr>\n",
        "            <tr>\n",
        "                <td style=\"border: 0;\">Rogier Gernaat</td>\n",
        "                <td style=\"border: 0;\">RogierHHS</td>\n",
        "            </tr>\n",
        "            <tr>\n",
        "                <td style=\"border: 0;\">Daan Eising</td>\n",
        "                <td style=\"border: 0;\">DaanEising</td>\n",
        "            </tr>\n",
        "            <tr>\n",
        "                <td style=\"border: 0;\">Julia Boschman</td>\n",
        "                <td style=\"border: 0;\">JuliaBoschman</td>\n",
        "            </tr>\n",
        "            <tr>\n",
        "                <td style=\"border: 0;\">Jort Akershoek</td>\n",
        "                <td style=\"border: 0;\">JortAkershoek</td>\n",
        "            </tr>\n",
        "        </table>\n",
        "    </p></div>\n",
        "\n",
        "<div style=\"display: flex; justify-content: center; align-items: center; margin-top: 10px;\">\n",
        "    <img src=\"\" alt=\"warlords_ss.png\" style=\"width: 1000px; height: auto;\">\n",
        "</div>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0851f3ab",
      "metadata": {
        "id": "0851f3ab"
      },
      "source": [
        "- ***Docent***: Vikram Radhakrishnan\n",
        "- ***Datum***: 08-04-2025"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "57553bbf",
      "metadata": {
        "id": "57553bbf"
      },
      "source": [
        "\n",
        "---\n",
        "<div style=\"background-color:LightBlue; text-align:center; vertical-align:middle; padding:50px 0; margin-top:5px; margin-bottom:5px\">\n",
        "    <h2 id=\"eda-title\" style=\"color:black; font-family: Verdana, sans-serif; font-size: 25px;\"><strong> Inhoudsopgave </strong></h2>\n",
        "</div>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d7dc902d",
      "metadata": {
        "id": "d7dc902d"
      },
      "source": [
        "## **Inhoudsopgave**\n",
        "\n",
        "1. [H1: Inleiding](#1.0)\n",
        "   - [&sect;1.1: Imports en Setup](#1.1)  \n",
        "  \n",
        "2. [H2: Kiezen van Algoritme](#2.0)  \n",
        "   - [&sect;2.1: Kiezen van RL-Algoritme](#2.1)    \n",
        "   - [&sect;2.3: Kiezen van Trainingsstrategie](#2.3)  \n",
        "\n",
        "3. [H3: Probleemdefinitie](#3.0)  \n",
        "   - [&sect;3.1: Wat is het probleem?](#3.1)   \n",
        "\n",
        "4. [H4: Ontwerp en Implementatie](#4.0)  \n",
        "   - [&sect;4.1: Baseline strategie ontwikkelen](#4.1)  \n",
        "   - [&sect;4.2: Selectie van DRL algoritme en frameworks](#4.2)   \n",
        "   - [&sect;4.3: Implementatie MARL-agent](#4.3)  \n",
        "\n",
        "5. [H5: Training en Hyperparameter Search](#5.0)  \n",
        "   - [&sect;5.1: Training](#5.1)  \n",
        "   - [&sect;5.2: Selectie en tuning van hyperparameters](#5.2)  \n",
        "\n",
        "6. [H6: Evaluatie en Vergelijking](#6.0)  \n",
        "   - [&sect;6.1: Evaluatie t.o.v. baseline](#6.1)  \n",
        "   - [&sect;6.2: Analyse met metrics](#6.2)  \n",
        "   - [&sect;6.3: Visualisatie van resultaten](#6.3)  \n",
        "\n",
        "7. [H7: Rapportage en Reflectie](#7.0)  \n",
        "   - [&sect;7.1: Methodologie en aanpak](#7.1)  \n",
        "   - [&sect;7.2: Samenvatting van resultaten](#7.2)  \n",
        "   - [&sect;7.3: Reflectie op model, prestaties en uitbreidingsmogelijkheden](#7.3)  \n",
        "\n",
        "8. [H8: Literatuurlijst](#8.0)  \n",
        "\n",
        "9. [H9: Beoordelingscriteria](#9.0)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b59f4614",
      "metadata": {
        "id": "b59f4614"
      },
      "source": [
        "\n",
        "---\n",
        "<div style=\"background-color:LightBlue; text-align:center; vertical-align:middle; padding:50px 0; margin-top:5px; margin-bottom:5px\">\n",
        "    <h2 id=\"eda-title\" style=\"color:black; font-family: Verdana, sans-serif; font-size: 25px;\"><strong>H1: Inleiding </strong></h2>\n",
        "</div>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d4151918",
      "metadata": {
        "id": "d4151918"
      },
      "source": [
        "Deze opdracht richt zich op het toepassen van Multi-Agent Reinforcement Learning (MARL) in een complexe, competitieve omgeving. Het doel is om een agent te ontwikkelen die zelfstandig leert te concurreren en samen te werken met andere agenten binnen de Atari-game Warlords. Hiervoor wordt gebruikgemaakt van de PettingZoo-omgeving, waarin meerdere agenten gelijktijdig tegen elkaar spelen, en wordt het algoritme Proximal Policy Optimization (PPO) ingezet voor training.\n",
        "\n",
        "In het notebook wordt stap voor stap uitgelegd hoe:\n",
        "De Warlords-omgeving wordt opgezet en geïnitialiseerd.\n",
        "Agents worden aangemaakt en getraind met behulp van PPO en Stable-Baselines3.\n",
        "Er een baseline wordt ontwikkeld (een random agent) ter vergelijking met het getrainde model.\n",
        "Verschillende hyperparameters worden getest en geoptimaliseerd.\n",
        "De prestaties van de agenten worden geëvalueerd en gevisualiseerd.\n",
        "Resultaten en bevindingen helder worden geanalyseerd en besproken.\n",
        "\n",
        "Het notebook is bedoeld om het volledige proces inzichtelijk te maken: van het begrijpen van de opdracht, het opzetten van een multi-agent omgeving, tot aan het trainen, evalueren en vergelijken van verschillende strategieën."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b7cc6769",
      "metadata": {
        "id": "b7cc6769"
      },
      "source": [
        "<a name='1.1'></a>\n",
        "<h3>&sect;1.1: Imports en Setup</h3>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<div style=\"background-color:white; color:black; padding: 10px;\">\n",
        "    <strong>Pip install's</strong>\n",
        "</div>\n",
        "\n"
      ],
      "metadata": {
        "id": "L4NIctHLp1oS"
      },
      "id": "L4NIctHLp1oS"
    },
    {
      "cell_type": "code",
      "source": [
        "# Install the necessary libraries\n",
        "\n",
        "!pip install gym\n",
        "!pip install stable_baselines3\n",
        "!pip install gymnasium[atari]\n",
        "!pip install pettingzoo[atari]\n",
        "!pip install \"autorom[accept-rom-license]\"\n",
        "!pip install --find-links dist/ --no-cache-dir AutoROM[accept-rom-license]\n",
        "!pip install supersuit"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ULHKlbghpy0k",
        "outputId": "de225cad-6a3a-4a2c-8e04-dd09bc8395c6"
      },
      "id": "ULHKlbghpy0k",
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: gym in /usr/local/lib/python3.11/dist-packages (0.25.2)\n",
            "Requirement already satisfied: numpy>=1.18.0 in /usr/local/lib/python3.11/dist-packages (from gym) (2.0.2)\n",
            "Requirement already satisfied: cloudpickle>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from gym) (3.1.1)\n",
            "Requirement already satisfied: gym-notices>=0.0.4 in /usr/local/lib/python3.11/dist-packages (from gym) (0.0.8)\n",
            "Collecting stable_baselines3\n",
            "  Downloading stable_baselines3-2.6.0-py3-none-any.whl.metadata (4.8 kB)\n",
            "Requirement already satisfied: gymnasium<1.2.0,>=0.29.1 in /usr/local/lib/python3.11/dist-packages (from stable_baselines3) (1.1.1)\n",
            "Requirement already satisfied: numpy<3.0,>=1.20 in /usr/local/lib/python3.11/dist-packages (from stable_baselines3) (2.0.2)\n",
            "Requirement already satisfied: torch<3.0,>=2.3 in /usr/local/lib/python3.11/dist-packages (from stable_baselines3) (2.6.0+cu124)\n",
            "Requirement already satisfied: cloudpickle in /usr/local/lib/python3.11/dist-packages (from stable_baselines3) (3.1.1)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from stable_baselines3) (2.2.2)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (from stable_baselines3) (3.10.0)\n",
            "Requirement already satisfied: typing-extensions>=4.3.0 in /usr/local/lib/python3.11/dist-packages (from gymnasium<1.2.0,>=0.29.1->stable_baselines3) (4.14.0)\n",
            "Requirement already satisfied: farama-notifications>=0.0.1 in /usr/local/lib/python3.11/dist-packages (from gymnasium<1.2.0,>=0.29.1->stable_baselines3) (0.0.4)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch<3.0,>=2.3->stable_baselines3) (3.18.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch<3.0,>=2.3->stable_baselines3) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch<3.0,>=2.3->stable_baselines3) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch<3.0,>=2.3->stable_baselines3) (2025.3.2)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch<3.0,>=2.3->stable_baselines3)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch<3.0,>=2.3->stable_baselines3)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch<3.0,>=2.3->stable_baselines3)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch<3.0,>=2.3->stable_baselines3)\n",
            "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch<3.0,>=2.3->stable_baselines3)\n",
            "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch<3.0,>=2.3->stable_baselines3)\n",
            "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.5.147 (from torch<3.0,>=2.3->stable_baselines3)\n",
            "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch<3.0,>=2.3->stable_baselines3)\n",
            "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch<3.0,>=2.3->stable_baselines3)\n",
            "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch<3.0,>=2.3->stable_baselines3) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch<3.0,>=2.3->stable_baselines3) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch<3.0,>=2.3->stable_baselines3) (12.4.127)\n",
            "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch<3.0,>=2.3->stable_baselines3)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch<3.0,>=2.3->stable_baselines3) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch<3.0,>=2.3->stable_baselines3) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch<3.0,>=2.3->stable_baselines3) (1.3.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->stable_baselines3) (1.3.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib->stable_baselines3) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib->stable_baselines3) (4.58.4)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->stable_baselines3) (1.4.8)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib->stable_baselines3) (24.2)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.11/dist-packages (from matplotlib->stable_baselines3) (11.2.1)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->stable_baselines3) (3.2.3)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib->stable_baselines3) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->stable_baselines3) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->stable_baselines3) (2025.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.7->matplotlib->stable_baselines3) (1.17.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch<3.0,>=2.3->stable_baselines3) (3.0.2)\n",
            "Downloading stable_baselines3-2.6.0-py3-none-any.whl (184 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m184.5/184.5 kB\u001b[0m \u001b[31m14.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m130.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m91.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m68.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m18.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m7.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m44.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, stable_baselines3\n",
            "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
            "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n",
            "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
            "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
            "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
            "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
            "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
            "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
            "Successfully installed nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127 stable_baselines3-2.6.0\n",
            "Requirement already satisfied: gymnasium[atari] in /usr/local/lib/python3.11/dist-packages (1.1.1)\n",
            "Requirement already satisfied: numpy>=1.21.0 in /usr/local/lib/python3.11/dist-packages (from gymnasium[atari]) (2.0.2)\n",
            "Requirement already satisfied: cloudpickle>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from gymnasium[atari]) (3.1.1)\n",
            "Requirement already satisfied: typing-extensions>=4.3.0 in /usr/local/lib/python3.11/dist-packages (from gymnasium[atari]) (4.14.0)\n",
            "Requirement already satisfied: farama-notifications>=0.0.1 in /usr/local/lib/python3.11/dist-packages (from gymnasium[atari]) (0.0.4)\n",
            "Requirement already satisfied: ale_py>=0.9 in /usr/local/lib/python3.11/dist-packages (from gymnasium[atari]) (0.11.1)\n",
            "Collecting pettingzoo[atari]\n",
            "  Downloading pettingzoo-1.25.0-py3-none-any.whl.metadata (8.9 kB)\n",
            "Requirement already satisfied: numpy>=1.21.0 in /usr/local/lib/python3.11/dist-packages (from pettingzoo[atari]) (2.0.2)\n",
            "Requirement already satisfied: gymnasium>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from pettingzoo[atari]) (1.1.1)\n",
            "Collecting multi_agent_ale_py>=0.1.11 (from pettingzoo[atari])\n",
            "  Downloading multi-agent-ale-py-0.1.11.tar.gz (551 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m552.0/552.0 kB\u001b[0m \u001b[31m32.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: pygame>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from pettingzoo[atari]) (2.6.1)\n",
            "Requirement already satisfied: cloudpickle>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from gymnasium>=1.0.0->pettingzoo[atari]) (3.1.1)\n",
            "Requirement already satisfied: typing-extensions>=4.3.0 in /usr/local/lib/python3.11/dist-packages (from gymnasium>=1.0.0->pettingzoo[atari]) (4.14.0)\n",
            "Requirement already satisfied: farama-notifications>=0.0.1 in /usr/local/lib/python3.11/dist-packages (from gymnasium>=1.0.0->pettingzoo[atari]) (0.0.4)\n",
            "Downloading pettingzoo-1.25.0-py3-none-any.whl (852 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m852.5/852.5 kB\u001b[0m \u001b[31m48.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: multi_agent_ale_py\n",
            "y\n",
            "y\n",
            "y\n",
            "y\n",
            "  Building wheel for multi_agent_ale_py (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for multi_agent_ale_py: filename=multi_agent_ale_py-0.1.11-cp311-cp311-linux_x86_64.whl size=721821 sha256=a059c36ec9e019252ea9836311260e2ac534c8be25a77e8b0515f8a0e70f3c52\n",
            "  Stored in directory: /root/.cache/pip/wheels/1d/81/76/771ec8e34292c8a71dd6c4a52a1c0401f4d93cbfb54e02fce4\n",
            "Successfully built multi_agent_ale_py\n",
            "Installing collected packages: multi_agent_ale_py, pettingzoo\n",
            "Successfully installed multi_agent_ale_py-0.1.11 pettingzoo-1.25.0\n",
            "Collecting autorom[accept-rom-license]\n",
            "  Downloading AutoROM-0.6.1-py3-none-any.whl.metadata (2.4 kB)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.11/dist-packages (from autorom[accept-rom-license]) (8.2.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from autorom[accept-rom-license]) (2.32.3)\n",
            "Collecting AutoROM.accept-rom-license (from autorom[accept-rom-license])\n",
            "  Downloading AutoROM.accept-rom-license-0.6.1.tar.gz (434 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m434.7/434.7 kB\u001b[0m \u001b[31m19.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->autorom[accept-rom-license]) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->autorom[accept-rom-license]) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->autorom[accept-rom-license]) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->autorom[accept-rom-license]) (2025.6.15)\n",
            "Downloading AutoROM-0.6.1-py3-none-any.whl (9.4 kB)\n",
            "Building wheels for collected packages: AutoROM.accept-rom-license\n",
            "  Building wheel for AutoROM.accept-rom-license (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for AutoROM.accept-rom-license: filename=autorom_accept_rom_license-0.6.1-py3-none-any.whl size=446709 sha256=58957813965bf9fe8ea6fd43746a17c7651e35c7d0ee1ac3e68f07b1a4a024a9\n",
            "  Stored in directory: /root/.cache/pip/wheels/bc/fc/c6/8aa657c0d2089982f2dabd110efc68c61eb49831fdb7397351\n",
            "Successfully built AutoROM.accept-rom-license\n",
            "Installing collected packages: AutoROM.accept-rom-license, autorom\n",
            "Successfully installed AutoROM.accept-rom-license-0.6.1 autorom-0.6.1\n",
            "Looking in links: dist/\n",
            "Requirement already satisfied: AutoROM[accept-rom-license] in /usr/local/lib/python3.11/dist-packages (0.6.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.11/dist-packages (from AutoROM[accept-rom-license]) (8.2.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from AutoROM[accept-rom-license]) (2.32.3)\n",
            "Requirement already satisfied: AutoROM.accept-rom-license in /usr/local/lib/python3.11/dist-packages (from AutoROM[accept-rom-license]) (0.6.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->AutoROM[accept-rom-license]) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->AutoROM[accept-rom-license]) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->AutoROM[accept-rom-license]) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->AutoROM[accept-rom-license]) (2025.6.15)\n",
            "Collecting supersuit\n",
            "  Downloading supersuit-3.10.0-py3-none-any.whl.metadata (3.1 kB)\n",
            "Requirement already satisfied: numpy>=1.19.0 in /usr/local/lib/python3.11/dist-packages (from supersuit) (2.0.2)\n",
            "Requirement already satisfied: gymnasium>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from supersuit) (1.1.1)\n",
            "Collecting tinyscaler>=1.2.6 (from supersuit)\n",
            "  Downloading tinyscaler-1.2.8-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.2 kB)\n",
            "Requirement already satisfied: cloudpickle>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from gymnasium>=1.0.0->supersuit) (3.1.1)\n",
            "Requirement already satisfied: typing-extensions>=4.3.0 in /usr/local/lib/python3.11/dist-packages (from gymnasium>=1.0.0->supersuit) (4.14.0)\n",
            "Requirement already satisfied: farama-notifications>=0.0.1 in /usr/local/lib/python3.11/dist-packages (from gymnasium>=1.0.0->supersuit) (0.0.4)\n",
            "Downloading supersuit-3.10.0-py3-none-any.whl (50 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.2/50.2 kB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tinyscaler-1.2.8-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (563 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m563.3/563.3 kB\u001b[0m \u001b[31m36.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: tinyscaler, supersuit\n",
            "Successfully installed supersuit-3.10.0 tinyscaler-1.2.8\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "id": "12e99777",
      "metadata": {
        "id": "12e99777"
      },
      "source": [
        "<div style=\"background-color:white; color:black; padding: 10px;\">\n",
        "    <strong>Importeren van de library's</strong>\n",
        "</div>\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "593b2447",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "593b2447",
        "outputId": "10780045-261c-4629-806a-6c4bd9ee589f",
        "collapsed": true
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "AutoROM will download the Atari 2600 ROMs.\n",
            "They will be installed to:\n",
            "\t/usr/local/lib/python3.11/dist-packages/AutoROM/roms\n",
            "\t/usr/local/lib/python3.11/dist-packages/multi_agent_ale_py/roms\n",
            "\n",
            "Existing ROMs will be overwritten.\n",
            "\n",
            "I own a license to these Atari 2600 ROMs.\n",
            "I agree to not distribute these ROMs and wish to proceed: [Y/n]: y\n",
            "Installed /usr/local/lib/python3.11/dist-packages/AutoROM/roms/adventure.bin\n",
            "Installed /usr/local/lib/python3.11/dist-packages/multi_agent_ale_py/roms/adventure.bin\n",
            "Installed /usr/local/lib/python3.11/dist-packages/AutoROM/roms/air_raid.bin\n",
            "Installed /usr/local/lib/python3.11/dist-packages/multi_agent_ale_py/roms/air_raid.bin\n",
            "Installed /usr/local/lib/python3.11/dist-packages/AutoROM/roms/alien.bin\n",
            "Installed /usr/local/lib/python3.11/dist-packages/multi_agent_ale_py/roms/alien.bin\n",
            "Installed /usr/local/lib/python3.11/dist-packages/AutoROM/roms/amidar.bin\n",
            "Installed /usr/local/lib/python3.11/dist-packages/multi_agent_ale_py/roms/amidar.bin\n",
            "Installed /usr/local/lib/python3.11/dist-packages/AutoROM/roms/assault.bin\n",
            "Installed /usr/local/lib/python3.11/dist-packages/multi_agent_ale_py/roms/assault.bin\n",
            "Installed /usr/local/lib/python3.11/dist-packages/AutoROM/roms/asterix.bin\n",
            "Installed /usr/local/lib/python3.11/dist-packages/multi_agent_ale_py/roms/asterix.bin\n",
            "Installed /usr/local/lib/python3.11/dist-packages/AutoROM/roms/asteroids.bin\n",
            "Installed /usr/local/lib/python3.11/dist-packages/multi_agent_ale_py/roms/asteroids.bin\n",
            "Installed /usr/local/lib/python3.11/dist-packages/AutoROM/roms/atlantis.bin\n",
            "Installed /usr/local/lib/python3.11/dist-packages/multi_agent_ale_py/roms/atlantis.bin\n",
            "Installed /usr/local/lib/python3.11/dist-packages/AutoROM/roms/atlantis2.bin\n",
            "Installed /usr/local/lib/python3.11/dist-packages/multi_agent_ale_py/roms/atlantis2.bin\n",
            "Installed /usr/local/lib/python3.11/dist-packages/AutoROM/roms/backgammon.bin\n",
            "Installed /usr/local/lib/python3.11/dist-packages/multi_agent_ale_py/roms/backgammon.bin\n",
            "Installed /usr/local/lib/python3.11/dist-packages/AutoROM/roms/bank_heist.bin\n",
            "Installed /usr/local/lib/python3.11/dist-packages/multi_agent_ale_py/roms/bank_heist.bin\n",
            "Installed /usr/local/lib/python3.11/dist-packages/AutoROM/roms/basic_math.bin\n",
            "Installed /usr/local/lib/python3.11/dist-packages/multi_agent_ale_py/roms/basic_math.bin\n",
            "Installed /usr/local/lib/python3.11/dist-packages/AutoROM/roms/battle_zone.bin\n",
            "Installed /usr/local/lib/python3.11/dist-packages/multi_agent_ale_py/roms/battle_zone.bin\n",
            "Installed /usr/local/lib/python3.11/dist-packages/AutoROM/roms/beam_rider.bin\n",
            "Installed /usr/local/lib/python3.11/dist-packages/multi_agent_ale_py/roms/beam_rider.bin\n",
            "Installed /usr/local/lib/python3.11/dist-packages/AutoROM/roms/berzerk.bin\n",
            "Installed /usr/local/lib/python3.11/dist-packages/multi_agent_ale_py/roms/berzerk.bin\n",
            "Installed /usr/local/lib/python3.11/dist-packages/AutoROM/roms/blackjack.bin\n",
            "Installed /usr/local/lib/python3.11/dist-packages/multi_agent_ale_py/roms/blackjack.bin\n",
            "Installed /usr/local/lib/python3.11/dist-packages/AutoROM/roms/bowling.bin\n",
            "Installed /usr/local/lib/python3.11/dist-packages/multi_agent_ale_py/roms/bowling.bin\n",
            "Installed /usr/local/lib/python3.11/dist-packages/AutoROM/roms/boxing.bin\n",
            "Installed /usr/local/lib/python3.11/dist-packages/multi_agent_ale_py/roms/boxing.bin\n",
            "Installed /usr/local/lib/python3.11/dist-packages/AutoROM/roms/breakout.bin\n",
            "Installed /usr/local/lib/python3.11/dist-packages/multi_agent_ale_py/roms/breakout.bin\n",
            "Installed /usr/local/lib/python3.11/dist-packages/AutoROM/roms/carnival.bin\n",
            "Installed /usr/local/lib/python3.11/dist-packages/multi_agent_ale_py/roms/carnival.bin\n",
            "Installed /usr/local/lib/python3.11/dist-packages/AutoROM/roms/casino.bin\n",
            "Installed /usr/local/lib/python3.11/dist-packages/multi_agent_ale_py/roms/casino.bin\n",
            "Installed /usr/local/lib/python3.11/dist-packages/AutoROM/roms/centipede.bin\n",
            "Installed /usr/local/lib/python3.11/dist-packages/multi_agent_ale_py/roms/centipede.bin\n",
            "Installed /usr/local/lib/python3.11/dist-packages/AutoROM/roms/chopper_command.bin\n",
            "Installed /usr/local/lib/python3.11/dist-packages/multi_agent_ale_py/roms/chopper_command.bin\n",
            "Installed /usr/local/lib/python3.11/dist-packages/AutoROM/roms/combat.bin\n",
            "Installed /usr/local/lib/python3.11/dist-packages/multi_agent_ale_py/roms/combat.bin\n",
            "Installed /usr/local/lib/python3.11/dist-packages/AutoROM/roms/crazy_climber.bin\n",
            "Installed /usr/local/lib/python3.11/dist-packages/multi_agent_ale_py/roms/crazy_climber.bin\n",
            "Installed /usr/local/lib/python3.11/dist-packages/AutoROM/roms/crossbow.bin\n",
            "Installed /usr/local/lib/python3.11/dist-packages/multi_agent_ale_py/roms/crossbow.bin\n",
            "Installed /usr/local/lib/python3.11/dist-packages/AutoROM/roms/darkchambers.bin\n",
            "Installed /usr/local/lib/python3.11/dist-packages/multi_agent_ale_py/roms/darkchambers.bin\n",
            "Installed /usr/local/lib/python3.11/dist-packages/AutoROM/roms/defender.bin\n",
            "Installed /usr/local/lib/python3.11/dist-packages/multi_agent_ale_py/roms/defender.bin\n",
            "Installed /usr/local/lib/python3.11/dist-packages/AutoROM/roms/demon_attack.bin\n",
            "Installed /usr/local/lib/python3.11/dist-packages/multi_agent_ale_py/roms/demon_attack.bin\n",
            "Installed /usr/local/lib/python3.11/dist-packages/AutoROM/roms/donkey_kong.bin\n",
            "Installed /usr/local/lib/python3.11/dist-packages/multi_agent_ale_py/roms/donkey_kong.bin\n",
            "Installed /usr/local/lib/python3.11/dist-packages/AutoROM/roms/double_dunk.bin\n",
            "Installed /usr/local/lib/python3.11/dist-packages/multi_agent_ale_py/roms/double_dunk.bin\n",
            "Installed /usr/local/lib/python3.11/dist-packages/AutoROM/roms/earthworld.bin\n",
            "Installed /usr/local/lib/python3.11/dist-packages/multi_agent_ale_py/roms/earthworld.bin\n",
            "Installed /usr/local/lib/python3.11/dist-packages/AutoROM/roms/elevator_action.bin\n",
            "Installed /usr/local/lib/python3.11/dist-packages/multi_agent_ale_py/roms/elevator_action.bin\n",
            "Installed /usr/local/lib/python3.11/dist-packages/AutoROM/roms/enduro.bin\n",
            "Installed /usr/local/lib/python3.11/dist-packages/multi_agent_ale_py/roms/enduro.bin\n",
            "Installed /usr/local/lib/python3.11/dist-packages/AutoROM/roms/entombed.bin\n",
            "Installed /usr/local/lib/python3.11/dist-packages/multi_agent_ale_py/roms/entombed.bin\n",
            "Installed /usr/local/lib/python3.11/dist-packages/AutoROM/roms/et.bin\n",
            "Installed /usr/local/lib/python3.11/dist-packages/multi_agent_ale_py/roms/et.bin\n",
            "Installed /usr/local/lib/python3.11/dist-packages/AutoROM/roms/fishing_derby.bin\n",
            "Installed /usr/local/lib/python3.11/dist-packages/multi_agent_ale_py/roms/fishing_derby.bin\n",
            "Installed /usr/local/lib/python3.11/dist-packages/AutoROM/roms/flag_capture.bin\n",
            "Installed /usr/local/lib/python3.11/dist-packages/multi_agent_ale_py/roms/flag_capture.bin\n",
            "Installed /usr/local/lib/python3.11/dist-packages/AutoROM/roms/freeway.bin\n",
            "Installed /usr/local/lib/python3.11/dist-packages/multi_agent_ale_py/roms/freeway.bin\n",
            "Installed /usr/local/lib/python3.11/dist-packages/AutoROM/roms/frogger.bin\n",
            "Installed /usr/local/lib/python3.11/dist-packages/multi_agent_ale_py/roms/frogger.bin\n",
            "Installed /usr/local/lib/python3.11/dist-packages/AutoROM/roms/frostbite.bin\n",
            "Installed /usr/local/lib/python3.11/dist-packages/multi_agent_ale_py/roms/frostbite.bin\n",
            "Installed /usr/local/lib/python3.11/dist-packages/AutoROM/roms/galaxian.bin\n",
            "Installed /usr/local/lib/python3.11/dist-packages/multi_agent_ale_py/roms/galaxian.bin\n",
            "Installed /usr/local/lib/python3.11/dist-packages/AutoROM/roms/gopher.bin\n",
            "Installed /usr/local/lib/python3.11/dist-packages/multi_agent_ale_py/roms/gopher.bin\n",
            "Installed /usr/local/lib/python3.11/dist-packages/AutoROM/roms/gravitar.bin\n",
            "Installed /usr/local/lib/python3.11/dist-packages/multi_agent_ale_py/roms/gravitar.bin\n",
            "Installed /usr/local/lib/python3.11/dist-packages/AutoROM/roms/hangman.bin\n",
            "Installed /usr/local/lib/python3.11/dist-packages/multi_agent_ale_py/roms/hangman.bin\n",
            "Installed /usr/local/lib/python3.11/dist-packages/AutoROM/roms/haunted_house.bin\n",
            "Installed /usr/local/lib/python3.11/dist-packages/multi_agent_ale_py/roms/haunted_house.bin\n",
            "Installed /usr/local/lib/python3.11/dist-packages/AutoROM/roms/hero.bin\n",
            "Installed /usr/local/lib/python3.11/dist-packages/multi_agent_ale_py/roms/hero.bin\n",
            "Installed /usr/local/lib/python3.11/dist-packages/AutoROM/roms/human_cannonball.bin\n",
            "Installed /usr/local/lib/python3.11/dist-packages/multi_agent_ale_py/roms/human_cannonball.bin\n",
            "Installed /usr/local/lib/python3.11/dist-packages/AutoROM/roms/ice_hockey.bin\n",
            "Installed /usr/local/lib/python3.11/dist-packages/multi_agent_ale_py/roms/ice_hockey.bin\n",
            "Installed /usr/local/lib/python3.11/dist-packages/AutoROM/roms/jamesbond.bin\n",
            "Installed /usr/local/lib/python3.11/dist-packages/multi_agent_ale_py/roms/jamesbond.bin\n",
            "Installed /usr/local/lib/python3.11/dist-packages/AutoROM/roms/journey_escape.bin\n",
            "Installed /usr/local/lib/python3.11/dist-packages/multi_agent_ale_py/roms/journey_escape.bin\n",
            "Installed /usr/local/lib/python3.11/dist-packages/AutoROM/roms/joust.bin\n",
            "Installed /usr/local/lib/python3.11/dist-packages/multi_agent_ale_py/roms/joust.bin\n",
            "Installed /usr/local/lib/python3.11/dist-packages/AutoROM/roms/kaboom.bin\n",
            "Installed /usr/local/lib/python3.11/dist-packages/multi_agent_ale_py/roms/kaboom.bin\n",
            "Installed /usr/local/lib/python3.11/dist-packages/AutoROM/roms/kangaroo.bin\n",
            "Installed /usr/local/lib/python3.11/dist-packages/multi_agent_ale_py/roms/kangaroo.bin\n",
            "Installed /usr/local/lib/python3.11/dist-packages/AutoROM/roms/keystone_kapers.bin\n",
            "Installed /usr/local/lib/python3.11/dist-packages/multi_agent_ale_py/roms/keystone_kapers.bin\n",
            "Installed /usr/local/lib/python3.11/dist-packages/AutoROM/roms/king_kong.bin\n",
            "Installed /usr/local/lib/python3.11/dist-packages/multi_agent_ale_py/roms/king_kong.bin\n",
            "Installed /usr/local/lib/python3.11/dist-packages/AutoROM/roms/klax.bin\n",
            "Installed /usr/local/lib/python3.11/dist-packages/multi_agent_ale_py/roms/klax.bin\n",
            "Installed /usr/local/lib/python3.11/dist-packages/AutoROM/roms/koolaid.bin\n",
            "Installed /usr/local/lib/python3.11/dist-packages/multi_agent_ale_py/roms/koolaid.bin\n",
            "Installed /usr/local/lib/python3.11/dist-packages/AutoROM/roms/krull.bin\n",
            "Installed /usr/local/lib/python3.11/dist-packages/multi_agent_ale_py/roms/krull.bin\n",
            "Installed /usr/local/lib/python3.11/dist-packages/AutoROM/roms/kung_fu_master.bin\n",
            "Installed /usr/local/lib/python3.11/dist-packages/multi_agent_ale_py/roms/kung_fu_master.bin\n",
            "Installed /usr/local/lib/python3.11/dist-packages/AutoROM/roms/laser_gates.bin\n",
            "Installed /usr/local/lib/python3.11/dist-packages/multi_agent_ale_py/roms/laser_gates.bin\n",
            "Installed /usr/local/lib/python3.11/dist-packages/AutoROM/roms/lost_luggage.bin\n",
            "Installed /usr/local/lib/python3.11/dist-packages/multi_agent_ale_py/roms/lost_luggage.bin\n",
            "Installed /usr/local/lib/python3.11/dist-packages/AutoROM/roms/mario_bros.bin\n",
            "Installed /usr/local/lib/python3.11/dist-packages/multi_agent_ale_py/roms/mario_bros.bin\n",
            "Installed /usr/local/lib/python3.11/dist-packages/AutoROM/roms/maze_craze.bin\n",
            "Installed /usr/local/lib/python3.11/dist-packages/multi_agent_ale_py/roms/maze_craze.bin\n",
            "Installed /usr/local/lib/python3.11/dist-packages/AutoROM/roms/miniature_golf.bin\n",
            "Installed /usr/local/lib/python3.11/dist-packages/multi_agent_ale_py/roms/miniature_golf.bin\n",
            "Installed /usr/local/lib/python3.11/dist-packages/AutoROM/roms/montezuma_revenge.bin\n",
            "Installed /usr/local/lib/python3.11/dist-packages/multi_agent_ale_py/roms/montezuma_revenge.bin\n",
            "Installed /usr/local/lib/python3.11/dist-packages/AutoROM/roms/mr_do.bin\n",
            "Installed /usr/local/lib/python3.11/dist-packages/multi_agent_ale_py/roms/mr_do.bin\n",
            "Installed /usr/local/lib/python3.11/dist-packages/AutoROM/roms/ms_pacman.bin\n",
            "Installed /usr/local/lib/python3.11/dist-packages/multi_agent_ale_py/roms/ms_pacman.bin\n",
            "Installed /usr/local/lib/python3.11/dist-packages/AutoROM/roms/name_this_game.bin\n",
            "Installed /usr/local/lib/python3.11/dist-packages/multi_agent_ale_py/roms/name_this_game.bin\n",
            "Installed /usr/local/lib/python3.11/dist-packages/AutoROM/roms/othello.bin\n",
            "Installed /usr/local/lib/python3.11/dist-packages/multi_agent_ale_py/roms/othello.bin\n",
            "Installed /usr/local/lib/python3.11/dist-packages/AutoROM/roms/pacman.bin\n",
            "Installed /usr/local/lib/python3.11/dist-packages/multi_agent_ale_py/roms/pacman.bin\n",
            "Installed /usr/local/lib/python3.11/dist-packages/AutoROM/roms/phoenix.bin\n",
            "Installed /usr/local/lib/python3.11/dist-packages/multi_agent_ale_py/roms/phoenix.bin\n",
            "Installed /usr/local/lib/python3.11/dist-packages/AutoROM/roms/pitfall.bin\n",
            "Installed /usr/local/lib/python3.11/dist-packages/multi_agent_ale_py/roms/pitfall.bin\n",
            "Installed /usr/local/lib/python3.11/dist-packages/AutoROM/roms/pitfall2.bin\n",
            "Installed /usr/local/lib/python3.11/dist-packages/multi_agent_ale_py/roms/pitfall2.bin\n",
            "Installed /usr/local/lib/python3.11/dist-packages/AutoROM/roms/pong.bin\n",
            "Installed /usr/local/lib/python3.11/dist-packages/multi_agent_ale_py/roms/pong.bin\n",
            "Installed /usr/local/lib/python3.11/dist-packages/AutoROM/roms/pooyan.bin\n",
            "Installed /usr/local/lib/python3.11/dist-packages/multi_agent_ale_py/roms/pooyan.bin\n",
            "Installed /usr/local/lib/python3.11/dist-packages/AutoROM/roms/private_eye.bin\n",
            "Installed /usr/local/lib/python3.11/dist-packages/multi_agent_ale_py/roms/private_eye.bin\n",
            "Installed /usr/local/lib/python3.11/dist-packages/AutoROM/roms/qbert.bin\n",
            "Installed /usr/local/lib/python3.11/dist-packages/multi_agent_ale_py/roms/qbert.bin\n",
            "Installed /usr/local/lib/python3.11/dist-packages/AutoROM/roms/riverraid.bin\n",
            "Installed /usr/local/lib/python3.11/dist-packages/multi_agent_ale_py/roms/riverraid.bin\n",
            "Installed /usr/local/lib/python3.11/dist-packages/AutoROM/roms/road_runner.bin\n",
            "Installed /usr/local/lib/python3.11/dist-packages/multi_agent_ale_py/roms/road_runner.bin\n",
            "Installed /usr/local/lib/python3.11/dist-packages/AutoROM/roms/robotank.bin\n",
            "Installed /usr/local/lib/python3.11/dist-packages/multi_agent_ale_py/roms/robotank.bin\n",
            "Installed /usr/local/lib/python3.11/dist-packages/AutoROM/roms/seaquest.bin\n",
            "Installed /usr/local/lib/python3.11/dist-packages/multi_agent_ale_py/roms/seaquest.bin\n",
            "Installed /usr/local/lib/python3.11/dist-packages/AutoROM/roms/sir_lancelot.bin\n",
            "Installed /usr/local/lib/python3.11/dist-packages/multi_agent_ale_py/roms/sir_lancelot.bin\n",
            "Installed /usr/local/lib/python3.11/dist-packages/AutoROM/roms/skiing.bin\n",
            "Installed /usr/local/lib/python3.11/dist-packages/multi_agent_ale_py/roms/skiing.bin\n",
            "Installed /usr/local/lib/python3.11/dist-packages/AutoROM/roms/solaris.bin\n",
            "Installed /usr/local/lib/python3.11/dist-packages/multi_agent_ale_py/roms/solaris.bin\n",
            "Installed /usr/local/lib/python3.11/dist-packages/AutoROM/roms/space_invaders.bin\n",
            "Installed /usr/local/lib/python3.11/dist-packages/multi_agent_ale_py/roms/space_invaders.bin\n",
            "Installed /usr/local/lib/python3.11/dist-packages/AutoROM/roms/space_war.bin\n",
            "Installed /usr/local/lib/python3.11/dist-packages/multi_agent_ale_py/roms/space_war.bin\n",
            "Installed /usr/local/lib/python3.11/dist-packages/AutoROM/roms/star_gunner.bin\n",
            "Installed /usr/local/lib/python3.11/dist-packages/multi_agent_ale_py/roms/star_gunner.bin\n",
            "Installed /usr/local/lib/python3.11/dist-packages/AutoROM/roms/superman.bin\n",
            "Installed /usr/local/lib/python3.11/dist-packages/multi_agent_ale_py/roms/superman.bin\n",
            "Installed /usr/local/lib/python3.11/dist-packages/AutoROM/roms/surround.bin\n",
            "Installed /usr/local/lib/python3.11/dist-packages/multi_agent_ale_py/roms/surround.bin\n",
            "Installed /usr/local/lib/python3.11/dist-packages/AutoROM/roms/tennis.bin\n",
            "Installed /usr/local/lib/python3.11/dist-packages/multi_agent_ale_py/roms/tennis.bin\n",
            "Installed /usr/local/lib/python3.11/dist-packages/AutoROM/roms/tetris.bin\n",
            "Installed /usr/local/lib/python3.11/dist-packages/multi_agent_ale_py/roms/tetris.bin\n",
            "Installed /usr/local/lib/python3.11/dist-packages/AutoROM/roms/tic_tac_toe_3d.bin\n",
            "Installed /usr/local/lib/python3.11/dist-packages/multi_agent_ale_py/roms/tic_tac_toe_3d.bin\n",
            "Installed /usr/local/lib/python3.11/dist-packages/AutoROM/roms/time_pilot.bin\n",
            "Installed /usr/local/lib/python3.11/dist-packages/multi_agent_ale_py/roms/time_pilot.bin\n",
            "Installed /usr/local/lib/python3.11/dist-packages/AutoROM/roms/trondead.bin\n",
            "Installed /usr/local/lib/python3.11/dist-packages/multi_agent_ale_py/roms/trondead.bin\n",
            "Installed /usr/local/lib/python3.11/dist-packages/AutoROM/roms/turmoil.bin\n",
            "Installed /usr/local/lib/python3.11/dist-packages/multi_agent_ale_py/roms/turmoil.bin\n",
            "Installed /usr/local/lib/python3.11/dist-packages/AutoROM/roms/tutankham.bin\n",
            "Installed /usr/local/lib/python3.11/dist-packages/multi_agent_ale_py/roms/tutankham.bin\n",
            "Installed /usr/local/lib/python3.11/dist-packages/AutoROM/roms/up_n_down.bin\n",
            "Installed /usr/local/lib/python3.11/dist-packages/multi_agent_ale_py/roms/up_n_down.bin\n",
            "Installed /usr/local/lib/python3.11/dist-packages/AutoROM/roms/venture.bin\n",
            "Installed /usr/local/lib/python3.11/dist-packages/multi_agent_ale_py/roms/venture.bin\n",
            "Installed /usr/local/lib/python3.11/dist-packages/AutoROM/roms/video_checkers.bin\n",
            "Installed /usr/local/lib/python3.11/dist-packages/multi_agent_ale_py/roms/video_checkers.bin\n",
            "Installed /usr/local/lib/python3.11/dist-packages/AutoROM/roms/video_chess.bin\n",
            "Installed /usr/local/lib/python3.11/dist-packages/multi_agent_ale_py/roms/video_chess.bin\n",
            "Installed /usr/local/lib/python3.11/dist-packages/AutoROM/roms/video_cube.bin\n",
            "Installed /usr/local/lib/python3.11/dist-packages/multi_agent_ale_py/roms/video_cube.bin\n",
            "Installed /usr/local/lib/python3.11/dist-packages/AutoROM/roms/video_pinball.bin\n",
            "Installed /usr/local/lib/python3.11/dist-packages/multi_agent_ale_py/roms/video_pinball.bin\n",
            "Installed /usr/local/lib/python3.11/dist-packages/AutoROM/roms/warlords.bin\n",
            "Installed /usr/local/lib/python3.11/dist-packages/multi_agent_ale_py/roms/warlords.bin\n",
            "Installed /usr/local/lib/python3.11/dist-packages/AutoROM/roms/wizard_of_wor.bin\n",
            "Installed /usr/local/lib/python3.11/dist-packages/multi_agent_ale_py/roms/wizard_of_wor.bin\n",
            "Installed /usr/local/lib/python3.11/dist-packages/AutoROM/roms/word_zapper.bin\n",
            "Installed /usr/local/lib/python3.11/dist-packages/multi_agent_ale_py/roms/word_zapper.bin\n",
            "Installed /usr/local/lib/python3.11/dist-packages/AutoROM/roms/yars_revenge.bin\n",
            "Installed /usr/local/lib/python3.11/dist-packages/multi_agent_ale_py/roms/yars_revenge.bin\n",
            "Installed /usr/local/lib/python3.11/dist-packages/AutoROM/roms/zaxxon.bin\n",
            "Installed /usr/local/lib/python3.11/dist-packages/multi_agent_ale_py/roms/zaxxon.bin\n",
            "Done!\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import sys\n",
        "import gymnasium as gym\n",
        "import os\n",
        "import time\n",
        "import imageio\n",
        "import importlib\n",
        "from collections import defaultdict, Counter\n",
        "\n",
        "from stable_baselines3 import PPO\n",
        "from stable_baselines3.ppo import CnnPolicy\n",
        "\n",
        "from pettingzoo.atari import warlords_v3\n",
        "from pettingzoo.utils import BaseParallelWrapper\n",
        "import supersuit as ss\n",
        "\n",
        "from google.colab import drive\n",
        "!AutoROM"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<div style=\"background-color:white; color:black; padding: 10px;\">\n",
        "    <strong>Mounten van colab drive en inladen van de agents</strong>\n",
        "</div>"
      ],
      "metadata": {
        "id": "041sv7N4qs7r"
      },
      "id": "041sv7N4qs7r"
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "drive.mount('/content/drive')\n",
        "sys.path.append('/content/drive/MyDrive/Autonomous Systems')\n",
        "print(os.listdir('/content/drive/MyDrive/Autonomous Systems'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5w-qIX5DqtDb",
        "outputId": "7361a66a-25c4-43e7-84f1-c73b0c936dbd"
      },
      "id": "5w-qIX5DqtDb",
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "[]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "id": "438c13d8",
      "metadata": {
        "id": "438c13d8"
      },
      "source": [
        "\n",
        "---\n",
        "<div style=\"background-color:LightBlue; text-align:center; vertical-align:middle; padding:50px 0; margin-top:5px; margin-bottom:5px\">\n",
        "    <h2 id=\"eda-title\" style=\"color:black; font-family: Verdana, sans-serif; font-size: 25px;\"><strong>H2: Kiezen van Algoritme </strong></h2>\n",
        "</div>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## §2.1: Kiezen van RL-Algoritme\n",
        "\n",
        "In deze opdracht staat de Atari-game **Warlords** centraal: een klassieke arcadegame waarbij vier spelers (agents) gelijktijdig strijden op een speelveld. Iedere agent verdedigt zijn eigen kasteel en probeert de anderen uit te schakelen, wat resulteert in een typisch **multi-agent scenario** met zowel competitie als wisselende interactiepatronen tussen agents. Voor deze complexe en dynamische omgeving is het belangrijk om een reinforcement learning-algoritme te kiezen dat bewezen effectief is bij problemen met een hoge mate van onzekerheid, veel mogelijke toestanden en meerdere spelers.\n",
        "\n",
        "We kiezen voor het **Proximal Policy Optimization (PPO)** algoritme als basis voor onze agent. PPO is een krachtig, modern en veelgebruikt algoritme binnen deep reinforcement learning. Het is ontworpen voor stabiliteit en efficiëntie bij het optimaliseren van beleid (policies), en heeft uitstekende prestaties laten zien in visuele, dynamische omgevingen zoals Atari-games. PPO leert direct van ruwe pixeldata via een convolutioneel neuraal netwerk en maakt gebruik van policy-gradient updates die gecontroleerd worden uitgevoerd om instabiliteit te voorkomen.\n",
        "\n",
        "### Waarom PPO?\n",
        "\n",
        "- **Geschikt voor visuele input:**  \n",
        "  PPO werkt uitstekend met ruwe spelbeelden (frames) als input, en kan daardoor zelfstandig complexe strategieën ontwikkelen zonder handmatige feature engineering. De convolutionele neurale netwerken van PPO zijn uitermate geschikt voor het herkennen van visuele patronen in Atari-omgevingen.\n",
        "\n",
        "- **Stabiel en robuust leren:**  \n",
        "  Door het gebruik van trust-region updates (clipping), mini-batch learning en advantage schatting (GAE), blijft het leerproces gecontroleerd en raakt het model minder snel verstrikt in abrupte of onstabiele policy-wijzigingen. Dit is cruciaal in chaotische multi-agent omgevingen zoals Warlords.\n",
        "\n",
        "- **Multi-agent compatibiliteit:**  \n",
        "  PPO laat zich eenvoudig toepassen op multi-agent settings, bijvoorbeeld via parameter sharing (één policy voor meerdere agents) of door individuele policies te trainen per agent. Dit maakt het flexibel inzetbaar voor uiteenlopende experimenten.\n",
        "\n",
        "- **Breed onderzocht en veel gebruikt:**  \n",
        "  PPO behoort tot de standaardbenchmarks in reinforcement learning en is in tal van studies succesvol ingezet voor Atari-omgevingen en multi-agent settings. Er zijn veel goed onderhouden frameworks beschikbaar (zoals Stable-Baselines3 en PettingZoo), wat snelle en correcte implementatie mogelijk maakt.\n",
        "\n",
        "### Concreet voordeel voor deze opdracht\n",
        "\n",
        "- **Algoritmische robuustheid:**  \n",
        "  PPO is bijzonder effectief in dynamische en onvoorspelbare omgevingen waar het gedrag van andere agents voortdurend verandert. Dankzij gecontroleerde policy-updates en efficiënte verwerking van ervaringen is PPO in staat om robuuste strategieën te ontwikkelen.\n",
        "\n",
        "- **Vergelijkbaarheid:**  \n",
        "  PPO is een veelgebruikte standaard in de literatuur rondom Atari en multi-agent reinforcement learning. Hierdoor zijn onze resultaten goed te vergelijken met bestaande benchmarks en alternatieve algoritmes (zoals DQN of random policies).\n",
        "\n",
        "- **Transparantie en reproduceerbaarheid:**  \n",
        "  Dankzij de brede adoptie en solide implementaties in frameworks als Stable-Baselines3 en PettingZoo zijn onze experimenten eenvoudig te reproduceren, uit te breiden en te valideren door andere studenten of onderzoekers.\n"
      ],
      "metadata": {
        "id": "aTDt5gr586-3"
      },
      "id": "aTDt5gr586-3"
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Uitleg van PPO**\n",
        "\n",
        "Proximal Policy Optimization (PPO) is een geavanceerd reinforcement learning-algoritme dat veel wordt gebruikt voor het trainen van agents in complexe omgevingen zoals Atari-spellen. PPO verbetert eerdere policy-gradient-methodes door bij elke stap de aanpassing van het beleid (“policy”) te beperken. Hierdoor wordt het leerproces stabieler en is de kans kleiner dat de agent ineens “vergeet” wat hij geleerd heeft.\n",
        "\n",
        "PPO werkt door het beleid steeds een klein beetje aan te passen op basis van ervaringen uit de omgeving. Hierdoor leert de agent efficiënter en zijn de resultaten vaak beter reproduceerbaar. PPO is ook geschikt voor situaties met hoge-dimensionale input, zoals beelden, en werkt goed in multi-agent omgevingen zoals Warlords.\n",
        "\n",
        "DhanushKumar (2024)\n",
        "\n",
        "### **Motivatie**\n",
        "\n",
        "Voor deze opdracht heb ik gekozen voor het algoritme Proximal Policy Optimization (PPO). De belangrijkste reden hiervoor is dat PPO bekend staat om zijn stabiliteit en efficiëntie bij het trainen van agents in complexe omgevingen met hoge-dimensionale input, zoals de Atari-game Warlords, Schulman et al. (2017). Omdat PPO de aanpassingen aan het beleid per stap beperkt, blijft het leerproces gecontroleerd en voorkom je dat de agent tijdens het trainen “vergeet” wat eerder geleerd is. Dit is vooral belangrijk in multi-agent omgevingen, waar het gedrag van andere agents de situatie voortdurend beïnvloedt.\n",
        "\n",
        "Daarnaast is PPO eenvoudig te implementeren dankzij bestaande libraries zoals stable-baselines3, waardoor het mogelijk is om snel te experimenteren met verschillende hyperparameters. De standaardwaarden die ik voor de belangrijkste hyperparameters heb gekozen, zijn gebaseerd op aanbevelingen uit de literatuur en eerdere succesvolle toepassingen in vergelijkbare omgevingen (The 37 Implementation Details Of Proximal Policy Optimization · The ICLR Blog Track, 2022). PPO is bovendien goed schaalbaar, waardoor het geschikt is om in een multi-agent setting zoals Warlords verschillende agents onafhankelijk van elkaar te trainen en te vergelijken.\n",
        "\n",
        "Door deze eigenschappen is PPO naar mijn mening de meest geschikte keuze voor deze opdracht, omdat het zorgt voor betrouwbare leerresultaten en flexibiliteit biedt bij het uitvoeren van experimenten met verschillende agents en trainingsinstellingen.\n",
        "\n",
        "### **Aanpak**\n",
        "\n",
        "Voor deze opdracht heb ik een PPO-agent geïmplementeerd met behulp van de stable-baselines3 library. PPO is gekozen vanwege de stabiele prestaties en de robuustheid bij het trainen in omgevingen met beeldinput, zoals “Warlords”. De agent gebruikt een convolutioneel neuraal netwerk om de observaties te verwerken.\n",
        "De belangrijkste hyperparameters zijn gekozen op basis van aanbevolen waarden uit wetenschappelijke literatuur voor Atari-omgevingen, maar kunnen verder geoptimaliseerd worden.\n",
        "Mijn implementatie maakt het makkelijk om het model op te slaan, opnieuw te laden en te evalueren, zodat experimenten goed reproduceerbaar zijn."
      ],
      "metadata": {
        "id": "cZW97gbO7eh5"
      },
      "id": "cZW97gbO7eh5"
    },
    {
      "cell_type": "markdown",
      "id": "e9d941ae",
      "metadata": {
        "id": "e9d941ae"
      },
      "source": [
        "<a name='1.1'></a>\n",
        "<h3>&sect;2.3: Kiezen van Trainingsstrategie</h3>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Trainingsstrategie in Multi-Agent Warlords\n",
        "\n",
        "Om optimaal gebruik te maken van het gekozen algoritme, hanteren we een trainingsstrategie die inspeelt op de uitdagingen van multi-agent reinforcement learning:\n",
        "\n",
        "1. **Multi-agent omgeving:**  \n",
        "   In Warlords zijn altijd meerdere agents actief. Onze PPO-agent wordt getraind door herhaaldelijk games te spelen tegen vooraf ingestelde tegenstanders, zoals random agents of (indien gewenst) andere PPO-agents. Dit zorgt ervoor dat de agent leert in een realistische, competitieve setting.\n",
        "\n",
        "2. **Variatie in tegenstanders:**  \n",
        "   Door de agent bloot te stellen aan verschillende typen tegenstanders (van random tot geavanceerd), voorkomen we dat de agent eenzijdige strategieën aanleert. Zo ontwikkelt de agent robuustere, meer generaliseerbare strategieën.\n",
        "\n",
        "3. **Observatie- en actie-preprocessing:**  \n",
        "   We gebruiken beeldverwerkingstechnieken zoals grijswaardenconversie, rescaling en stacking van frames. Dit zorgt ervoor dat de agent alleen de essentiële informatie uit het spel verwerkt, waardoor het leerproces efficiënter verloopt.\n",
        "\n",
        "4. **On-policy leren & rollouts:**  \n",
        "   PPO werkt met zogenoemde rollouts: de agent verzamelt verse trajecten door de omgeving en leert direct van deze actuele ervaringen. Dit betekent dat elke policy-update gebaseerd is op recent gedrag, wat bijdraagt aan stabiliteit en effectieve policy-veranderingen.\n",
        "\n",
        "5. **Regelmatige evaluatie en hyperparameter tuning:**  \n",
        "   Tijdens de training evalueren we regelmatig de prestaties van de agent door deze te laten spelen tegen de baseline (zoals een random agent). Daarnaast experimenteren we met verschillende hyperparameters, zoals learning rate, batch size, en de clipping-range van PPO, om de optimale instellingen te bepalen.\n",
        "\n",
        "6. **Logging en visualisatie:**  \n",
        "   Alle trainingsresultaten (zoals reward curves, winpercentages, etc.) worden gelogd en gevisualiseerd. Hierdoor kunnen we het leerproces volgen en analyseren, en waar nodig de strategie bijstellen.\n",
        "\n",
        "### Samenvattend\n",
        "\n",
        "Deze aanpak zorgt ervoor dat onze PPO-agent niet alleen leert van het eigen gedrag, maar zich ook kan aanpassen aan verschillende soorten tegenstanders. Door systematisch te trainen, evalueren en hyperparameters te tunen, halen we het maximale uit ons algoritme en maken we de voordelen van reinforcement learning in een multi-agent context helder zichtbaar.\n"
      ],
      "metadata": {
        "id": "QdDPbh7p9UNL"
      },
      "id": "QdDPbh7p9UNL"
    },
    {
      "cell_type": "markdown",
      "id": "6107d561",
      "metadata": {
        "id": "6107d561"
      },
      "source": [
        "\n",
        "---\n",
        "<div style=\"background-color:LightBlue; text-align:center; vertical-align:middle; padding:50px 0; margin-top:5px; margin-bottom:5px\">\n",
        "    <h2 id=\"eda-title\" style=\"color:black; font-family: Verdana, sans-serif; font-size: 25px;\"><strong>H3: Probleemdefinitie </strong></h2>\n",
        "</div>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6bcbb909",
      "metadata": {
        "id": "6bcbb909"
      },
      "source": [
        "<a name='1.1'></a>\n",
        "<h3>&sect;3.1: Wat is het probleem?</h3>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Probleemanalyse\n",
        "De opkomst van multi-agent omgevingen in toepassingen zoals robotica, games en logistiek vraagt om slimme algoritmes die kunnen concurreren én samenwerken. In de praktijk betekent dit dat agents hun strategieën continu moeten bijstellen op basis van het gedrag van andere agents in hun omgeving. In de Atari-game Warlords komen vier agents tegelijkertijd in actie, waarbij hun succes afhankelijk is van zowel hun eigen keuzes als die van hun tegenstanders.\n",
        "\n",
        "Single-agent reinforcement learning is onvoldoende, omdat hierbij wordt aangenomen dat de omgeving stationair is (niet verandert door anderen). In multi-agent settings verandert de omgeving echter continu, omdat andere agents ook leren en hun gedrag aanpassen. Dit vraagt om een benadering waarbij agents niet alleen leren van hun eigen ervaringen, maar ook van de interacties met anderen.\n",
        "\n",
        "Met multi-agent reinforcement learning (MARL) kunnen agents hun beleid optimaliseren terwijl ze rekening houden met de strategieën van anderen. Hierdoor ontstaan vaak complexe en onverwachte gedragingen die in single-agent settings niet mogelijk zijn. Bovendien kunnen MARL-methoden worden ingezet om situaties te modelleren waarin competitie, samenwerking of beide tegelijk nodig zijn.\n",
        "\n",
        "##### Relevantie van het probleem\n",
        "- In veel echte omgevingen zijn meerdere autonome beslissers actief (bijvoorbeeld zelfrijdende auto's in verkeer).\n",
        "- Het ontwerpen van robuuste agents in zulke settings helpt bij het ontwikkelen van realistische, schaalbare en adaptieve AI-systemen.\n",
        "- In de context van games als Warlords kan MARL inzichten bieden in hoe intelligente strategieën en tegenstrategieën ontstaan in competitieve settings.\n",
        "\n",
        "##### Samenvatting probleemstelling (één zin):\n",
        "\"Hoe kunnen we effectieve, lerende agents ontwikkelen die optimaal presteren in een competitieve multi-agent omgeving, waarbij rekening wordt gehouden met de voortdurende interactie en dynamiek tussen verschillende agents?\"\n",
        "\n",
        "Scharwächter (2024)\n",
        "\n",
        "#### Doelstelling\n",
        "Het doel van deze opdracht is om een multi-agent reinforcement learning systeem te ontwerpen, implementeren en evalueren voor de Atari Warlords-omgeving. Dit gebeurt door een MARL-algoritme, PPO, te trainen en de prestaties te vergelijken met een baseline. Het eindresultaat is een reproduceerbaar systeem en een rapport met een diepgaande analyse van de werking en effectiviteit van het gekozen algoritme."
      ],
      "metadata": {
        "id": "9ydUYqpqrNmw"
      },
      "id": "9ydUYqpqrNmw"
    },
    {
      "cell_type": "markdown",
      "id": "18f470aa",
      "metadata": {
        "id": "18f470aa"
      },
      "source": [
        "\n",
        "---\n",
        "<div style=\"background-color:LightBlue; text-align:center; vertical-align:middle; padding:50px 0; margin-top:5px; margin-bottom:5px\">\n",
        "    <h2 id=\"eda-title\" style=\"color:black; font-family: Verdana, sans-serif; font-size: 25px;\"><strong>H4: Ontwerp en Implementatie</strong></h2>\n",
        "</div>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "086bad36",
      "metadata": {
        "id": "086bad36"
      },
      "source": [
        "<a name='1.1'></a>\n",
        "<h3>&sect;4.1: Baseline strategie ontwikkelen</h3>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<div style=\"background-color:white; color:black; padding: 10px;\">\n",
        "    <strong>Baseline: Random Agent</strong>\n",
        "</div>\n",
        "\n",
        "Als startpunt voor het vergelijken van verschillende algoritmes is het belangrijk om een baseline te definiëren. In deze opdracht gebruiken we een random agent als baseline. Dit is een agent die bij elke stap willekeurig een van de mogelijke acties kiest, ongeacht de observatie of situatie in het spel.\n",
        "\n",
        "**Waarom een random agent als baseline?**\n",
        "\n",
        "Een random agent biedt een objectief referentiepunt: het laat zien wat de prestaties zouden zijn zonder enige vorm van intelligentie, strategie of leren. Door de resultaten van geavanceerdere agents (zoals een rule-based agent of een reinforcement learning agent zoals PPO) te vergelijken met deze random agent, kun je duidelijk aantonen of jouw aanpak daadwerkelijk beter presteert dan toeval.\n",
        "\n",
        "**Implementatie**\n",
        "\n",
        "De implementatie van de random agent is heel eenvoudig. De agent kiest telkens een willekeurige actie uit het totale aantal toegestane acties van de omgeving. In het geval van Atari Warlords zijn dit bijvoorbeeld zes mogelijke acties.\n"
      ],
      "metadata": {
        "id": "hmQKYc-6tRob"
      },
      "id": "hmQKYc-6tRob"
    },
    {
      "cell_type": "code",
      "source": [
        "class AgentRandomPolicy:\n",
        "    def act(self, observation):\n",
        "        # Return a random action (6 possible in ALE Warlords)\n",
        "        return np.random.randint(6)\n"
      ],
      "metadata": {
        "id": "IXQkWF0RsqFo"
      },
      "id": "IXQkWF0RsqFo",
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "b41eef89",
      "metadata": {
        "id": "b41eef89"
      },
      "source": [
        "<a name='1.1'></a>\n",
        "<h3>&sect;4.2: Selectie van DRL algoritme en frameworks</h3>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Keuze van Algoritme\n",
        "\n",
        "Voor deze opdracht, waarin de agent moet presteren in de **multi-agent omgeving van Atari Warlords**, kiezen we voor het **Proximal Policy Optimization (PPO)** algoritme. PPO is momenteel één van de meest gebruikte en robuuste algoritmes voor deep reinforcement learning, vooral geschikt voor problemen met complexe visuele input en multi-agent interactie. De belangrijkste voordelen van PPO:\n",
        "\n",
        "- **Stabiel leren van ruwe pixels:** PPO maakt gebruik van convolutionele neurale netwerken (CNN’s) om direct van visuele observaties te leren, zonder handmatig feature engineering.\n",
        "- **Uitstekende prestaties in Atari-omgevingen:** PPO heeft zich bewezen als benchmark-algoritme in veel Atari-games, mede dankzij de balans tussen exploratie en exploitatie.\n",
        "- **Direct geschikt voor multi-agent settings:** PPO kan eenvoudig worden ingezet met *parameter sharing* (één policy voor meerdere agents) of individuele policies per agent, wat het flexibel maakt voor uiteenlopende MARL-experimenten.\n",
        "\n",
        "### Keuze & Motivatie\n",
        "\n",
        "In deze opdracht trainen we een **PPO-agent** in de multi-agent Warlords-omgeving. Hierbij nemen onze agenten het op tegen ingebouwde tegenstanders, zoals random agents. Zo kunnen we de kracht van deep RL aantonen in vergelijking met simpele baseline strategieën.\n",
        "\n",
        "#### Waarom PPO in deze context?\n",
        "\n",
        "- **Stabiele policy learning:** PPO minimaliseert het risico op instabiliteit door gecontroleerde policy-updates (clipping), wat vooral belangrijk is in chaotische multi-agent omgevingen.\n",
        "- **Visual input:** Warlords levert observaties als pixeldata, wat naadloos aansluit op de CNN-architectuur van PPO.\n",
        "- **Flexibiliteit:** PPO werkt zowel met discrete als continue actie-ruimtes en laat zich makkelijk combineren met moderne MARL frameworks.\n",
        "\n",
        "---\n",
        "\n",
        "### Packages en Frameworks\n",
        "\n",
        "Voor de implementatie en evaluatie maken we gebruik van de volgende frameworks en libraries:\n",
        "\n",
        "#### 1. **Stable-Baselines3**\n",
        "- Biedt een krachtige en stabiele implementatie van PPO, met uitgebreide ondersteuning voor logging en evaluatie.\n",
        "- Direct compatibel met vectorized en custom omgevingen.\n",
        "\n",
        "#### 2. **PettingZoo**\n",
        "- De standaard voor multi-agent reinforcement learning omgevingen, met een ruime keuze aan benchmarkomgevingen zoals Atari Warlords.\n",
        "- Zorgt voor een uniforme interface en maakt snelle experimentatie mogelijk.\n",
        "\n",
        "#### 3. **Supersuit**\n",
        "- Bibliotheek voor preprocessing (o.a. frames resizen, kleuren reduceren en frame stacking), essentieel voor efficiënte training op visuele data.\n",
        "\n",
        "---\n",
        "\n",
        "### Samenvatting van de strategie\n",
        "\n",
        "- We trainen een PPO-agent in de **PettingZoo Atari Warlords** omgeving tegen baseline agents (zoals random).\n",
        "- PPO stelt ons in staat om efficiënt en stabiel te leren in deze multi-agent setting, met als doel beter te presteren dan eenvoudige baselines.\n",
        "- Door te bouwen op bewezen frameworks en preprocessing pipelines is onze aanpak **reproduceerbaar, schaalbaar en robuust**.\n",
        "\n",
        "---\n"
      ],
      "metadata": {
        "id": "sm8SLNH6wAbI"
      },
      "id": "sm8SLNH6wAbI"
    },
    {
      "cell_type": "markdown",
      "id": "e51ff2f0",
      "metadata": {
        "id": "e51ff2f0"
      },
      "source": [
        "<a name='1.1'></a>\n",
        "<h3>&sect;4.3: Implementatie MARL-agent</h3>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "327a104c",
      "metadata": {
        "id": "327a104c"
      },
      "source": [
        "d.\tResultaat: Een werkend MARL-systeem dat klaar is voor training en evaluatie."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<div style=\"background-color:white; color:black; padding: 10px;\">\n",
        "    <strong>(Rogier) PPO Agent ( DEZE FUNCTIE NOG ZETTEN BIJ DE TRAINING STAP )</strong>\n",
        "</div>"
      ],
      "metadata": {
        "id": "3us4a2TXs3IY"
      },
      "id": "3us4a2TXs3IY"
    },
    {
      "cell_type": "markdown",
      "source": [
        "In de onderstaande cel definiëren we de klasse MARLAgentPPO, een modulair systeem dat geschikt is voor het trainen van PPO-agenten in een multi-agent setting met behulp van de PettingZoo-omgeving warlords_v3. De klasse bevat methoden voor het instellen van de omgeving, het trainen van het model, en het opslaan of laden van een getraind PPO-model.\n",
        "\n",
        " -   De omgeving wordt gepreprocessed met behulp van Supersuit-wrappers (zoals black_death, color_reduction, resizing en frame stacking).\n",
        "\n",
        "-  Vervolgens wordt de omgeving geconverteerd naar een vectorized environment die compatibel is met Stable-Baselines3.\n",
        "\n",
        "-   De train()-methode traint het PPO-model met een CnnPolicy, geschikt voor de beeldinvoer van Atari-games.\n",
        "\n",
        "-  Met save() en load() kunnen getrainde modellen eenvoudig worden opgeslagen of ingeladen.\n",
        "\n",
        "Deze klasse maakt het mogelijk om met ons MARL-systeem op een reproduceerbare en schaalbare manier PPO-agenten te trainen in een multi-agent omgeving.\n",
        "\n",
        "(PPO — Stable Baselines3 2.7.0a0 Documentation, z.d.)"
      ],
      "metadata": {
        "id": "QVf1ym4iZO3C"
      },
      "id": "QVf1ym4iZO3C"
    },
    {
      "cell_type": "markdown",
      "source": [
        "# MARL PPO met meer parameters"
      ],
      "metadata": {
        "id": "morKGfwKC5pq"
      },
      "id": "morKGfwKC5pq"
    },
    {
      "cell_type": "code",
      "source": [
        "class MARLAgentPPO:\n",
        "    \"\"\"\n",
        "    Multi-Agent RL systeem voor de Atari Warlords omgeving.\n",
        "    Ondersteunt setup, training, evaluatie en het opslaan/laden van PPO-modellen.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(\n",
        "        self,\n",
        "        num_vec_envs=2,\n",
        "        frame_stack=4,\n",
        "        x_size=84,\n",
        "        y_size=84,\n",
        "        batch_size=256,\n",
        "        total_timesteps=4_000_000,\n",
        "        verbose=1\n",
        "    ):\n",
        "        \"\"\"\n",
        "        Initialiseer de omgeving en hyperparameters.\n",
        "        \"\"\"\n",
        "        self.num_vec_envs = num_vec_envs\n",
        "        self.frame_stack = frame_stack\n",
        "        self.x_size = x_size\n",
        "        self.y_size = y_size\n",
        "        self.batch_size = batch_size\n",
        "        self.total_timesteps = total_timesteps\n",
        "        self.verbose = verbose\n",
        "\n",
        "        self.env = self._make_env()\n",
        "        self.vec_env = self._make_vec_env()\n",
        "        self.model = None\n",
        "\n",
        "    def _make_env(self):\n",
        "        \"\"\"\n",
        "        Zet de Warlords-omgeving klaar met preprocessing-wrappers.\n",
        "        \"\"\"\n",
        "        env = warlords_v3.parallel_env()\n",
        "        env = ss.black_death_v3(env)\n",
        "        env = ss.color_reduction_v0(env, mode='full')\n",
        "        env = ss.resize_v1(env, x_size=self.x_size, y_size=self.y_size)\n",
        "        env = ss.frame_stack_v1(env, self.frame_stack)\n",
        "        return env\n",
        "\n",
        "    def _make_vec_env(self):\n",
        "        \"\"\"\n",
        "        Converteer naar een vectorized environment voor Stable-Baselines3.\n",
        "        \"\"\"\n",
        "        vec_env = ss.pettingzoo_env_to_vec_env_v1(self.env)\n",
        "        vec_env = ss.concat_vec_envs_v1(\n",
        "            vec_env,\n",
        "            num_vec_envs=self.num_vec_envs,\n",
        "            num_cpus=1,\n",
        "            base_class=\"stable_baselines3\"\n",
        "        )\n",
        "        return vec_env\n",
        "\n",
        "    def train(self):\n",
        "        \"\"\"\n",
        "        Initialiseer en train het PPO-model met geoptimaliseerde hyperparameters.\n",
        "        \"\"\"\n",
        "        print(\"Start training...\")\n",
        "        self.model = PPO(\n",
        "            CnnPolicy,\n",
        "            self.vec_env,\n",
        "            verbose=self.verbose,\n",
        "            batch_size=self.batch_size,\n",
        "            n_steps=128,\n",
        "            n_epochs=4,\n",
        "            learning_rate=2.5e-4,\n",
        "            ent_coef=0.01,\n",
        "            gae_lambda=0.95,\n",
        "            gamma=0.99,\n",
        "            clip_range=0.1,\n",
        "            vf_coef=0.5,\n",
        "            max_grad_norm=0.5,\n",
        "            tensorboard_log=\"./ppo_warlords_tensorboard/\"\n",
        "        )\n",
        "        self.model.learn(total_timesteps=self.total_timesteps)\n",
        "        print(\"Training gereed.\")\n",
        "\n",
        "    def save(self, model_name=None):\n",
        "        \"\"\"\n",
        "        Sla het getrainde model op, optioneel met custom naam.\n",
        "        \"\"\"\n",
        "        if self.model is None:\n",
        "            raise ValueError(\"Model is nog niet getraind.\")\n",
        "        if model_name is None:\n",
        "            timestamp = time.strftime(\"%Y%m%d-%H%M%S\")\n",
        "            model_name = f\"warlords_ppo_model_{timestamp}\"\n",
        "        self.model.save(model_name)\n",
        "        print(f\"Model opgeslagen als {model_name}\")\n",
        "\n",
        "    def load(self, path):\n",
        "        \"\"\"\n",
        "        Laad een eerder getraind PPO-model.\n",
        "        \"\"\"\n",
        "        self.model = PPO.load(path)\n",
        "        print(f\"Model geladen van {path}\")\n",
        "\n",
        "\n",
        "#Bronnen: (PettingZoo Documentation, warlords, z.d.), (PettingZoo Documentation, supersuit_wrappers, z.d.-b), (PPO — Stable Baselines3 2.7.0a0 Documentation, z.d.-b)\n"
      ],
      "metadata": {
        "id": "LatI8v0NC3q8"
      },
      "id": "LatI8v0NC3q8",
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "agent2 = MARLAgentPPO()\n",
        "agent2.train()\n",
        "agent2.save(\"ppo_model_warlords_4m\")\n",
        "save_path = \"/content/drive/MyDrive/MARL_models\"\n",
        "import os\n",
        "\n",
        "\n",
        "os.makedirs(save_path, exist_ok=True)\n",
        "\n",
        "\n",
        "model_name = os.path.join(save_path, \"warlords_ppo_model_4m\")\n",
        "agent2.save(model_name)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "214zLTC8D34j",
        "outputId": "5e17f931-8ef3-4d37-ffee-64a667efc6ef"
      },
      "id": "214zLTC8D34j",
      "execution_count": null,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Start training...\n",
            "Using cuda device\n",
            "Wrapping the env in a VecTransposeImage.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/stable_baselines3/common/vec_env/base_vec_env.py:78: UserWarning: The `render_mode` attribute is not defined in your environment. It will be set to None.\n",
            "  warnings.warn(\"The `render_mode` attribute is not defined in your environment. It will be set to None.\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1;30;43mStreaming output truncated to the last 5000 lines.\u001b[0m\n",
            "|    approx_kl            | 0.0024425047 |\n",
            "|    clip_fraction        | 0.0933       |\n",
            "|    clip_range           | 0.1          |\n",
            "|    entropy_loss         | -1.72        |\n",
            "|    explained_variance   | 0.219        |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | -0.0296      |\n",
            "|    n_updates            | 14516        |\n",
            "|    policy_gradient_loss | -0.00833     |\n",
            "|    value_loss           | 1.77e-05     |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 591          |\n",
            "|    iterations           | 3631         |\n",
            "|    time_elapsed         | 6289         |\n",
            "|    total_timesteps      | 3718144      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0040649907 |\n",
            "|    clip_fraction        | 0.151        |\n",
            "|    clip_range           | 0.1          |\n",
            "|    entropy_loss         | -1.72        |\n",
            "|    explained_variance   | 0.32         |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | -0.0348      |\n",
            "|    n_updates            | 14520        |\n",
            "|    policy_gradient_loss | -0.0115      |\n",
            "|    value_loss           | 7.97e-06     |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 591          |\n",
            "|    iterations           | 3632         |\n",
            "|    time_elapsed         | 6291         |\n",
            "|    total_timesteps      | 3719168      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0022883913 |\n",
            "|    clip_fraction        | 0.0747       |\n",
            "|    clip_range           | 0.1          |\n",
            "|    entropy_loss         | -1.72        |\n",
            "|    explained_variance   | 0.199        |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | -0.0447      |\n",
            "|    n_updates            | 14524        |\n",
            "|    policy_gradient_loss | -0.0103      |\n",
            "|    value_loss           | 5.33e-06     |\n",
            "------------------------------------------\n",
            "----------------------------------------\n",
            "| time/                   |            |\n",
            "|    fps                  | 591        |\n",
            "|    iterations           | 3633       |\n",
            "|    time_elapsed         | 6292       |\n",
            "|    total_timesteps      | 3720192    |\n",
            "| train/                  |            |\n",
            "|    approx_kl            | 0.00407524 |\n",
            "|    clip_fraction        | 0.125      |\n",
            "|    clip_range           | 0.1        |\n",
            "|    entropy_loss         | -1.71      |\n",
            "|    explained_variance   | 0.0202     |\n",
            "|    learning_rate        | 0.00025    |\n",
            "|    loss                 | -0.0389    |\n",
            "|    n_updates            | 14528      |\n",
            "|    policy_gradient_loss | -0.0118    |\n",
            "|    value_loss           | 6.68e-06   |\n",
            "----------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 591         |\n",
            "|    iterations           | 3634        |\n",
            "|    time_elapsed         | 6294        |\n",
            "|    total_timesteps      | 3721216     |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.005329633 |\n",
            "|    clip_fraction        | 0.156       |\n",
            "|    clip_range           | 0.1         |\n",
            "|    entropy_loss         | -1.72       |\n",
            "|    explained_variance   | 0.0257      |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | -0.0297     |\n",
            "|    n_updates            | 14532       |\n",
            "|    policy_gradient_loss | -0.0128     |\n",
            "|    value_loss           | 5.78e-06    |\n",
            "-----------------------------------------\n",
            "----------------------------------------\n",
            "| time/                   |            |\n",
            "|    fps                  | 591        |\n",
            "|    iterations           | 3635       |\n",
            "|    time_elapsed         | 6295       |\n",
            "|    total_timesteps      | 3722240    |\n",
            "| train/                  |            |\n",
            "|    approx_kl            | 0.00251583 |\n",
            "|    clip_fraction        | 0.0615     |\n",
            "|    clip_range           | 0.1        |\n",
            "|    entropy_loss         | -1.71      |\n",
            "|    explained_variance   | -2.17      |\n",
            "|    learning_rate        | 0.00025    |\n",
            "|    loss                 | -0.043     |\n",
            "|    n_updates            | 14536      |\n",
            "|    policy_gradient_loss | -0.0118    |\n",
            "|    value_loss           | 1.28e-05   |\n",
            "----------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 591         |\n",
            "|    iterations           | 3636        |\n",
            "|    time_elapsed         | 6298        |\n",
            "|    total_timesteps      | 3723264     |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.003879455 |\n",
            "|    clip_fraction        | 0.102       |\n",
            "|    clip_range           | 0.1         |\n",
            "|    entropy_loss         | -1.69       |\n",
            "|    explained_variance   | -0.214      |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | -0.0393     |\n",
            "|    n_updates            | 14540       |\n",
            "|    policy_gradient_loss | -0.00957    |\n",
            "|    value_loss           | 9.75e-06    |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 591         |\n",
            "|    iterations           | 3637        |\n",
            "|    time_elapsed         | 6299        |\n",
            "|    total_timesteps      | 3724288     |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.004752664 |\n",
            "|    clip_fraction        | 0.122       |\n",
            "|    clip_range           | 0.1         |\n",
            "|    entropy_loss         | -1.65       |\n",
            "|    explained_variance   | -7.4        |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | -0.0417     |\n",
            "|    n_updates            | 14544       |\n",
            "|    policy_gradient_loss | -0.0141     |\n",
            "|    value_loss           | 1.62e-05    |\n",
            "-----------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 591          |\n",
            "|    iterations           | 3638         |\n",
            "|    time_elapsed         | 6301         |\n",
            "|    total_timesteps      | 3725312      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0034300694 |\n",
            "|    clip_fraction        | 0.0898       |\n",
            "|    clip_range           | 0.1          |\n",
            "|    entropy_loss         | -1.63        |\n",
            "|    explained_variance   | -2.77        |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | -0.0412      |\n",
            "|    n_updates            | 14548        |\n",
            "|    policy_gradient_loss | -0.0153      |\n",
            "|    value_loss           | 2.24e-05     |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 591          |\n",
            "|    iterations           | 3639         |\n",
            "|    time_elapsed         | 6303         |\n",
            "|    total_timesteps      | 3726336      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0043338197 |\n",
            "|    clip_fraction        | 0.122        |\n",
            "|    clip_range           | 0.1          |\n",
            "|    entropy_loss         | -1.65        |\n",
            "|    explained_variance   | -1.87        |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | -0.045       |\n",
            "|    n_updates            | 14552        |\n",
            "|    policy_gradient_loss | -0.0133      |\n",
            "|    value_loss           | 1.17e-05     |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 591          |\n",
            "|    iterations           | 3640         |\n",
            "|    time_elapsed         | 6304         |\n",
            "|    total_timesteps      | 3727360      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0013662623 |\n",
            "|    clip_fraction        | 0.0649       |\n",
            "|    clip_range           | 0.1          |\n",
            "|    entropy_loss         | -1.68        |\n",
            "|    explained_variance   | -0.000122    |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | -0.00952     |\n",
            "|    n_updates            | 14556        |\n",
            "|    policy_gradient_loss | -0.00158     |\n",
            "|    value_loss           | 0.0169       |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 591          |\n",
            "|    iterations           | 3641         |\n",
            "|    time_elapsed         | 6306         |\n",
            "|    total_timesteps      | 3728384      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0038477068 |\n",
            "|    clip_fraction        | 0.152        |\n",
            "|    clip_range           | 0.1          |\n",
            "|    entropy_loss         | -1.56        |\n",
            "|    explained_variance   | -9           |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | -0.0369      |\n",
            "|    n_updates            | 14560        |\n",
            "|    policy_gradient_loss | -0.0157      |\n",
            "|    value_loss           | 1.99e-05     |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 591          |\n",
            "|    iterations           | 3642         |\n",
            "|    time_elapsed         | 6307         |\n",
            "|    total_timesteps      | 3729408      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0032923755 |\n",
            "|    clip_fraction        | 0.137        |\n",
            "|    clip_range           | 0.1          |\n",
            "|    entropy_loss         | -1.67        |\n",
            "|    explained_variance   | -4.69        |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | -0.0459      |\n",
            "|    n_updates            | 14564        |\n",
            "|    policy_gradient_loss | -0.0125      |\n",
            "|    value_loss           | 1.51e-05     |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 591          |\n",
            "|    iterations           | 3643         |\n",
            "|    time_elapsed         | 6309         |\n",
            "|    total_timesteps      | 3730432      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0042750156 |\n",
            "|    clip_fraction        | 0.132        |\n",
            "|    clip_range           | 0.1          |\n",
            "|    entropy_loss         | -1.66        |\n",
            "|    explained_variance   | -22          |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | -0.0434      |\n",
            "|    n_updates            | 14568        |\n",
            "|    policy_gradient_loss | -0.0127      |\n",
            "|    value_loss           | 7.54e-06     |\n",
            "------------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 591         |\n",
            "|    iterations           | 3644        |\n",
            "|    time_elapsed         | 6312        |\n",
            "|    total_timesteps      | 3731456     |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.004222627 |\n",
            "|    clip_fraction        | 0.109       |\n",
            "|    clip_range           | 0.1         |\n",
            "|    entropy_loss         | -1.66       |\n",
            "|    explained_variance   | -10.4       |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | -0.0411     |\n",
            "|    n_updates            | 14572       |\n",
            "|    policy_gradient_loss | -0.0076     |\n",
            "|    value_loss           | 5.56e-06    |\n",
            "-----------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 591          |\n",
            "|    iterations           | 3645         |\n",
            "|    time_elapsed         | 6313         |\n",
            "|    total_timesteps      | 3732480      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0026938242 |\n",
            "|    clip_fraction        | 0.115        |\n",
            "|    clip_range           | 0.1          |\n",
            "|    entropy_loss         | -1.7         |\n",
            "|    explained_variance   | -7.9         |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | -0.0329      |\n",
            "|    n_updates            | 14576        |\n",
            "|    policy_gradient_loss | -0.00963     |\n",
            "|    value_loss           | 2.24e-06     |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 591          |\n",
            "|    iterations           | 3646         |\n",
            "|    time_elapsed         | 6315         |\n",
            "|    total_timesteps      | 3733504      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0036510227 |\n",
            "|    clip_fraction        | 0.0964       |\n",
            "|    clip_range           | 0.1          |\n",
            "|    entropy_loss         | -1.69        |\n",
            "|    explained_variance   | -4.36        |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | -0.0331      |\n",
            "|    n_updates            | 14580        |\n",
            "|    policy_gradient_loss | -0.00784     |\n",
            "|    value_loss           | 1.98e-06     |\n",
            "------------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 591         |\n",
            "|    iterations           | 3647        |\n",
            "|    time_elapsed         | 6316        |\n",
            "|    total_timesteps      | 3734528     |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.002995336 |\n",
            "|    clip_fraction        | 0.13        |\n",
            "|    clip_range           | 0.1         |\n",
            "|    entropy_loss         | -1.68       |\n",
            "|    explained_variance   | -7.58       |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | -0.0315     |\n",
            "|    n_updates            | 14584       |\n",
            "|    policy_gradient_loss | -0.00801    |\n",
            "|    value_loss           | 1.41e-06    |\n",
            "-----------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 591          |\n",
            "|    iterations           | 3648         |\n",
            "|    time_elapsed         | 6318         |\n",
            "|    total_timesteps      | 3735552      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0021192562 |\n",
            "|    clip_fraction        | 0.0603       |\n",
            "|    clip_range           | 0.1          |\n",
            "|    entropy_loss         | -1.65        |\n",
            "|    explained_variance   | -14.5        |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | -0.0327      |\n",
            "|    n_updates            | 14588        |\n",
            "|    policy_gradient_loss | -0.00803     |\n",
            "|    value_loss           | 4.68e-06     |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 591          |\n",
            "|    iterations           | 3649         |\n",
            "|    time_elapsed         | 6320         |\n",
            "|    total_timesteps      | 3736576      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0036245068 |\n",
            "|    clip_fraction        | 0.114        |\n",
            "|    clip_range           | 0.1          |\n",
            "|    entropy_loss         | -1.68        |\n",
            "|    explained_variance   | -13.9        |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | -0.0393      |\n",
            "|    n_updates            | 14592        |\n",
            "|    policy_gradient_loss | -0.0104      |\n",
            "|    value_loss           | 2.46e-06     |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 591          |\n",
            "|    iterations           | 3650         |\n",
            "|    time_elapsed         | 6321         |\n",
            "|    total_timesteps      | 3737600      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0038721703 |\n",
            "|    clip_fraction        | 0.132        |\n",
            "|    clip_range           | 0.1          |\n",
            "|    entropy_loss         | -1.72        |\n",
            "|    explained_variance   | -4.33        |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | -0.031       |\n",
            "|    n_updates            | 14596        |\n",
            "|    policy_gradient_loss | -0.0081      |\n",
            "|    value_loss           | 1.88e-06     |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 591          |\n",
            "|    iterations           | 3651         |\n",
            "|    time_elapsed         | 6323         |\n",
            "|    total_timesteps      | 3738624      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0028790287 |\n",
            "|    clip_fraction        | 0.0884       |\n",
            "|    clip_range           | 0.1          |\n",
            "|    entropy_loss         | -1.69        |\n",
            "|    explained_variance   | -5.66        |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | -0.0406      |\n",
            "|    n_updates            | 14600        |\n",
            "|    policy_gradient_loss | -0.00777     |\n",
            "|    value_loss           | 3.12e-06     |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 591          |\n",
            "|    iterations           | 3652         |\n",
            "|    time_elapsed         | 6325         |\n",
            "|    total_timesteps      | 3739648      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0034437398 |\n",
            "|    clip_fraction        | 0.0745       |\n",
            "|    clip_range           | 0.1          |\n",
            "|    entropy_loss         | -1.7         |\n",
            "|    explained_variance   | -5.67        |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | -0.033       |\n",
            "|    n_updates            | 14604        |\n",
            "|    policy_gradient_loss | -0.00742     |\n",
            "|    value_loss           | 2.37e-06     |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 591          |\n",
            "|    iterations           | 3653         |\n",
            "|    time_elapsed         | 6327         |\n",
            "|    total_timesteps      | 3740672      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0031259824 |\n",
            "|    clip_fraction        | 0.0796       |\n",
            "|    clip_range           | 0.1          |\n",
            "|    entropy_loss         | -1.66        |\n",
            "|    explained_variance   | -3.61        |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | -0.0406      |\n",
            "|    n_updates            | 14608        |\n",
            "|    policy_gradient_loss | -0.00845     |\n",
            "|    value_loss           | 3.02e-06     |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 591          |\n",
            "|    iterations           | 3654         |\n",
            "|    time_elapsed         | 6328         |\n",
            "|    total_timesteps      | 3741696      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0025226916 |\n",
            "|    clip_fraction        | 0.151        |\n",
            "|    clip_range           | 0.1          |\n",
            "|    entropy_loss         | -1.66        |\n",
            "|    explained_variance   | -2.63        |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | -0.0361      |\n",
            "|    n_updates            | 14612        |\n",
            "|    policy_gradient_loss | -0.00894     |\n",
            "|    value_loss           | 2.4e-06      |\n",
            "------------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 591         |\n",
            "|    iterations           | 3655        |\n",
            "|    time_elapsed         | 6330        |\n",
            "|    total_timesteps      | 3742720     |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.002564635 |\n",
            "|    clip_fraction        | 0.0613      |\n",
            "|    clip_range           | 0.1         |\n",
            "|    entropy_loss         | -1.65       |\n",
            "|    explained_variance   | -16.5       |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | -0.0329     |\n",
            "|    n_updates            | 14616       |\n",
            "|    policy_gradient_loss | -0.00968    |\n",
            "|    value_loss           | 2.96e-06    |\n",
            "-----------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 591          |\n",
            "|    iterations           | 3656         |\n",
            "|    time_elapsed         | 6332         |\n",
            "|    total_timesteps      | 3743744      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0036355618 |\n",
            "|    clip_fraction        | 0.127        |\n",
            "|    clip_range           | 0.1          |\n",
            "|    entropy_loss         | -1.66        |\n",
            "|    explained_variance   | -1.86        |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | -0.0321      |\n",
            "|    n_updates            | 14620        |\n",
            "|    policy_gradient_loss | -0.00821     |\n",
            "|    value_loss           | 2.38e-06     |\n",
            "------------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 591         |\n",
            "|    iterations           | 3657        |\n",
            "|    time_elapsed         | 6333        |\n",
            "|    total_timesteps      | 3744768     |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.002272547 |\n",
            "|    clip_fraction        | 0.131       |\n",
            "|    clip_range           | 0.1         |\n",
            "|    entropy_loss         | -1.66       |\n",
            "|    explained_variance   | -7.44       |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | -0.039      |\n",
            "|    n_updates            | 14624       |\n",
            "|    policy_gradient_loss | -0.00915    |\n",
            "|    value_loss           | 1.82e-06    |\n",
            "-----------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 591          |\n",
            "|    iterations           | 3658         |\n",
            "|    time_elapsed         | 6335         |\n",
            "|    total_timesteps      | 3745792      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0022767917 |\n",
            "|    clip_fraction        | 0.0803       |\n",
            "|    clip_range           | 0.1          |\n",
            "|    entropy_loss         | -1.64        |\n",
            "|    explained_variance   | -9.57        |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | -0.0364      |\n",
            "|    n_updates            | 14628        |\n",
            "|    policy_gradient_loss | -0.00927     |\n",
            "|    value_loss           | 2.67e-06     |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 591          |\n",
            "|    iterations           | 3659         |\n",
            "|    time_elapsed         | 6337         |\n",
            "|    total_timesteps      | 3746816      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0032051555 |\n",
            "|    clip_fraction        | 0.128        |\n",
            "|    clip_range           | 0.1          |\n",
            "|    entropy_loss         | -1.67        |\n",
            "|    explained_variance   | -3.68        |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | -0.033       |\n",
            "|    n_updates            | 14632        |\n",
            "|    policy_gradient_loss | -0.00914     |\n",
            "|    value_loss           | 2.47e-06     |\n",
            "------------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 591         |\n",
            "|    iterations           | 3660        |\n",
            "|    time_elapsed         | 6339        |\n",
            "|    total_timesteps      | 3747840     |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.002393554 |\n",
            "|    clip_fraction        | 0.102       |\n",
            "|    clip_range           | 0.1         |\n",
            "|    entropy_loss         | -1.68       |\n",
            "|    explained_variance   | -10.4       |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | -0.0353     |\n",
            "|    n_updates            | 14636       |\n",
            "|    policy_gradient_loss | -0.00926    |\n",
            "|    value_loss           | 1.94e-06    |\n",
            "-----------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 591          |\n",
            "|    iterations           | 3661         |\n",
            "|    time_elapsed         | 6341         |\n",
            "|    total_timesteps      | 3748864      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0034583476 |\n",
            "|    clip_fraction        | 0.138        |\n",
            "|    clip_range           | 0.1          |\n",
            "|    entropy_loss         | -1.66        |\n",
            "|    explained_variance   | -3.45        |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | -0.0345      |\n",
            "|    n_updates            | 14640        |\n",
            "|    policy_gradient_loss | -0.0115      |\n",
            "|    value_loss           | 3.18e-06     |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 591          |\n",
            "|    iterations           | 3662         |\n",
            "|    time_elapsed         | 6342         |\n",
            "|    total_timesteps      | 3749888      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0034884394 |\n",
            "|    clip_fraction        | 0.154        |\n",
            "|    clip_range           | 0.1          |\n",
            "|    entropy_loss         | -1.63        |\n",
            "|    explained_variance   | -3.12        |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | -0.0378      |\n",
            "|    n_updates            | 14644        |\n",
            "|    policy_gradient_loss | -0.00857     |\n",
            "|    value_loss           | 4.19e-06     |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 591          |\n",
            "|    iterations           | 3663         |\n",
            "|    time_elapsed         | 6344         |\n",
            "|    total_timesteps      | 3750912      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0033049788 |\n",
            "|    clip_fraction        | 0.117        |\n",
            "|    clip_range           | 0.1          |\n",
            "|    entropy_loss         | -1.68        |\n",
            "|    explained_variance   | -0.0021      |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | -0.0235      |\n",
            "|    n_updates            | 14648        |\n",
            "|    policy_gradient_loss | -0.00509     |\n",
            "|    value_loss           | 0.00635      |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 591          |\n",
            "|    iterations           | 3664         |\n",
            "|    time_elapsed         | 6346         |\n",
            "|    total_timesteps      | 3751936      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0041155275 |\n",
            "|    clip_fraction        | 0.13         |\n",
            "|    clip_range           | 0.1          |\n",
            "|    entropy_loss         | -1.69        |\n",
            "|    explained_variance   | 0.422        |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | -0.0386      |\n",
            "|    n_updates            | 14652        |\n",
            "|    policy_gradient_loss | -0.0106      |\n",
            "|    value_loss           | 3.3e-05      |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 591          |\n",
            "|    iterations           | 3665         |\n",
            "|    time_elapsed         | 6347         |\n",
            "|    total_timesteps      | 3752960      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0016842631 |\n",
            "|    clip_fraction        | 0.0298       |\n",
            "|    clip_range           | 0.1          |\n",
            "|    entropy_loss         | -1.71        |\n",
            "|    explained_variance   | 0.0415       |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | -0.0249      |\n",
            "|    n_updates            | 14656        |\n",
            "|    policy_gradient_loss | -0.00428     |\n",
            "|    value_loss           | 0.00785      |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 591          |\n",
            "|    iterations           | 3666         |\n",
            "|    time_elapsed         | 6349         |\n",
            "|    total_timesteps      | 3753984      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0032050773 |\n",
            "|    clip_fraction        | 0.0935       |\n",
            "|    clip_range           | 0.1          |\n",
            "|    entropy_loss         | -1.67        |\n",
            "|    explained_variance   | -2.39        |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | -0.021       |\n",
            "|    n_updates            | 14660        |\n",
            "|    policy_gradient_loss | -0.00689     |\n",
            "|    value_loss           | 0.00014      |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 591          |\n",
            "|    iterations           | 3667         |\n",
            "|    time_elapsed         | 6351         |\n",
            "|    total_timesteps      | 3755008      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0029643222 |\n",
            "|    clip_fraction        | 0.082        |\n",
            "|    clip_range           | 0.1          |\n",
            "|    entropy_loss         | -1.73        |\n",
            "|    explained_variance   | 0.101        |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | -0.0285      |\n",
            "|    n_updates            | 14664        |\n",
            "|    policy_gradient_loss | -0.00849     |\n",
            "|    value_loss           | 3.76e-05     |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 591          |\n",
            "|    iterations           | 3668         |\n",
            "|    time_elapsed         | 6353         |\n",
            "|    total_timesteps      | 3756032      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0022626203 |\n",
            "|    clip_fraction        | 0.0898       |\n",
            "|    clip_range           | 0.1          |\n",
            "|    entropy_loss         | -1.72        |\n",
            "|    explained_variance   | -0.147       |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | -0.0375      |\n",
            "|    n_updates            | 14668        |\n",
            "|    policy_gradient_loss | -0.00978     |\n",
            "|    value_loss           | 3.35e-05     |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 591          |\n",
            "|    iterations           | 3669         |\n",
            "|    time_elapsed         | 6355         |\n",
            "|    total_timesteps      | 3757056      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0028756564 |\n",
            "|    clip_fraction        | 0.0789       |\n",
            "|    clip_range           | 0.1          |\n",
            "|    entropy_loss         | -1.73        |\n",
            "|    explained_variance   | 0.233        |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | -0.0409      |\n",
            "|    n_updates            | 14672        |\n",
            "|    policy_gradient_loss | -0.00925     |\n",
            "|    value_loss           | 2.36e-05     |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 591          |\n",
            "|    iterations           | 3670         |\n",
            "|    time_elapsed         | 6356         |\n",
            "|    total_timesteps      | 3758080      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0024154393 |\n",
            "|    clip_fraction        | 0.0688       |\n",
            "|    clip_range           | 0.1          |\n",
            "|    entropy_loss         | -1.68        |\n",
            "|    explained_variance   | -0.00454     |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | -0.019       |\n",
            "|    n_updates            | 14676        |\n",
            "|    policy_gradient_loss | -0.00474     |\n",
            "|    value_loss           | 0.00801      |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 591          |\n",
            "|    iterations           | 3671         |\n",
            "|    time_elapsed         | 6358         |\n",
            "|    total_timesteps      | 3759104      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0029852414 |\n",
            "|    clip_fraction        | 0.0784       |\n",
            "|    clip_range           | 0.1          |\n",
            "|    entropy_loss         | -1.72        |\n",
            "|    explained_variance   | 0.537        |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | -0.0409      |\n",
            "|    n_updates            | 14680        |\n",
            "|    policy_gradient_loss | -0.0102      |\n",
            "|    value_loss           | 5.97e-05     |\n",
            "------------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 591         |\n",
            "|    iterations           | 3672        |\n",
            "|    time_elapsed         | 6359        |\n",
            "|    total_timesteps      | 3760128     |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.004555689 |\n",
            "|    clip_fraction        | 0.206       |\n",
            "|    clip_range           | 0.1         |\n",
            "|    entropy_loss         | -1.72       |\n",
            "|    explained_variance   | 0.473       |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | -0.045      |\n",
            "|    n_updates            | 14684       |\n",
            "|    policy_gradient_loss | -0.0119     |\n",
            "|    value_loss           | 6.16e-05    |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 591         |\n",
            "|    iterations           | 3673        |\n",
            "|    time_elapsed         | 6361        |\n",
            "|    total_timesteps      | 3761152     |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.003067829 |\n",
            "|    clip_fraction        | 0.084       |\n",
            "|    clip_range           | 0.1         |\n",
            "|    entropy_loss         | -1.73       |\n",
            "|    explained_variance   | 0.677       |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | -0.036      |\n",
            "|    n_updates            | 14688       |\n",
            "|    policy_gradient_loss | -0.00967    |\n",
            "|    value_loss           | 2.79e-05    |\n",
            "-----------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 591          |\n",
            "|    iterations           | 3674         |\n",
            "|    time_elapsed         | 6363         |\n",
            "|    total_timesteps      | 3762176      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0013966769 |\n",
            "|    clip_fraction        | 0.0256       |\n",
            "|    clip_range           | 0.1          |\n",
            "|    entropy_loss         | -1.72        |\n",
            "|    explained_variance   | 0.565        |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | -0.0299      |\n",
            "|    n_updates            | 14692        |\n",
            "|    policy_gradient_loss | -0.00665     |\n",
            "|    value_loss           | 2.76e-05     |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 591          |\n",
            "|    iterations           | 3675         |\n",
            "|    time_elapsed         | 6365         |\n",
            "|    total_timesteps      | 3763200      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0038530377 |\n",
            "|    clip_fraction        | 0.104        |\n",
            "|    clip_range           | 0.1          |\n",
            "|    entropy_loss         | -1.73        |\n",
            "|    explained_variance   | 0.694        |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | -0.0303      |\n",
            "|    n_updates            | 14696        |\n",
            "|    policy_gradient_loss | -0.0094      |\n",
            "|    value_loss           | 1.6e-05      |\n",
            "------------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 591         |\n",
            "|    iterations           | 3676        |\n",
            "|    time_elapsed         | 6367        |\n",
            "|    total_timesteps      | 3764224     |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.002537118 |\n",
            "|    clip_fraction        | 0.0427      |\n",
            "|    clip_range           | 0.1         |\n",
            "|    entropy_loss         | -1.7        |\n",
            "|    explained_variance   | 0.646       |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | -0.0387     |\n",
            "|    n_updates            | 14700       |\n",
            "|    policy_gradient_loss | -0.00933    |\n",
            "|    value_loss           | 1.62e-05    |\n",
            "-----------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 591          |\n",
            "|    iterations           | 3677         |\n",
            "|    time_elapsed         | 6368         |\n",
            "|    total_timesteps      | 3765248      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0019014702 |\n",
            "|    clip_fraction        | 0.0459       |\n",
            "|    clip_range           | 0.1          |\n",
            "|    entropy_loss         | -1.7         |\n",
            "|    explained_variance   | 0.567        |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | -0.0364      |\n",
            "|    n_updates            | 14704        |\n",
            "|    policy_gradient_loss | -0.0106      |\n",
            "|    value_loss           | 1.84e-05     |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 591          |\n",
            "|    iterations           | 3678         |\n",
            "|    time_elapsed         | 6370         |\n",
            "|    total_timesteps      | 3766272      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0017272562 |\n",
            "|    clip_fraction        | 0.0542       |\n",
            "|    clip_range           | 0.1          |\n",
            "|    entropy_loss         | -1.73        |\n",
            "|    explained_variance   | 0.658        |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | -0.0373      |\n",
            "|    n_updates            | 14708        |\n",
            "|    policy_gradient_loss | -0.00984     |\n",
            "|    value_loss           | 1.16e-05     |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 591          |\n",
            "|    iterations           | 3679         |\n",
            "|    time_elapsed         | 6371         |\n",
            "|    total_timesteps      | 3767296      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0024606453 |\n",
            "|    clip_fraction        | 0.0322       |\n",
            "|    clip_range           | 0.1          |\n",
            "|    entropy_loss         | -1.7         |\n",
            "|    explained_variance   | 0.0195       |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | -0.0196      |\n",
            "|    n_updates            | 14712        |\n",
            "|    policy_gradient_loss | -0.00154     |\n",
            "|    value_loss           | 0.00476      |\n",
            "------------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 591         |\n",
            "|    iterations           | 3680        |\n",
            "|    time_elapsed         | 6373        |\n",
            "|    total_timesteps      | 3768320     |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.001981824 |\n",
            "|    clip_fraction        | 0.0754      |\n",
            "|    clip_range           | 0.1         |\n",
            "|    entropy_loss         | -1.67       |\n",
            "|    explained_variance   | 5.1e-05     |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | -0.0196     |\n",
            "|    n_updates            | 14716       |\n",
            "|    policy_gradient_loss | -0.00584    |\n",
            "|    value_loss           | 0.017       |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 591         |\n",
            "|    iterations           | 3681        |\n",
            "|    time_elapsed         | 6374        |\n",
            "|    total_timesteps      | 3769344     |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.005217725 |\n",
            "|    clip_fraction        | 0.125       |\n",
            "|    clip_range           | 0.1         |\n",
            "|    entropy_loss         | -1.6        |\n",
            "|    explained_variance   | -0.897      |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | -0.043      |\n",
            "|    n_updates            | 14720       |\n",
            "|    policy_gradient_loss | -0.0166     |\n",
            "|    value_loss           | 4.26e-05    |\n",
            "-----------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 591          |\n",
            "|    iterations           | 3682         |\n",
            "|    time_elapsed         | 6377         |\n",
            "|    total_timesteps      | 3770368      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0027747515 |\n",
            "|    clip_fraction        | 0.0823       |\n",
            "|    clip_range           | 0.1          |\n",
            "|    entropy_loss         | -1.62        |\n",
            "|    explained_variance   | -1.44        |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | -0.038       |\n",
            "|    n_updates            | 14724        |\n",
            "|    policy_gradient_loss | -0.0102      |\n",
            "|    value_loss           | 2.47e-05     |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 591          |\n",
            "|    iterations           | 3683         |\n",
            "|    time_elapsed         | 6379         |\n",
            "|    total_timesteps      | 3771392      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0026800523 |\n",
            "|    clip_fraction        | 0.0674       |\n",
            "|    clip_range           | 0.1          |\n",
            "|    entropy_loss         | -1.66        |\n",
            "|    explained_variance   | 0.283        |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | -0.0443      |\n",
            "|    n_updates            | 14728        |\n",
            "|    policy_gradient_loss | -0.011       |\n",
            "|    value_loss           | 1.13e-05     |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 591          |\n",
            "|    iterations           | 3684         |\n",
            "|    time_elapsed         | 6380         |\n",
            "|    total_timesteps      | 3772416      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0028254718 |\n",
            "|    clip_fraction        | 0.0969       |\n",
            "|    clip_range           | 0.1          |\n",
            "|    entropy_loss         | -1.67        |\n",
            "|    explained_variance   | -1.15        |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | -0.0445      |\n",
            "|    n_updates            | 14732        |\n",
            "|    policy_gradient_loss | -0.0134      |\n",
            "|    value_loss           | 2.31e-05     |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 591          |\n",
            "|    iterations           | 3685         |\n",
            "|    time_elapsed         | 6382         |\n",
            "|    total_timesteps      | 3773440      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0036416063 |\n",
            "|    clip_fraction        | 0.0852       |\n",
            "|    clip_range           | 0.1          |\n",
            "|    entropy_loss         | -1.67        |\n",
            "|    explained_variance   | -1.45        |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | -0.0403      |\n",
            "|    n_updates            | 14736        |\n",
            "|    policy_gradient_loss | -0.0148      |\n",
            "|    value_loss           | 1.44e-05     |\n",
            "------------------------------------------\n",
            "----------------------------------------\n",
            "| time/                   |            |\n",
            "|    fps                  | 591        |\n",
            "|    iterations           | 3686       |\n",
            "|    time_elapsed         | 6383       |\n",
            "|    total_timesteps      | 3774464    |\n",
            "| train/                  |            |\n",
            "|    approx_kl            | 0.00382066 |\n",
            "|    clip_fraction        | 0.111      |\n",
            "|    clip_range           | 0.1        |\n",
            "|    entropy_loss         | -1.63      |\n",
            "|    explained_variance   | -2.52      |\n",
            "|    learning_rate        | 0.00025    |\n",
            "|    loss                 | -0.0434    |\n",
            "|    n_updates            | 14740      |\n",
            "|    policy_gradient_loss | -0.0166    |\n",
            "|    value_loss           | 1.93e-05   |\n",
            "----------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 591         |\n",
            "|    iterations           | 3687        |\n",
            "|    time_elapsed         | 6385        |\n",
            "|    total_timesteps      | 3775488     |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.003915878 |\n",
            "|    clip_fraction        | 0.146       |\n",
            "|    clip_range           | 0.1         |\n",
            "|    entropy_loss         | -1.6        |\n",
            "|    explained_variance   | -2.61       |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | -0.0417     |\n",
            "|    n_updates            | 14744       |\n",
            "|    policy_gradient_loss | -0.0129     |\n",
            "|    value_loss           | 1.24e-05    |\n",
            "-----------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 591          |\n",
            "|    iterations           | 3688         |\n",
            "|    time_elapsed         | 6386         |\n",
            "|    total_timesteps      | 3776512      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0032900716 |\n",
            "|    clip_fraction        | 0.084        |\n",
            "|    clip_range           | 0.1          |\n",
            "|    entropy_loss         | -1.65        |\n",
            "|    explained_variance   | -1.76        |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | -0.0463      |\n",
            "|    n_updates            | 14748        |\n",
            "|    policy_gradient_loss | -0.0152      |\n",
            "|    value_loss           | 1.41e-05     |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 591          |\n",
            "|    iterations           | 3689         |\n",
            "|    time_elapsed         | 6388         |\n",
            "|    total_timesteps      | 3777536      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0039001158 |\n",
            "|    clip_fraction        | 0.112        |\n",
            "|    clip_range           | 0.1          |\n",
            "|    entropy_loss         | -1.57        |\n",
            "|    explained_variance   | -3.06        |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | -0.0453      |\n",
            "|    n_updates            | 14752        |\n",
            "|    policy_gradient_loss | -0.0164      |\n",
            "|    value_loss           | 2.27e-05     |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 591          |\n",
            "|    iterations           | 3690         |\n",
            "|    time_elapsed         | 6391         |\n",
            "|    total_timesteps      | 3778560      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0030641167 |\n",
            "|    clip_fraction        | 0.0994       |\n",
            "|    clip_range           | 0.1          |\n",
            "|    entropy_loss         | -1.63        |\n",
            "|    explained_variance   | -1.67        |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | -0.0465      |\n",
            "|    n_updates            | 14756        |\n",
            "|    policy_gradient_loss | -0.0144      |\n",
            "|    value_loss           | 1.1e-05      |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 591          |\n",
            "|    iterations           | 3691         |\n",
            "|    time_elapsed         | 6392         |\n",
            "|    total_timesteps      | 3779584      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0035326136 |\n",
            "|    clip_fraction        | 0.0869       |\n",
            "|    clip_range           | 0.1          |\n",
            "|    entropy_loss         | -1.63        |\n",
            "|    explained_variance   | -0.949       |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | -0.0449      |\n",
            "|    n_updates            | 14760        |\n",
            "|    policy_gradient_loss | -0.0118      |\n",
            "|    value_loss           | 1.05e-05     |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 591          |\n",
            "|    iterations           | 3692         |\n",
            "|    time_elapsed         | 6394         |\n",
            "|    total_timesteps      | 3780608      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0044664564 |\n",
            "|    clip_fraction        | 0.107        |\n",
            "|    clip_range           | 0.1          |\n",
            "|    entropy_loss         | -1.64        |\n",
            "|    explained_variance   | -2.5         |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | -0.0393      |\n",
            "|    n_updates            | 14764        |\n",
            "|    policy_gradient_loss | -0.0133      |\n",
            "|    value_loss           | 7.92e-06     |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 591          |\n",
            "|    iterations           | 3693         |\n",
            "|    time_elapsed         | 6395         |\n",
            "|    total_timesteps      | 3781632      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0035963913 |\n",
            "|    clip_fraction        | 0.122        |\n",
            "|    clip_range           | 0.1          |\n",
            "|    entropy_loss         | -1.66        |\n",
            "|    explained_variance   | -0.452       |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | -0.0394      |\n",
            "|    n_updates            | 14768        |\n",
            "|    policy_gradient_loss | -0.0122      |\n",
            "|    value_loss           | 4.87e-06     |\n",
            "------------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 591         |\n",
            "|    iterations           | 3694        |\n",
            "|    time_elapsed         | 6397        |\n",
            "|    total_timesteps      | 3782656     |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.003268447 |\n",
            "|    clip_fraction        | 0.108       |\n",
            "|    clip_range           | 0.1         |\n",
            "|    entropy_loss         | -1.66       |\n",
            "|    explained_variance   | -0.67       |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | -0.039      |\n",
            "|    n_updates            | 14772       |\n",
            "|    policy_gradient_loss | -0.0128     |\n",
            "|    value_loss           | 4.85e-06    |\n",
            "-----------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 591          |\n",
            "|    iterations           | 3695         |\n",
            "|    time_elapsed         | 6398         |\n",
            "|    total_timesteps      | 3783680      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0032764059 |\n",
            "|    clip_fraction        | 0.0754       |\n",
            "|    clip_range           | 0.1          |\n",
            "|    entropy_loss         | -1.64        |\n",
            "|    explained_variance   | -0.00716     |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | -0.023       |\n",
            "|    n_updates            | 14776        |\n",
            "|    policy_gradient_loss | -0.00779     |\n",
            "|    value_loss           | 0.00808      |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 591          |\n",
            "|    iterations           | 3696         |\n",
            "|    time_elapsed         | 6400         |\n",
            "|    total_timesteps      | 3784704      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0037332273 |\n",
            "|    clip_fraction        | 0.0896       |\n",
            "|    clip_range           | 0.1          |\n",
            "|    entropy_loss         | -1.69        |\n",
            "|    explained_variance   | -0.704       |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | -0.0328      |\n",
            "|    n_updates            | 14780        |\n",
            "|    policy_gradient_loss | -0.0128      |\n",
            "|    value_loss           | 0.000171     |\n",
            "------------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 591         |\n",
            "|    iterations           | 3697        |\n",
            "|    time_elapsed         | 6402        |\n",
            "|    total_timesteps      | 3785728     |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.004925601 |\n",
            "|    clip_fraction        | 0.123       |\n",
            "|    clip_range           | 0.1         |\n",
            "|    entropy_loss         | -1.63       |\n",
            "|    explained_variance   | -0.216      |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | -0.0515     |\n",
            "|    n_updates            | 14784       |\n",
            "|    policy_gradient_loss | -0.0129     |\n",
            "|    value_loss           | 9.11e-05    |\n",
            "-----------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 591          |\n",
            "|    iterations           | 3698         |\n",
            "|    time_elapsed         | 6404         |\n",
            "|    total_timesteps      | 3786752      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0038130525 |\n",
            "|    clip_fraction        | 0.138        |\n",
            "|    clip_range           | 0.1          |\n",
            "|    entropy_loss         | -1.64        |\n",
            "|    explained_variance   | 0.366        |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | -0.0447      |\n",
            "|    n_updates            | 14788        |\n",
            "|    policy_gradient_loss | -0.0145      |\n",
            "|    value_loss           | 3.46e-05     |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 591          |\n",
            "|    iterations           | 3699         |\n",
            "|    time_elapsed         | 6406         |\n",
            "|    total_timesteps      | 3787776      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0035749879 |\n",
            "|    clip_fraction        | 0.107        |\n",
            "|    clip_range           | 0.1          |\n",
            "|    entropy_loss         | -1.64        |\n",
            "|    explained_variance   | 0.214        |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | -0.0429      |\n",
            "|    n_updates            | 14792        |\n",
            "|    policy_gradient_loss | -0.0141      |\n",
            "|    value_loss           | 3.2e-05      |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 591          |\n",
            "|    iterations           | 3700         |\n",
            "|    time_elapsed         | 6407         |\n",
            "|    total_timesteps      | 3788800      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0038328604 |\n",
            "|    clip_fraction        | 0.102        |\n",
            "|    clip_range           | 0.1          |\n",
            "|    entropy_loss         | -1.67        |\n",
            "|    explained_variance   | 0.333        |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | -0.0471      |\n",
            "|    n_updates            | 14796        |\n",
            "|    policy_gradient_loss | -0.0157      |\n",
            "|    value_loss           | 1.79e-05     |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 591          |\n",
            "|    iterations           | 3701         |\n",
            "|    time_elapsed         | 6409         |\n",
            "|    total_timesteps      | 3789824      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0024075597 |\n",
            "|    clip_fraction        | 0.0352       |\n",
            "|    clip_range           | 0.1          |\n",
            "|    entropy_loss         | -1.61        |\n",
            "|    explained_variance   | -0.000409    |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | -0.015       |\n",
            "|    n_updates            | 14800        |\n",
            "|    policy_gradient_loss | -0.00651     |\n",
            "|    value_loss           | 0.016        |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 591          |\n",
            "|    iterations           | 3702         |\n",
            "|    time_elapsed         | 6411         |\n",
            "|    total_timesteps      | 3790848      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0034060264 |\n",
            "|    clip_fraction        | 0.134        |\n",
            "|    clip_range           | 0.1          |\n",
            "|    entropy_loss         | -1.63        |\n",
            "|    explained_variance   | -0.384       |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | -0.0432      |\n",
            "|    n_updates            | 14804        |\n",
            "|    policy_gradient_loss | -0.0135      |\n",
            "|    value_loss           | 1.33e-05     |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 591          |\n",
            "|    iterations           | 3703         |\n",
            "|    time_elapsed         | 6412         |\n",
            "|    total_timesteps      | 3791872      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0038006378 |\n",
            "|    clip_fraction        | 0.119        |\n",
            "|    clip_range           | 0.1          |\n",
            "|    entropy_loss         | -1.56        |\n",
            "|    explained_variance   | -2.59        |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | -0.0398      |\n",
            "|    n_updates            | 14808        |\n",
            "|    policy_gradient_loss | -0.013       |\n",
            "|    value_loss           | 1.54e-05     |\n",
            "------------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 591         |\n",
            "|    iterations           | 3704        |\n",
            "|    time_elapsed         | 6414        |\n",
            "|    total_timesteps      | 3792896     |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.004375378 |\n",
            "|    clip_fraction        | 0.122       |\n",
            "|    clip_range           | 0.1         |\n",
            "|    entropy_loss         | -1.59       |\n",
            "|    explained_variance   | -3.76       |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | -0.0417     |\n",
            "|    n_updates            | 14812       |\n",
            "|    policy_gradient_loss | -0.0135     |\n",
            "|    value_loss           | 1.98e-05    |\n",
            "-----------------------------------------\n",
            "----------------------------------------\n",
            "| time/                   |            |\n",
            "|    fps                  | 591        |\n",
            "|    iterations           | 3705       |\n",
            "|    time_elapsed         | 6416       |\n",
            "|    total_timesteps      | 3793920    |\n",
            "| train/                  |            |\n",
            "|    approx_kl            | 0.00337967 |\n",
            "|    clip_fraction        | 0.108      |\n",
            "|    clip_range           | 0.1        |\n",
            "|    entropy_loss         | -1.58      |\n",
            "|    explained_variance   | -1.6       |\n",
            "|    learning_rate        | 0.00025    |\n",
            "|    loss                 | -0.0385    |\n",
            "|    n_updates            | 14816      |\n",
            "|    policy_gradient_loss | -0.0113    |\n",
            "|    value_loss           | 1.22e-05   |\n",
            "----------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 591          |\n",
            "|    iterations           | 3706         |\n",
            "|    time_elapsed         | 6418         |\n",
            "|    total_timesteps      | 3794944      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0038277633 |\n",
            "|    clip_fraction        | 0.129        |\n",
            "|    clip_range           | 0.1          |\n",
            "|    entropy_loss         | -1.52        |\n",
            "|    explained_variance   | -2.27        |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | -0.0394      |\n",
            "|    n_updates            | 14820        |\n",
            "|    policy_gradient_loss | -0.014       |\n",
            "|    value_loss           | 1.33e-05     |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 591          |\n",
            "|    iterations           | 3707         |\n",
            "|    time_elapsed         | 6420         |\n",
            "|    total_timesteps      | 3795968      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0027453615 |\n",
            "|    clip_fraction        | 0.131        |\n",
            "|    clip_range           | 0.1          |\n",
            "|    entropy_loss         | -1.59        |\n",
            "|    explained_variance   | -3.41        |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | -0.0378      |\n",
            "|    n_updates            | 14824        |\n",
            "|    policy_gradient_loss | -0.014       |\n",
            "|    value_loss           | 1.28e-05     |\n",
            "------------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 591         |\n",
            "|    iterations           | 3708        |\n",
            "|    time_elapsed         | 6421        |\n",
            "|    total_timesteps      | 3796992     |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.004946589 |\n",
            "|    clip_fraction        | 0.14        |\n",
            "|    clip_range           | 0.1         |\n",
            "|    entropy_loss         | -1.58       |\n",
            "|    explained_variance   | -1.09       |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | -0.0315     |\n",
            "|    n_updates            | 14828       |\n",
            "|    policy_gradient_loss | -0.0122     |\n",
            "|    value_loss           | 8.72e-06    |\n",
            "-----------------------------------------\n",
            "----------------------------------------\n",
            "| time/                   |            |\n",
            "|    fps                  | 591        |\n",
            "|    iterations           | 3709       |\n",
            "|    time_elapsed         | 6423       |\n",
            "|    total_timesteps      | 3798016    |\n",
            "| train/                  |            |\n",
            "|    approx_kl            | 0.00485449 |\n",
            "|    clip_fraction        | 0.129      |\n",
            "|    clip_range           | 0.1        |\n",
            "|    entropy_loss         | -1.5       |\n",
            "|    explained_variance   | -1.48      |\n",
            "|    learning_rate        | 0.00025    |\n",
            "|    loss                 | -0.0456    |\n",
            "|    n_updates            | 14832      |\n",
            "|    policy_gradient_loss | -0.0142    |\n",
            "|    value_loss           | 1.21e-05   |\n",
            "----------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 591          |\n",
            "|    iterations           | 3710         |\n",
            "|    time_elapsed         | 6424         |\n",
            "|    total_timesteps      | 3799040      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0039430093 |\n",
            "|    clip_fraction        | 0.114        |\n",
            "|    clip_range           | 0.1          |\n",
            "|    entropy_loss         | -1.53        |\n",
            "|    explained_variance   | -1.79        |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | -0.0398      |\n",
            "|    n_updates            | 14836        |\n",
            "|    policy_gradient_loss | -0.0132      |\n",
            "|    value_loss           | 9.03e-06     |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 591          |\n",
            "|    iterations           | 3711         |\n",
            "|    time_elapsed         | 6426         |\n",
            "|    total_timesteps      | 3800064      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0048022103 |\n",
            "|    clip_fraction        | 0.152        |\n",
            "|    clip_range           | 0.1          |\n",
            "|    entropy_loss         | -1.56        |\n",
            "|    explained_variance   | -2.04        |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | -0.0468      |\n",
            "|    n_updates            | 14840        |\n",
            "|    policy_gradient_loss | -0.0153      |\n",
            "|    value_loss           | 9.61e-06     |\n",
            "------------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 591         |\n",
            "|    iterations           | 3712        |\n",
            "|    time_elapsed         | 6428        |\n",
            "|    total_timesteps      | 3801088     |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.003417424 |\n",
            "|    clip_fraction        | 0.156       |\n",
            "|    clip_range           | 0.1         |\n",
            "|    entropy_loss         | -1.51       |\n",
            "|    explained_variance   | -2.61       |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | -0.0407     |\n",
            "|    n_updates            | 14844       |\n",
            "|    policy_gradient_loss | -0.0132     |\n",
            "|    value_loss           | 9.47e-06    |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 591         |\n",
            "|    iterations           | 3713        |\n",
            "|    time_elapsed         | 6430        |\n",
            "|    total_timesteps      | 3802112     |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.004121621 |\n",
            "|    clip_fraction        | 0.115       |\n",
            "|    clip_range           | 0.1         |\n",
            "|    entropy_loss         | -1.6        |\n",
            "|    explained_variance   | -1.91       |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | -0.0389     |\n",
            "|    n_updates            | 14848       |\n",
            "|    policy_gradient_loss | -0.0142     |\n",
            "|    value_loss           | 7.83e-06    |\n",
            "-----------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 591          |\n",
            "|    iterations           | 3714         |\n",
            "|    time_elapsed         | 6432         |\n",
            "|    total_timesteps      | 3803136      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0035496198 |\n",
            "|    clip_fraction        | 0.134        |\n",
            "|    clip_range           | 0.1          |\n",
            "|    entropy_loss         | -1.54        |\n",
            "|    explained_variance   | -1.29        |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | -0.0424      |\n",
            "|    n_updates            | 14852        |\n",
            "|    policy_gradient_loss | -0.0145      |\n",
            "|    value_loss           | 8.22e-06     |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 591          |\n",
            "|    iterations           | 3715         |\n",
            "|    time_elapsed         | 6434         |\n",
            "|    total_timesteps      | 3804160      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0026232991 |\n",
            "|    clip_fraction        | 0.0923       |\n",
            "|    clip_range           | 0.1          |\n",
            "|    entropy_loss         | -1.57        |\n",
            "|    explained_variance   | 0.000696     |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | -0.0249      |\n",
            "|    n_updates            | 14856        |\n",
            "|    policy_gradient_loss | -0.00889     |\n",
            "|    value_loss           | 0.0156       |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 591          |\n",
            "|    iterations           | 3716         |\n",
            "|    time_elapsed         | 6435         |\n",
            "|    total_timesteps      | 3805184      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0028547223 |\n",
            "|    clip_fraction        | 0.0879       |\n",
            "|    clip_range           | 0.1          |\n",
            "|    entropy_loss         | -1.65        |\n",
            "|    explained_variance   | -0.22        |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | -0.0383      |\n",
            "|    n_updates            | 14860        |\n",
            "|    policy_gradient_loss | -0.00965     |\n",
            "|    value_loss           | 0.000282     |\n",
            "------------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 591         |\n",
            "|    iterations           | 3717        |\n",
            "|    time_elapsed         | 6437        |\n",
            "|    total_timesteps      | 3806208     |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.002580984 |\n",
            "|    clip_fraction        | 0.0588      |\n",
            "|    clip_range           | 0.1         |\n",
            "|    entropy_loss         | -1.62       |\n",
            "|    explained_variance   | 0.0503      |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | -0.0357     |\n",
            "|    n_updates            | 14864       |\n",
            "|    policy_gradient_loss | -0.0106     |\n",
            "|    value_loss           | 9.89e-05    |\n",
            "-----------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 591          |\n",
            "|    iterations           | 3718         |\n",
            "|    time_elapsed         | 6438         |\n",
            "|    total_timesteps      | 3807232      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0032886507 |\n",
            "|    clip_fraction        | 0.0625       |\n",
            "|    clip_range           | 0.1          |\n",
            "|    entropy_loss         | -1.57        |\n",
            "|    explained_variance   | -0.000315    |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | -0.016       |\n",
            "|    n_updates            | 14868        |\n",
            "|    policy_gradient_loss | -0.00614     |\n",
            "|    value_loss           | 0.017        |\n",
            "------------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 591         |\n",
            "|    iterations           | 3719        |\n",
            "|    time_elapsed         | 6440        |\n",
            "|    total_timesteps      | 3808256     |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.005335287 |\n",
            "|    clip_fraction        | 0.123       |\n",
            "|    clip_range           | 0.1         |\n",
            "|    entropy_loss         | -1.59       |\n",
            "|    explained_variance   | -0.508      |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | -0.0454     |\n",
            "|    n_updates            | 14872       |\n",
            "|    policy_gradient_loss | -0.0152     |\n",
            "|    value_loss           | 5.97e-05    |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 591         |\n",
            "|    iterations           | 3720        |\n",
            "|    time_elapsed         | 6442        |\n",
            "|    total_timesteps      | 3809280     |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.005443939 |\n",
            "|    clip_fraction        | 0.141       |\n",
            "|    clip_range           | 0.1         |\n",
            "|    entropy_loss         | -1.49       |\n",
            "|    explained_variance   | -0.0925     |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | -0.0422     |\n",
            "|    n_updates            | 14876       |\n",
            "|    policy_gradient_loss | -0.0155     |\n",
            "|    value_loss           | 4.48e-05    |\n",
            "-----------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 591          |\n",
            "|    iterations           | 3721         |\n",
            "|    time_elapsed         | 6444         |\n",
            "|    total_timesteps      | 3810304      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0042459248 |\n",
            "|    clip_fraction        | 0.14         |\n",
            "|    clip_range           | 0.1          |\n",
            "|    entropy_loss         | -1.56        |\n",
            "|    explained_variance   | -1.43        |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | -0.0286      |\n",
            "|    n_updates            | 14880        |\n",
            "|    policy_gradient_loss | -0.0122      |\n",
            "|    value_loss           | 4.89e-05     |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 591          |\n",
            "|    iterations           | 3722         |\n",
            "|    time_elapsed         | 6446         |\n",
            "|    total_timesteps      | 3811328      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0046503525 |\n",
            "|    clip_fraction        | 0.164        |\n",
            "|    clip_range           | 0.1          |\n",
            "|    entropy_loss         | -1.62        |\n",
            "|    explained_variance   | -0.408       |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | -0.0414      |\n",
            "|    n_updates            | 14884        |\n",
            "|    policy_gradient_loss | -0.0151      |\n",
            "|    value_loss           | 2.61e-05     |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 591          |\n",
            "|    iterations           | 3723         |\n",
            "|    time_elapsed         | 6447         |\n",
            "|    total_timesteps      | 3812352      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0036053564 |\n",
            "|    clip_fraction        | 0.158        |\n",
            "|    clip_range           | 0.1          |\n",
            "|    entropy_loss         | -1.59        |\n",
            "|    explained_variance   | -0.783       |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | -0.0411      |\n",
            "|    n_updates            | 14888        |\n",
            "|    policy_gradient_loss | -0.0108      |\n",
            "|    value_loss           | 2.46e-05     |\n",
            "------------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 591         |\n",
            "|    iterations           | 3724        |\n",
            "|    time_elapsed         | 6449        |\n",
            "|    total_timesteps      | 3813376     |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.003303762 |\n",
            "|    clip_fraction        | 0.152       |\n",
            "|    clip_range           | 0.1         |\n",
            "|    entropy_loss         | -1.57       |\n",
            "|    explained_variance   | -1.85       |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | -0.0426     |\n",
            "|    n_updates            | 14892       |\n",
            "|    policy_gradient_loss | -0.0119     |\n",
            "|    value_loss           | 1.98e-05    |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 591         |\n",
            "|    iterations           | 3725        |\n",
            "|    time_elapsed         | 6450        |\n",
            "|    total_timesteps      | 3814400     |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.002426661 |\n",
            "|    clip_fraction        | 0.111       |\n",
            "|    clip_range           | 0.1         |\n",
            "|    entropy_loss         | -1.62       |\n",
            "|    explained_variance   | -0.923      |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | -0.0414     |\n",
            "|    n_updates            | 14896       |\n",
            "|    policy_gradient_loss | -0.0109     |\n",
            "|    value_loss           | 8.68e-06    |\n",
            "-----------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 591          |\n",
            "|    iterations           | 3726         |\n",
            "|    time_elapsed         | 6452         |\n",
            "|    total_timesteps      | 3815424      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0043679485 |\n",
            "|    clip_fraction        | 0.158        |\n",
            "|    clip_range           | 0.1          |\n",
            "|    entropy_loss         | -1.57        |\n",
            "|    explained_variance   | -0.743       |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | -0.0337      |\n",
            "|    n_updates            | 14900        |\n",
            "|    policy_gradient_loss | -0.0128      |\n",
            "|    value_loss           | 1.05e-05     |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 591          |\n",
            "|    iterations           | 3727         |\n",
            "|    time_elapsed         | 6454         |\n",
            "|    total_timesteps      | 3816448      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0042780573 |\n",
            "|    clip_fraction        | 0.159        |\n",
            "|    clip_range           | 0.1          |\n",
            "|    entropy_loss         | -1.61        |\n",
            "|    explained_variance   | -1.94        |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | -0.0483      |\n",
            "|    n_updates            | 14904        |\n",
            "|    policy_gradient_loss | -0.0144      |\n",
            "|    value_loss           | 1.09e-05     |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 591          |\n",
            "|    iterations           | 3728         |\n",
            "|    time_elapsed         | 6456         |\n",
            "|    total_timesteps      | 3817472      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0033126534 |\n",
            "|    clip_fraction        | 0.126        |\n",
            "|    clip_range           | 0.1          |\n",
            "|    entropy_loss         | -1.53        |\n",
            "|    explained_variance   | -5.14        |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | -0.0443      |\n",
            "|    n_updates            | 14908        |\n",
            "|    policy_gradient_loss | -0.015       |\n",
            "|    value_loss           | 1.11e-05     |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 591          |\n",
            "|    iterations           | 3729         |\n",
            "|    time_elapsed         | 6458         |\n",
            "|    total_timesteps      | 3818496      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0042534703 |\n",
            "|    clip_fraction        | 0.15         |\n",
            "|    clip_range           | 0.1          |\n",
            "|    entropy_loss         | -1.6         |\n",
            "|    explained_variance   | -2.67        |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | -0.0363      |\n",
            "|    n_updates            | 14912        |\n",
            "|    policy_gradient_loss | -0.0116      |\n",
            "|    value_loss           | 9.38e-06     |\n",
            "------------------------------------------\n",
            "----------------------------------------\n",
            "| time/                   |            |\n",
            "|    fps                  | 591        |\n",
            "|    iterations           | 3730       |\n",
            "|    time_elapsed         | 6459       |\n",
            "|    total_timesteps      | 3819520    |\n",
            "| train/                  |            |\n",
            "|    approx_kl            | 0.00412937 |\n",
            "|    clip_fraction        | 0.132      |\n",
            "|    clip_range           | 0.1        |\n",
            "|    entropy_loss         | -1.58      |\n",
            "|    explained_variance   | -0.807     |\n",
            "|    learning_rate        | 0.00025    |\n",
            "|    loss                 | -0.0455    |\n",
            "|    n_updates            | 14916      |\n",
            "|    policy_gradient_loss | -0.0142    |\n",
            "|    value_loss           | 1.15e-05   |\n",
            "----------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 591          |\n",
            "|    iterations           | 3731         |\n",
            "|    time_elapsed         | 6461         |\n",
            "|    total_timesteps      | 3820544      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0039348714 |\n",
            "|    clip_fraction        | 0.161        |\n",
            "|    clip_range           | 0.1          |\n",
            "|    entropy_loss         | -1.63        |\n",
            "|    explained_variance   | -1.9         |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | -0.0411      |\n",
            "|    n_updates            | 14920        |\n",
            "|    policy_gradient_loss | -0.014       |\n",
            "|    value_loss           | 1.06e-05     |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 591          |\n",
            "|    iterations           | 3732         |\n",
            "|    time_elapsed         | 6462         |\n",
            "|    total_timesteps      | 3821568      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0052457973 |\n",
            "|    clip_fraction        | 0.146        |\n",
            "|    clip_range           | 0.1          |\n",
            "|    entropy_loss         | -1.52        |\n",
            "|    explained_variance   | -2.68        |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | -0.0401      |\n",
            "|    n_updates            | 14924        |\n",
            "|    policy_gradient_loss | -0.0119      |\n",
            "|    value_loss           | 1.12e-05     |\n",
            "------------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 591         |\n",
            "|    iterations           | 3733        |\n",
            "|    time_elapsed         | 6464        |\n",
            "|    total_timesteps      | 3822592     |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.003746897 |\n",
            "|    clip_fraction        | 0.136       |\n",
            "|    clip_range           | 0.1         |\n",
            "|    entropy_loss         | -1.62       |\n",
            "|    explained_variance   | -0.625      |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | -0.0379     |\n",
            "|    n_updates            | 14928       |\n",
            "|    policy_gradient_loss | -0.0118     |\n",
            "|    value_loss           | 5.67e-06    |\n",
            "-----------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 591          |\n",
            "|    iterations           | 3734         |\n",
            "|    time_elapsed         | 6466         |\n",
            "|    total_timesteps      | 3823616      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0042958166 |\n",
            "|    clip_fraction        | 0.0706       |\n",
            "|    clip_range           | 0.1          |\n",
            "|    entropy_loss         | -1.62        |\n",
            "|    explained_variance   | 0.00607      |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | -0.0215      |\n",
            "|    n_updates            | 14932        |\n",
            "|    policy_gradient_loss | -0.00427     |\n",
            "|    value_loss           | 0.00527      |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 591          |\n",
            "|    iterations           | 3735         |\n",
            "|    time_elapsed         | 6467         |\n",
            "|    total_timesteps      | 3824640      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0039757583 |\n",
            "|    clip_fraction        | 0.126        |\n",
            "|    clip_range           | 0.1          |\n",
            "|    entropy_loss         | -1.66        |\n",
            "|    explained_variance   | -1.02        |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | -0.0342      |\n",
            "|    n_updates            | 14936        |\n",
            "|    policy_gradient_loss | -0.0114      |\n",
            "|    value_loss           | 0.000154     |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 591          |\n",
            "|    iterations           | 3736         |\n",
            "|    time_elapsed         | 6469         |\n",
            "|    total_timesteps      | 3825664      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0042680944 |\n",
            "|    clip_fraction        | 0.157        |\n",
            "|    clip_range           | 0.1          |\n",
            "|    entropy_loss         | -1.6         |\n",
            "|    explained_variance   | -5.75        |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | -0.0429      |\n",
            "|    n_updates            | 14940        |\n",
            "|    policy_gradient_loss | -0.0131      |\n",
            "|    value_loss           | 7.55e-05     |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 591          |\n",
            "|    iterations           | 3737         |\n",
            "|    time_elapsed         | 6471         |\n",
            "|    total_timesteps      | 3826688      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0038160542 |\n",
            "|    clip_fraction        | 0.0952       |\n",
            "|    clip_range           | 0.1          |\n",
            "|    entropy_loss         | -1.61        |\n",
            "|    explained_variance   | -0.0513      |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | -0.0331      |\n",
            "|    n_updates            | 14944        |\n",
            "|    policy_gradient_loss | -0.00721     |\n",
            "|    value_loss           | 0.001        |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 591          |\n",
            "|    iterations           | 3738         |\n",
            "|    time_elapsed         | 6473         |\n",
            "|    total_timesteps      | 3827712      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0039838282 |\n",
            "|    clip_fraction        | 0.11         |\n",
            "|    clip_range           | 0.1          |\n",
            "|    entropy_loss         | -1.65        |\n",
            "|    explained_variance   | 0.457        |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | -0.0459      |\n",
            "|    n_updates            | 14948        |\n",
            "|    policy_gradient_loss | -0.0132      |\n",
            "|    value_loss           | 4.2e-05      |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 591          |\n",
            "|    iterations           | 3739         |\n",
            "|    time_elapsed         | 6474         |\n",
            "|    total_timesteps      | 3828736      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0023559453 |\n",
            "|    clip_fraction        | 0.0647       |\n",
            "|    clip_range           | 0.1          |\n",
            "|    entropy_loss         | -1.65        |\n",
            "|    explained_variance   | -0.599       |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | -0.0363      |\n",
            "|    n_updates            | 14952        |\n",
            "|    policy_gradient_loss | -0.00996     |\n",
            "|    value_loss           | 7.74e-05     |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 591          |\n",
            "|    iterations           | 3740         |\n",
            "|    time_elapsed         | 6476         |\n",
            "|    total_timesteps      | 3829760      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0038796891 |\n",
            "|    clip_fraction        | 0.115        |\n",
            "|    clip_range           | 0.1          |\n",
            "|    entropy_loss         | -1.68        |\n",
            "|    explained_variance   | -0.778       |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | -0.0316      |\n",
            "|    n_updates            | 14956        |\n",
            "|    policy_gradient_loss | -0.00875     |\n",
            "|    value_loss           | 5.89e-05     |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 591          |\n",
            "|    iterations           | 3741         |\n",
            "|    time_elapsed         | 6477         |\n",
            "|    total_timesteps      | 3830784      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0023077603 |\n",
            "|    clip_fraction        | 0.0701       |\n",
            "|    clip_range           | 0.1          |\n",
            "|    entropy_loss         | -1.68        |\n",
            "|    explained_variance   | 0.0364       |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | -0.0356      |\n",
            "|    n_updates            | 14960        |\n",
            "|    policy_gradient_loss | -0.00989     |\n",
            "|    value_loss           | 1.67e-05     |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 591          |\n",
            "|    iterations           | 3742         |\n",
            "|    time_elapsed         | 6479         |\n",
            "|    total_timesteps      | 3831808      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0020228908 |\n",
            "|    clip_fraction        | 0.0991       |\n",
            "|    clip_range           | 0.1          |\n",
            "|    entropy_loss         | -1.71        |\n",
            "|    explained_variance   | 0.778        |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | -0.0283      |\n",
            "|    n_updates            | 14964        |\n",
            "|    policy_gradient_loss | -0.00797     |\n",
            "|    value_loss           | 4.89e-06     |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 591          |\n",
            "|    iterations           | 3743         |\n",
            "|    time_elapsed         | 6480         |\n",
            "|    total_timesteps      | 3832832      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0044741537 |\n",
            "|    clip_fraction        | 0.111        |\n",
            "|    clip_range           | 0.1          |\n",
            "|    entropy_loss         | -1.68        |\n",
            "|    explained_variance   | 0.415        |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | -0.0334      |\n",
            "|    n_updates            | 14968        |\n",
            "|    policy_gradient_loss | -0.0111      |\n",
            "|    value_loss           | 8.74e-06     |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 591          |\n",
            "|    iterations           | 3744         |\n",
            "|    time_elapsed         | 6483         |\n",
            "|    total_timesteps      | 3833856      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0029005813 |\n",
            "|    clip_fraction        | 0.0688       |\n",
            "|    clip_range           | 0.1          |\n",
            "|    entropy_loss         | -1.67        |\n",
            "|    explained_variance   | -0.884       |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | -0.0229      |\n",
            "|    n_updates            | 14972        |\n",
            "|    policy_gradient_loss | -0.00705     |\n",
            "|    value_loss           | 2.27e-05     |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 591          |\n",
            "|    iterations           | 3745         |\n",
            "|    time_elapsed         | 6484         |\n",
            "|    total_timesteps      | 3834880      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0032215684 |\n",
            "|    clip_fraction        | 0.0815       |\n",
            "|    clip_range           | 0.1          |\n",
            "|    entropy_loss         | -1.66        |\n",
            "|    explained_variance   | -1.07        |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | -0.0381      |\n",
            "|    n_updates            | 14976        |\n",
            "|    policy_gradient_loss | -0.0124      |\n",
            "|    value_loss           | 1.95e-05     |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 591          |\n",
            "|    iterations           | 3746         |\n",
            "|    time_elapsed         | 6486         |\n",
            "|    total_timesteps      | 3835904      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0039727637 |\n",
            "|    clip_fraction        | 0.124        |\n",
            "|    clip_range           | 0.1          |\n",
            "|    entropy_loss         | -1.66        |\n",
            "|    explained_variance   | -0.497       |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | -0.032       |\n",
            "|    n_updates            | 14980        |\n",
            "|    policy_gradient_loss | -0.0115      |\n",
            "|    value_loss           | 1.18e-05     |\n",
            "------------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 591         |\n",
            "|    iterations           | 3747        |\n",
            "|    time_elapsed         | 6487        |\n",
            "|    total_timesteps      | 3836928     |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.004373301 |\n",
            "|    clip_fraction        | 0.122       |\n",
            "|    clip_range           | 0.1         |\n",
            "|    entropy_loss         | -1.68       |\n",
            "|    explained_variance   | -1.5        |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | -0.0358     |\n",
            "|    n_updates            | 14984       |\n",
            "|    policy_gradient_loss | -0.0121     |\n",
            "|    value_loss           | 2.63e-05    |\n",
            "-----------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 591          |\n",
            "|    iterations           | 3748         |\n",
            "|    time_elapsed         | 6489         |\n",
            "|    total_timesteps      | 3837952      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0020464507 |\n",
            "|    clip_fraction        | 0.0354       |\n",
            "|    clip_range           | 0.1          |\n",
            "|    entropy_loss         | -1.66        |\n",
            "|    explained_variance   | -0.00486     |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | -0.0216      |\n",
            "|    n_updates            | 14988        |\n",
            "|    policy_gradient_loss | -0.00844     |\n",
            "|    value_loss           | 0.017        |\n",
            "------------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 591         |\n",
            "|    iterations           | 3749        |\n",
            "|    time_elapsed         | 6490        |\n",
            "|    total_timesteps      | 3838976     |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.003300895 |\n",
            "|    clip_fraction        | 0.0862      |\n",
            "|    clip_range           | 0.1         |\n",
            "|    entropy_loss         | -1.57       |\n",
            "|    explained_variance   | -4.88       |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | -0.0287     |\n",
            "|    n_updates            | 14992       |\n",
            "|    policy_gradient_loss | -0.00901    |\n",
            "|    value_loss           | 2.38e-05    |\n",
            "-----------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 591          |\n",
            "|    iterations           | 3750         |\n",
            "|    time_elapsed         | 6492         |\n",
            "|    total_timesteps      | 3840000      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0032078444 |\n",
            "|    clip_fraction        | 0.0969       |\n",
            "|    clip_range           | 0.1          |\n",
            "|    entropy_loss         | -1.65        |\n",
            "|    explained_variance   | -2.5         |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | -0.0342      |\n",
            "|    n_updates            | 14996        |\n",
            "|    policy_gradient_loss | -0.0111      |\n",
            "|    value_loss           | 9.17e-06     |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 591          |\n",
            "|    iterations           | 3751         |\n",
            "|    time_elapsed         | 6494         |\n",
            "|    total_timesteps      | 3841024      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0017699613 |\n",
            "|    clip_fraction        | 0.0439       |\n",
            "|    clip_range           | 0.1          |\n",
            "|    entropy_loss         | -1.69        |\n",
            "|    explained_variance   | -4.54        |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | -0.0306      |\n",
            "|    n_updates            | 15000        |\n",
            "|    policy_gradient_loss | -0.00833     |\n",
            "|    value_loss           | 7.65e-06     |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 591          |\n",
            "|    iterations           | 3752         |\n",
            "|    time_elapsed         | 6496         |\n",
            "|    total_timesteps      | 3842048      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0031439792 |\n",
            "|    clip_fraction        | 0.157        |\n",
            "|    clip_range           | 0.1          |\n",
            "|    entropy_loss         | -1.66        |\n",
            "|    explained_variance   | -9.05        |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | -0.034       |\n",
            "|    n_updates            | 15004        |\n",
            "|    policy_gradient_loss | -0.0118      |\n",
            "|    value_loss           | 1.11e-05     |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 591          |\n",
            "|    iterations           | 3753         |\n",
            "|    time_elapsed         | 6498         |\n",
            "|    total_timesteps      | 3843072      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0027464938 |\n",
            "|    clip_fraction        | 0.123        |\n",
            "|    clip_range           | 0.1          |\n",
            "|    entropy_loss         | -1.66        |\n",
            "|    explained_variance   | -3.05        |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | -0.0387      |\n",
            "|    n_updates            | 15008        |\n",
            "|    policy_gradient_loss | -0.00852     |\n",
            "|    value_loss           | 9.97e-06     |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 591          |\n",
            "|    iterations           | 3754         |\n",
            "|    time_elapsed         | 6499         |\n",
            "|    total_timesteps      | 3844096      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0035177767 |\n",
            "|    clip_fraction        | 0.144        |\n",
            "|    clip_range           | 0.1          |\n",
            "|    entropy_loss         | -1.58        |\n",
            "|    explained_variance   | -6.02        |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | -0.0432      |\n",
            "|    n_updates            | 15012        |\n",
            "|    policy_gradient_loss | -0.00964     |\n",
            "|    value_loss           | 1.07e-05     |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 591          |\n",
            "|    iterations           | 3755         |\n",
            "|    time_elapsed         | 6501         |\n",
            "|    total_timesteps      | 3845120      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0034807846 |\n",
            "|    clip_fraction        | 0.135        |\n",
            "|    clip_range           | 0.1          |\n",
            "|    entropy_loss         | -1.65        |\n",
            "|    explained_variance   | -4.54        |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | -0.0353      |\n",
            "|    n_updates            | 15016        |\n",
            "|    policy_gradient_loss | -0.011       |\n",
            "|    value_loss           | 6.47e-06     |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 591          |\n",
            "|    iterations           | 3756         |\n",
            "|    time_elapsed         | 6502         |\n",
            "|    total_timesteps      | 3846144      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0037054685 |\n",
            "|    clip_fraction        | 0.164        |\n",
            "|    clip_range           | 0.1          |\n",
            "|    entropy_loss         | -1.66        |\n",
            "|    explained_variance   | 0.00411      |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | -0.0249      |\n",
            "|    n_updates            | 15020        |\n",
            "|    policy_gradient_loss | -0.00694     |\n",
            "|    value_loss           | 0.00774      |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 591          |\n",
            "|    iterations           | 3757         |\n",
            "|    time_elapsed         | 6504         |\n",
            "|    total_timesteps      | 3847168      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0026188984 |\n",
            "|    clip_fraction        | 0.106        |\n",
            "|    clip_range           | 0.1          |\n",
            "|    entropy_loss         | -1.65        |\n",
            "|    explained_variance   | 0.772        |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | -0.0246      |\n",
            "|    n_updates            | 15024        |\n",
            "|    policy_gradient_loss | -0.00849     |\n",
            "|    value_loss           | 7.61e-05     |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 591          |\n",
            "|    iterations           | 3758         |\n",
            "|    time_elapsed         | 6505         |\n",
            "|    total_timesteps      | 3848192      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0018353115 |\n",
            "|    clip_fraction        | 0.145        |\n",
            "|    clip_range           | 0.1          |\n",
            "|    entropy_loss         | -1.67        |\n",
            "|    explained_variance   | 0.52         |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | -0.0406      |\n",
            "|    n_updates            | 15028        |\n",
            "|    policy_gradient_loss | -0.0101      |\n",
            "|    value_loss           | 6.87e-05     |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 591          |\n",
            "|    iterations           | 3759         |\n",
            "|    time_elapsed         | 6507         |\n",
            "|    total_timesteps      | 3849216      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0026786455 |\n",
            "|    clip_fraction        | 0.145        |\n",
            "|    clip_range           | 0.1          |\n",
            "|    entropy_loss         | -1.67        |\n",
            "|    explained_variance   | 0.442        |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | -0.0312      |\n",
            "|    n_updates            | 15032        |\n",
            "|    policy_gradient_loss | -0.00682     |\n",
            "|    value_loss           | 2.83e-05     |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 591          |\n",
            "|    iterations           | 3760         |\n",
            "|    time_elapsed         | 6509         |\n",
            "|    total_timesteps      | 3850240      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0033476704 |\n",
            "|    clip_fraction        | 0.135        |\n",
            "|    clip_range           | 0.1          |\n",
            "|    entropy_loss         | -1.68        |\n",
            "|    explained_variance   | 0.748        |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | -0.0329      |\n",
            "|    n_updates            | 15036        |\n",
            "|    policy_gradient_loss | -0.00718     |\n",
            "|    value_loss           | 1.02e-05     |\n",
            "------------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 591         |\n",
            "|    iterations           | 3761        |\n",
            "|    time_elapsed         | 6511        |\n",
            "|    total_timesteps      | 3851264     |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.003383895 |\n",
            "|    clip_fraction        | 0.0786      |\n",
            "|    clip_range           | 0.1         |\n",
            "|    entropy_loss         | -1.61       |\n",
            "|    explained_variance   | 0.403       |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | -0.0315     |\n",
            "|    n_updates            | 15040       |\n",
            "|    policy_gradient_loss | -0.0108     |\n",
            "|    value_loss           | 1.26e-05    |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 591         |\n",
            "|    iterations           | 3762        |\n",
            "|    time_elapsed         | 6512        |\n",
            "|    total_timesteps      | 3852288     |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.002525625 |\n",
            "|    clip_fraction        | 0.104       |\n",
            "|    clip_range           | 0.1         |\n",
            "|    entropy_loss         | -1.67       |\n",
            "|    explained_variance   | 0.314       |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | -0.0325     |\n",
            "|    n_updates            | 15044       |\n",
            "|    policy_gradient_loss | -0.00815    |\n",
            "|    value_loss           | 1.52e-05    |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 591         |\n",
            "|    iterations           | 3763        |\n",
            "|    time_elapsed         | 6514        |\n",
            "|    total_timesteps      | 3853312     |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.001736975 |\n",
            "|    clip_fraction        | 0.0801      |\n",
            "|    clip_range           | 0.1         |\n",
            "|    entropy_loss         | -1.52       |\n",
            "|    explained_variance   | -0.000655   |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | -0.00509    |\n",
            "|    n_updates            | 15048       |\n",
            "|    policy_gradient_loss | -0.000326   |\n",
            "|    value_loss           | 0.0169      |\n",
            "-----------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 591          |\n",
            "|    iterations           | 3764         |\n",
            "|    time_elapsed         | 6515         |\n",
            "|    total_timesteps      | 3854336      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0021437556 |\n",
            "|    clip_fraction        | 0.102        |\n",
            "|    clip_range           | 0.1          |\n",
            "|    entropy_loss         | -1.62        |\n",
            "|    explained_variance   | -6.57        |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | -0.0364      |\n",
            "|    n_updates            | 15052        |\n",
            "|    policy_gradient_loss | -0.0103      |\n",
            "|    value_loss           | 1.36e-05     |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 591          |\n",
            "|    iterations           | 3765         |\n",
            "|    time_elapsed         | 6517         |\n",
            "|    total_timesteps      | 3855360      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0033992026 |\n",
            "|    clip_fraction        | 0.102        |\n",
            "|    clip_range           | 0.1          |\n",
            "|    entropy_loss         | -1.64        |\n",
            "|    explained_variance   | -10.7        |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | -0.0286      |\n",
            "|    n_updates            | 15056        |\n",
            "|    policy_gradient_loss | -0.00902     |\n",
            "|    value_loss           | 5.93e-06     |\n",
            "------------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 591         |\n",
            "|    iterations           | 3766        |\n",
            "|    time_elapsed         | 6518        |\n",
            "|    total_timesteps      | 3856384     |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.003366982 |\n",
            "|    clip_fraction        | 0.125       |\n",
            "|    clip_range           | 0.1         |\n",
            "|    entropy_loss         | -1.61       |\n",
            "|    explained_variance   | -9.35       |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | -0.0411     |\n",
            "|    n_updates            | 15060       |\n",
            "|    policy_gradient_loss | -0.0118     |\n",
            "|    value_loss           | 9.34e-06    |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 591         |\n",
            "|    iterations           | 3767        |\n",
            "|    time_elapsed         | 6520        |\n",
            "|    total_timesteps      | 3857408     |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.002589128 |\n",
            "|    clip_fraction        | 0.0952      |\n",
            "|    clip_range           | 0.1         |\n",
            "|    entropy_loss         | -1.65       |\n",
            "|    explained_variance   | -5.68       |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | -0.0319     |\n",
            "|    n_updates            | 15064       |\n",
            "|    policy_gradient_loss | -0.00747    |\n",
            "|    value_loss           | 7.48e-06    |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 591         |\n",
            "|    iterations           | 3768        |\n",
            "|    time_elapsed         | 6523        |\n",
            "|    total_timesteps      | 3858432     |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.004461378 |\n",
            "|    clip_fraction        | 0.109       |\n",
            "|    clip_range           | 0.1         |\n",
            "|    entropy_loss         | -1.45       |\n",
            "|    explained_variance   | -11.2       |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | -0.0265     |\n",
            "|    n_updates            | 15068       |\n",
            "|    policy_gradient_loss | -0.00987    |\n",
            "|    value_loss           | 1.11e-05    |\n",
            "-----------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 591          |\n",
            "|    iterations           | 3769         |\n",
            "|    time_elapsed         | 6524         |\n",
            "|    total_timesteps      | 3859456      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0020046306 |\n",
            "|    clip_fraction        | 0.0962       |\n",
            "|    clip_range           | 0.1          |\n",
            "|    entropy_loss         | -1.59        |\n",
            "|    explained_variance   | -4.66        |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | -0.0345      |\n",
            "|    n_updates            | 15072        |\n",
            "|    policy_gradient_loss | -0.00884     |\n",
            "|    value_loss           | 7.97e-06     |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 591          |\n",
            "|    iterations           | 3770         |\n",
            "|    time_elapsed         | 6526         |\n",
            "|    total_timesteps      | 3860480      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0025473158 |\n",
            "|    clip_fraction        | 0.12         |\n",
            "|    clip_range           | 0.1          |\n",
            "|    entropy_loss         | -1.55        |\n",
            "|    explained_variance   | -0.27        |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | -0.0401      |\n",
            "|    n_updates            | 15076        |\n",
            "|    policy_gradient_loss | -0.00995     |\n",
            "|    value_loss           | 6.2e-06      |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 591          |\n",
            "|    iterations           | 3771         |\n",
            "|    time_elapsed         | 6527         |\n",
            "|    total_timesteps      | 3861504      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0024439374 |\n",
            "|    clip_fraction        | 0.119        |\n",
            "|    clip_range           | 0.1          |\n",
            "|    entropy_loss         | -1.62        |\n",
            "|    explained_variance   | 0.342        |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | -0.027       |\n",
            "|    n_updates            | 15080        |\n",
            "|    policy_gradient_loss | -0.00655     |\n",
            "|    value_loss           | 4.18e-06     |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 591          |\n",
            "|    iterations           | 3772         |\n",
            "|    time_elapsed         | 6529         |\n",
            "|    total_timesteps      | 3862528      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0023319349 |\n",
            "|    clip_fraction        | 0.061        |\n",
            "|    clip_range           | 0.1          |\n",
            "|    entropy_loss         | -1.59        |\n",
            "|    explained_variance   | -1.4         |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | -0.0355      |\n",
            "|    n_updates            | 15084        |\n",
            "|    policy_gradient_loss | -0.00896     |\n",
            "|    value_loss           | 5.41e-06     |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 591          |\n",
            "|    iterations           | 3773         |\n",
            "|    time_elapsed         | 6530         |\n",
            "|    total_timesteps      | 3863552      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0037439892 |\n",
            "|    clip_fraction        | 0.115        |\n",
            "|    clip_range           | 0.1          |\n",
            "|    entropy_loss         | -1.58        |\n",
            "|    explained_variance   | -0.493       |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | -0.033       |\n",
            "|    n_updates            | 15088        |\n",
            "|    policy_gradient_loss | -0.0101      |\n",
            "|    value_loss           | 4.61e-06     |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 591          |\n",
            "|    iterations           | 3774         |\n",
            "|    time_elapsed         | 6532         |\n",
            "|    total_timesteps      | 3864576      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0028453676 |\n",
            "|    clip_fraction        | 0.104        |\n",
            "|    clip_range           | 0.1          |\n",
            "|    entropy_loss         | -1.57        |\n",
            "|    explained_variance   | -2.72        |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | -0.0422      |\n",
            "|    n_updates            | 15092        |\n",
            "|    policy_gradient_loss | -0.0107      |\n",
            "|    value_loss           | 7.5e-06      |\n",
            "------------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 591         |\n",
            "|    iterations           | 3775        |\n",
            "|    time_elapsed         | 6534        |\n",
            "|    total_timesteps      | 3865600     |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.002252211 |\n",
            "|    clip_fraction        | 0.141       |\n",
            "|    clip_range           | 0.1         |\n",
            "|    entropy_loss         | -1.61       |\n",
            "|    explained_variance   | -0.639      |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | -0.0319     |\n",
            "|    n_updates            | 15096       |\n",
            "|    policy_gradient_loss | -0.00789    |\n",
            "|    value_loss           | 2.88e-06    |\n",
            "-----------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 591          |\n",
            "|    iterations           | 3776         |\n",
            "|    time_elapsed         | 6536         |\n",
            "|    total_timesteps      | 3866624      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0031497043 |\n",
            "|    clip_fraction        | 0.202        |\n",
            "|    clip_range           | 0.1          |\n",
            "|    entropy_loss         | -1.53        |\n",
            "|    explained_variance   | -0.00404     |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | -0.015       |\n",
            "|    n_updates            | 15100        |\n",
            "|    policy_gradient_loss | -0.00184     |\n",
            "|    value_loss           | 0.00812      |\n",
            "------------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 591         |\n",
            "|    iterations           | 3777        |\n",
            "|    time_elapsed         | 6538        |\n",
            "|    total_timesteps      | 3867648     |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.006456783 |\n",
            "|    clip_fraction        | 0.198       |\n",
            "|    clip_range           | 0.1         |\n",
            "|    entropy_loss         | -1.62       |\n",
            "|    explained_variance   | -0.0269     |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | -0.00463    |\n",
            "|    n_updates            | 15104       |\n",
            "|    policy_gradient_loss | -0.00271    |\n",
            "|    value_loss           | 0.00822     |\n",
            "-----------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 591          |\n",
            "|    iterations           | 3778         |\n",
            "|    time_elapsed         | 6539         |\n",
            "|    total_timesteps      | 3868672      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0023470456 |\n",
            "|    clip_fraction        | 0.0957       |\n",
            "|    clip_range           | 0.1          |\n",
            "|    entropy_loss         | -1.62        |\n",
            "|    explained_variance   | 0.268        |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | -0.031       |\n",
            "|    n_updates            | 15108        |\n",
            "|    policy_gradient_loss | -0.00636     |\n",
            "|    value_loss           | 6e-05        |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 591          |\n",
            "|    iterations           | 3779         |\n",
            "|    time_elapsed         | 6541         |\n",
            "|    total_timesteps      | 3869696      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0028866963 |\n",
            "|    clip_fraction        | 0.118        |\n",
            "|    clip_range           | 0.1          |\n",
            "|    entropy_loss         | -1.65        |\n",
            "|    explained_variance   | 0.602        |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | -0.0331      |\n",
            "|    n_updates            | 15112        |\n",
            "|    policy_gradient_loss | -0.00865     |\n",
            "|    value_loss           | 2.77e-05     |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 591          |\n",
            "|    iterations           | 3780         |\n",
            "|    time_elapsed         | 6542         |\n",
            "|    total_timesteps      | 3870720      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0025389649 |\n",
            "|    clip_fraction        | 0.0942       |\n",
            "|    clip_range           | 0.1          |\n",
            "|    entropy_loss         | -1.48        |\n",
            "|    explained_variance   | 0.301        |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | -0.0277      |\n",
            "|    n_updates            | 15116        |\n",
            "|    policy_gradient_loss | -0.00937     |\n",
            "|    value_loss           | 3.53e-05     |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 591          |\n",
            "|    iterations           | 3781         |\n",
            "|    time_elapsed         | 6544         |\n",
            "|    total_timesteps      | 3871744      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0045947777 |\n",
            "|    clip_fraction        | 0.152        |\n",
            "|    clip_range           | 0.1          |\n",
            "|    entropy_loss         | -1.63        |\n",
            "|    explained_variance   | 0.0212       |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | -0.0217      |\n",
            "|    n_updates            | 15120        |\n",
            "|    policy_gradient_loss | -0.00597     |\n",
            "|    value_loss           | 0.00776      |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 591          |\n",
            "|    iterations           | 3782         |\n",
            "|    time_elapsed         | 6545         |\n",
            "|    total_timesteps      | 3872768      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0039815074 |\n",
            "|    clip_fraction        | 0.0972       |\n",
            "|    clip_range           | 0.1          |\n",
            "|    entropy_loss         | -1.58        |\n",
            "|    explained_variance   | 0.425        |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | -0.0365      |\n",
            "|    n_updates            | 15124        |\n",
            "|    policy_gradient_loss | -0.0112      |\n",
            "|    value_loss           | 0.00016      |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 591          |\n",
            "|    iterations           | 3783         |\n",
            "|    time_elapsed         | 6547         |\n",
            "|    total_timesteps      | 3873792      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0038072446 |\n",
            "|    clip_fraction        | 0.148        |\n",
            "|    clip_range           | 0.1          |\n",
            "|    entropy_loss         | -1.63        |\n",
            "|    explained_variance   | 0.56         |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | -0.0365      |\n",
            "|    n_updates            | 15128        |\n",
            "|    policy_gradient_loss | -0.0116      |\n",
            "|    value_loss           | 8.3e-05      |\n",
            "------------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 591         |\n",
            "|    iterations           | 3784        |\n",
            "|    time_elapsed         | 6549        |\n",
            "|    total_timesteps      | 3874816     |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.005308981 |\n",
            "|    clip_fraction        | 0.14        |\n",
            "|    clip_range           | 0.1         |\n",
            "|    entropy_loss         | -1.48       |\n",
            "|    explained_variance   | 0.668       |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | -0.0246     |\n",
            "|    n_updates            | 15132       |\n",
            "|    policy_gradient_loss | -0.00981    |\n",
            "|    value_loss           | 3.38e-05    |\n",
            "-----------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 591          |\n",
            "|    iterations           | 3785         |\n",
            "|    time_elapsed         | 6551         |\n",
            "|    total_timesteps      | 3875840      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0023622354 |\n",
            "|    clip_fraction        | 0.15         |\n",
            "|    clip_range           | 0.1          |\n",
            "|    entropy_loss         | -1.54        |\n",
            "|    explained_variance   | 0.768        |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | -0.0351      |\n",
            "|    n_updates            | 15136        |\n",
            "|    policy_gradient_loss | -0.0083      |\n",
            "|    value_loss           | 2.38e-05     |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 591          |\n",
            "|    iterations           | 3786         |\n",
            "|    time_elapsed         | 6552         |\n",
            "|    total_timesteps      | 3876864      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0035757637 |\n",
            "|    clip_fraction        | 0.16         |\n",
            "|    clip_range           | 0.1          |\n",
            "|    entropy_loss         | -1.57        |\n",
            "|    explained_variance   | 0.73         |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | -0.0371      |\n",
            "|    n_updates            | 15140        |\n",
            "|    policy_gradient_loss | -0.01        |\n",
            "|    value_loss           | 1.78e-05     |\n",
            "------------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 591         |\n",
            "|    iterations           | 3787        |\n",
            "|    time_elapsed         | 6554        |\n",
            "|    total_timesteps      | 3877888     |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.005366897 |\n",
            "|    clip_fraction        | 0.115       |\n",
            "|    clip_range           | 0.1         |\n",
            "|    entropy_loss         | -1.42       |\n",
            "|    explained_variance   | 0.563       |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | -0.0317     |\n",
            "|    n_updates            | 15144       |\n",
            "|    policy_gradient_loss | -0.012      |\n",
            "|    value_loss           | 1.88e-05    |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 591         |\n",
            "|    iterations           | 3788        |\n",
            "|    time_elapsed         | 6555        |\n",
            "|    total_timesteps      | 3878912     |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.002535063 |\n",
            "|    clip_fraction        | 0.0962      |\n",
            "|    clip_range           | 0.1         |\n",
            "|    entropy_loss         | -1.5        |\n",
            "|    explained_variance   | 0.5         |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | -0.0346     |\n",
            "|    n_updates            | 15148       |\n",
            "|    policy_gradient_loss | -0.0089     |\n",
            "|    value_loss           | 1.84e-05    |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 591         |\n",
            "|    iterations           | 3789        |\n",
            "|    time_elapsed         | 6557        |\n",
            "|    total_timesteps      | 3879936     |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.004233893 |\n",
            "|    clip_fraction        | 0.0996      |\n",
            "|    clip_range           | 0.1         |\n",
            "|    entropy_loss         | -1.52       |\n",
            "|    explained_variance   | 0.629       |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | -0.0328     |\n",
            "|    n_updates            | 15152       |\n",
            "|    policy_gradient_loss | -0.0111     |\n",
            "|    value_loss           | 1.08e-05    |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 591         |\n",
            "|    iterations           | 3790        |\n",
            "|    time_elapsed         | 6559        |\n",
            "|    total_timesteps      | 3880960     |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.003304587 |\n",
            "|    clip_fraction        | 0.106       |\n",
            "|    clip_range           | 0.1         |\n",
            "|    entropy_loss         | -1.51       |\n",
            "|    explained_variance   | 0.203       |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | -0.0364     |\n",
            "|    n_updates            | 15156       |\n",
            "|    policy_gradient_loss | -0.0116     |\n",
            "|    value_loss           | 9.68e-06    |\n",
            "-----------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 591          |\n",
            "|    iterations           | 3791         |\n",
            "|    time_elapsed         | 6561         |\n",
            "|    total_timesteps      | 3881984      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0019882454 |\n",
            "|    clip_fraction        | 0.0645       |\n",
            "|    clip_range           | 0.1          |\n",
            "|    entropy_loss         | -1.48        |\n",
            "|    explained_variance   | -0.981       |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | -0.0336      |\n",
            "|    n_updates            | 15160        |\n",
            "|    policy_gradient_loss | -0.00953     |\n",
            "|    value_loss           | 7.3e-06      |\n",
            "------------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 591         |\n",
            "|    iterations           | 3792        |\n",
            "|    time_elapsed         | 6563        |\n",
            "|    total_timesteps      | 3883008     |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.002536248 |\n",
            "|    clip_fraction        | 0.0564      |\n",
            "|    clip_range           | 0.1         |\n",
            "|    entropy_loss         | -1.46       |\n",
            "|    explained_variance   | -0.495      |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | -0.0307     |\n",
            "|    n_updates            | 15164       |\n",
            "|    policy_gradient_loss | -0.0094     |\n",
            "|    value_loss           | 5.84e-06    |\n",
            "-----------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 591          |\n",
            "|    iterations           | 3793         |\n",
            "|    time_elapsed         | 6564         |\n",
            "|    total_timesteps      | 3884032      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0035268571 |\n",
            "|    clip_fraction        | 0.119        |\n",
            "|    clip_range           | 0.1          |\n",
            "|    entropy_loss         | -1.53        |\n",
            "|    explained_variance   | 0.329        |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | -0.0371      |\n",
            "|    n_updates            | 15168        |\n",
            "|    policy_gradient_loss | -0.0103      |\n",
            "|    value_loss           | 4.42e-06     |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 591          |\n",
            "|    iterations           | 3794         |\n",
            "|    time_elapsed         | 6566         |\n",
            "|    total_timesteps      | 3885056      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0045508146 |\n",
            "|    clip_fraction        | 0.0879       |\n",
            "|    clip_range           | 0.1          |\n",
            "|    entropy_loss         | -1.42        |\n",
            "|    explained_variance   | -1.38        |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | -0.033       |\n",
            "|    n_updates            | 15172        |\n",
            "|    policy_gradient_loss | -0.0122      |\n",
            "|    value_loss           | 1.14e-05     |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 591          |\n",
            "|    iterations           | 3795         |\n",
            "|    time_elapsed         | 6567         |\n",
            "|    total_timesteps      | 3886080      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0031880012 |\n",
            "|    clip_fraction        | 0.0862       |\n",
            "|    clip_range           | 0.1          |\n",
            "|    entropy_loss         | -1.47        |\n",
            "|    explained_variance   | -2.14        |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | -0.0354      |\n",
            "|    n_updates            | 15176        |\n",
            "|    policy_gradient_loss | -0.0133      |\n",
            "|    value_loss           | 1.29e-05     |\n",
            "------------------------------------------\n",
            "----------------------------------------\n",
            "| time/                   |            |\n",
            "|    fps                  | 591        |\n",
            "|    iterations           | 3796       |\n",
            "|    time_elapsed         | 6569       |\n",
            "|    total_timesteps      | 3887104    |\n",
            "| train/                  |            |\n",
            "|    approx_kl            | 0.00166613 |\n",
            "|    clip_fraction        | 0.083      |\n",
            "|    clip_range           | 0.1        |\n",
            "|    entropy_loss         | -1.59      |\n",
            "|    explained_variance   | 0.518      |\n",
            "|    learning_rate        | 0.00025    |\n",
            "|    loss                 | -0.0313    |\n",
            "|    n_updates            | 15180      |\n",
            "|    policy_gradient_loss | -0.00851   |\n",
            "|    value_loss           | 3.46e-06   |\n",
            "----------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 591          |\n",
            "|    iterations           | 3797         |\n",
            "|    time_elapsed         | 6570         |\n",
            "|    total_timesteps      | 3888128      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0028646514 |\n",
            "|    clip_fraction        | 0.0918       |\n",
            "|    clip_range           | 0.1          |\n",
            "|    entropy_loss         | -1.61        |\n",
            "|    explained_variance   | 0.421        |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | -0.036       |\n",
            "|    n_updates            | 15184        |\n",
            "|    policy_gradient_loss | -0.00902     |\n",
            "|    value_loss           | 4.46e-06     |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 591          |\n",
            "|    iterations           | 3798         |\n",
            "|    time_elapsed         | 6572         |\n",
            "|    total_timesteps      | 3889152      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0051811077 |\n",
            "|    clip_fraction        | 0.126        |\n",
            "|    clip_range           | 0.1          |\n",
            "|    entropy_loss         | -1.58        |\n",
            "|    explained_variance   | -0.0407      |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | -0.038       |\n",
            "|    n_updates            | 15188        |\n",
            "|    policy_gradient_loss | -0.0135      |\n",
            "|    value_loss           | 7.15e-06     |\n",
            "------------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 591         |\n",
            "|    iterations           | 3799        |\n",
            "|    time_elapsed         | 6574        |\n",
            "|    total_timesteps      | 3890176     |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.002299164 |\n",
            "|    clip_fraction        | 0.104       |\n",
            "|    clip_range           | 0.1         |\n",
            "|    entropy_loss         | -1.64       |\n",
            "|    explained_variance   | 0.0479      |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | -0.0427     |\n",
            "|    n_updates            | 15192       |\n",
            "|    policy_gradient_loss | -0.0114     |\n",
            "|    value_loss           | 4.68e-06    |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 591         |\n",
            "|    iterations           | 3800        |\n",
            "|    time_elapsed         | 6576        |\n",
            "|    total_timesteps      | 3891200     |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.002999751 |\n",
            "|    clip_fraction        | 0.0703      |\n",
            "|    clip_range           | 0.1         |\n",
            "|    entropy_loss         | -1.53       |\n",
            "|    explained_variance   | -2.43       |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | -0.0375     |\n",
            "|    n_updates            | 15196       |\n",
            "|    policy_gradient_loss | -0.0124     |\n",
            "|    value_loss           | 7.64e-06    |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 591         |\n",
            "|    iterations           | 3801        |\n",
            "|    time_elapsed         | 6577        |\n",
            "|    total_timesteps      | 3892224     |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.002536831 |\n",
            "|    clip_fraction        | 0.0544      |\n",
            "|    clip_range           | 0.1         |\n",
            "|    entropy_loss         | -1.56       |\n",
            "|    explained_variance   | -1.96       |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | -0.0356     |\n",
            "|    n_updates            | 15200       |\n",
            "|    policy_gradient_loss | -0.00989    |\n",
            "|    value_loss           | 4.6e-06     |\n",
            "-----------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 591          |\n",
            "|    iterations           | 3802         |\n",
            "|    time_elapsed         | 6579         |\n",
            "|    total_timesteps      | 3893248      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0034255702 |\n",
            "|    clip_fraction        | 0.133        |\n",
            "|    clip_range           | 0.1          |\n",
            "|    entropy_loss         | -1.59        |\n",
            "|    explained_variance   | -8.94e-06    |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | -0.0254      |\n",
            "|    n_updates            | 15204        |\n",
            "|    policy_gradient_loss | -0.00694     |\n",
            "|    value_loss           | 0.0078       |\n",
            "------------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 591         |\n",
            "|    iterations           | 3803        |\n",
            "|    time_elapsed         | 6580        |\n",
            "|    total_timesteps      | 3894272     |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.002710761 |\n",
            "|    clip_fraction        | 0.0605      |\n",
            "|    clip_range           | 0.1         |\n",
            "|    entropy_loss         | -1.61       |\n",
            "|    explained_variance   | 0.00512     |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | -0.0143     |\n",
            "|    n_updates            | 15208       |\n",
            "|    policy_gradient_loss | -0.00574    |\n",
            "|    value_loss           | 0.0172      |\n",
            "-----------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 591          |\n",
            "|    iterations           | 3804         |\n",
            "|    time_elapsed         | 6582         |\n",
            "|    total_timesteps      | 3895296      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0029966058 |\n",
            "|    clip_fraction        | 0.124        |\n",
            "|    clip_range           | 0.1          |\n",
            "|    entropy_loss         | -1.56        |\n",
            "|    explained_variance   | 0.0967       |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | -0.0369      |\n",
            "|    n_updates            | 15212        |\n",
            "|    policy_gradient_loss | -0.0115      |\n",
            "|    value_loss           | 0.000103     |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 591          |\n",
            "|    iterations           | 3805         |\n",
            "|    time_elapsed         | 6584         |\n",
            "|    total_timesteps      | 3896320      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0029759896 |\n",
            "|    clip_fraction        | 0.11         |\n",
            "|    clip_range           | 0.1          |\n",
            "|    entropy_loss         | -1.52        |\n",
            "|    explained_variance   | -0.462       |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | -0.0285      |\n",
            "|    n_updates            | 15216        |\n",
            "|    policy_gradient_loss | -0.00815     |\n",
            "|    value_loss           | 6.23e-05     |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 591          |\n",
            "|    iterations           | 3806         |\n",
            "|    time_elapsed         | 6585         |\n",
            "|    total_timesteps      | 3897344      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0036199114 |\n",
            "|    clip_fraction        | 0.0884       |\n",
            "|    clip_range           | 0.1          |\n",
            "|    entropy_loss         | -1.62        |\n",
            "|    explained_variance   | 0.535        |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | -0.0425      |\n",
            "|    n_updates            | 15220        |\n",
            "|    policy_gradient_loss | -0.0121      |\n",
            "|    value_loss           | 2.24e-05     |\n",
            "------------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 591         |\n",
            "|    iterations           | 3807        |\n",
            "|    time_elapsed         | 6587        |\n",
            "|    total_timesteps      | 3898368     |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.003668398 |\n",
            "|    clip_fraction        | 0.0933      |\n",
            "|    clip_range           | 0.1         |\n",
            "|    entropy_loss         | -1.62       |\n",
            "|    explained_variance   | 0.512       |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | -0.0422     |\n",
            "|    n_updates            | 15224       |\n",
            "|    policy_gradient_loss | -0.00804    |\n",
            "|    value_loss           | 1.23e-05    |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 591         |\n",
            "|    iterations           | 3808        |\n",
            "|    time_elapsed         | 6589        |\n",
            "|    total_timesteps      | 3899392     |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.002434583 |\n",
            "|    clip_fraction        | 0.0913      |\n",
            "|    clip_range           | 0.1         |\n",
            "|    entropy_loss         | -1.58       |\n",
            "|    explained_variance   | 0.257       |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | -0.0239     |\n",
            "|    n_updates            | 15228       |\n",
            "|    policy_gradient_loss | -0.00881    |\n",
            "|    value_loss           | 1.52e-05    |\n",
            "-----------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 591          |\n",
            "|    iterations           | 3809         |\n",
            "|    time_elapsed         | 6591         |\n",
            "|    total_timesteps      | 3900416      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0017492337 |\n",
            "|    clip_fraction        | 0.103        |\n",
            "|    clip_range           | 0.1          |\n",
            "|    entropy_loss         | -1.52        |\n",
            "|    explained_variance   | 0.000822     |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | -0.0112      |\n",
            "|    n_updates            | 15232        |\n",
            "|    policy_gradient_loss | -0.00536     |\n",
            "|    value_loss           | 0.0251       |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 591          |\n",
            "|    iterations           | 3810         |\n",
            "|    time_elapsed         | 6592         |\n",
            "|    total_timesteps      | 3901440      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0063695814 |\n",
            "|    clip_fraction        | 0.127        |\n",
            "|    clip_range           | 0.1          |\n",
            "|    entropy_loss         | -1.47        |\n",
            "|    explained_variance   | -2.51        |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | -0.038       |\n",
            "|    n_updates            | 15236        |\n",
            "|    policy_gradient_loss | -0.00899     |\n",
            "|    value_loss           | 8.44e-05     |\n",
            "------------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 591         |\n",
            "|    iterations           | 3811        |\n",
            "|    time_elapsed         | 6594        |\n",
            "|    total_timesteps      | 3902464     |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.005105938 |\n",
            "|    clip_fraction        | 0.11        |\n",
            "|    clip_range           | 0.1         |\n",
            "|    entropy_loss         | -1.51       |\n",
            "|    explained_variance   | 0.0715      |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | -0.0356     |\n",
            "|    n_updates            | 15240       |\n",
            "|    policy_gradient_loss | -0.00926    |\n",
            "|    value_loss           | 2.86e-05    |\n",
            "-----------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 591          |\n",
            "|    iterations           | 3812         |\n",
            "|    time_elapsed         | 6595         |\n",
            "|    total_timesteps      | 3903488      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0028691404 |\n",
            "|    clip_fraction        | 0.137        |\n",
            "|    clip_range           | 0.1          |\n",
            "|    entropy_loss         | -1.58        |\n",
            "|    explained_variance   | 0.213        |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | -0.0282      |\n",
            "|    n_updates            | 15244        |\n",
            "|    policy_gradient_loss | -0.0097      |\n",
            "|    value_loss           | 1.83e-05     |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 591          |\n",
            "|    iterations           | 3813         |\n",
            "|    time_elapsed         | 6597         |\n",
            "|    total_timesteps      | 3904512      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0031681124 |\n",
            "|    clip_fraction        | 0.113        |\n",
            "|    clip_range           | 0.1          |\n",
            "|    entropy_loss         | -1.57        |\n",
            "|    explained_variance   | 0.482        |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | -0.0387      |\n",
            "|    n_updates            | 15248        |\n",
            "|    policy_gradient_loss | -0.0112      |\n",
            "|    value_loss           | 1.43e-05     |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 591          |\n",
            "|    iterations           | 3814         |\n",
            "|    time_elapsed         | 6598         |\n",
            "|    total_timesteps      | 3905536      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0044829426 |\n",
            "|    clip_fraction        | 0.102        |\n",
            "|    clip_range           | 0.1          |\n",
            "|    entropy_loss         | -1.54        |\n",
            "|    explained_variance   | 0.522        |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | -0.0399      |\n",
            "|    n_updates            | 15252        |\n",
            "|    policy_gradient_loss | -0.0116      |\n",
            "|    value_loss           | 9.66e-06     |\n",
            "------------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 591         |\n",
            "|    iterations           | 3815        |\n",
            "|    time_elapsed         | 6601        |\n",
            "|    total_timesteps      | 3906560     |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.004110629 |\n",
            "|    clip_fraction        | 0.116       |\n",
            "|    clip_range           | 0.1         |\n",
            "|    entropy_loss         | -1.45       |\n",
            "|    explained_variance   | -0.406      |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | -0.0353     |\n",
            "|    n_updates            | 15256       |\n",
            "|    policy_gradient_loss | -0.0135     |\n",
            "|    value_loss           | 1.21e-05    |\n",
            "-----------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 591          |\n",
            "|    iterations           | 3816         |\n",
            "|    time_elapsed         | 6602         |\n",
            "|    total_timesteps      | 3907584      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0025500273 |\n",
            "|    clip_fraction        | 0.15         |\n",
            "|    clip_range           | 0.1          |\n",
            "|    entropy_loss         | -1.57        |\n",
            "|    explained_variance   | -0.27        |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | -0.0325      |\n",
            "|    n_updates            | 15260        |\n",
            "|    policy_gradient_loss | -0.00856     |\n",
            "|    value_loss           | 1.18e-05     |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 591          |\n",
            "|    iterations           | 3817         |\n",
            "|    time_elapsed         | 6604         |\n",
            "|    total_timesteps      | 3908608      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0027685962 |\n",
            "|    clip_fraction        | 0.0864       |\n",
            "|    clip_range           | 0.1          |\n",
            "|    entropy_loss         | -1.59        |\n",
            "|    explained_variance   | 0.117        |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | -0.0364      |\n",
            "|    n_updates            | 15264        |\n",
            "|    policy_gradient_loss | -0.00917     |\n",
            "|    value_loss           | 6.15e-06     |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 591          |\n",
            "|    iterations           | 3818         |\n",
            "|    time_elapsed         | 6605         |\n",
            "|    total_timesteps      | 3909632      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0057330984 |\n",
            "|    clip_fraction        | 0.166        |\n",
            "|    clip_range           | 0.1          |\n",
            "|    entropy_loss         | -1.45        |\n",
            "|    explained_variance   | -1.81        |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | -0.0409      |\n",
            "|    n_updates            | 15268        |\n",
            "|    policy_gradient_loss | -0.0134      |\n",
            "|    value_loss           | 4.23e-05     |\n",
            "------------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 591         |\n",
            "|    iterations           | 3819        |\n",
            "|    time_elapsed         | 6607        |\n",
            "|    total_timesteps      | 3910656     |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.004316646 |\n",
            "|    clip_fraction        | 0.169       |\n",
            "|    clip_range           | 0.1         |\n",
            "|    entropy_loss         | -1.46       |\n",
            "|    explained_variance   | -2.43       |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | -0.044      |\n",
            "|    n_updates            | 15272       |\n",
            "|    policy_gradient_loss | -0.0128     |\n",
            "|    value_loss           | 2.27e-05    |\n",
            "-----------------------------------------\n",
            "----------------------------------------\n",
            "| time/                   |            |\n",
            "|    fps                  | 591        |\n",
            "|    iterations           | 3820       |\n",
            "|    time_elapsed         | 6608       |\n",
            "|    total_timesteps      | 3911680    |\n",
            "| train/                  |            |\n",
            "|    approx_kl            | 0.00504044 |\n",
            "|    clip_fraction        | 0.143      |\n",
            "|    clip_range           | 0.1        |\n",
            "|    entropy_loss         | -1.57      |\n",
            "|    explained_variance   | -2.42      |\n",
            "|    learning_rate        | 0.00025    |\n",
            "|    loss                 | -0.0481    |\n",
            "|    n_updates            | 15276      |\n",
            "|    policy_gradient_loss | -0.0136    |\n",
            "|    value_loss           | 1.92e-05   |\n",
            "----------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 591          |\n",
            "|    iterations           | 3821         |\n",
            "|    time_elapsed         | 6610         |\n",
            "|    total_timesteps      | 3912704      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0046288087 |\n",
            "|    clip_fraction        | 0.118        |\n",
            "|    clip_range           | 0.1          |\n",
            "|    entropy_loss         | -1.47        |\n",
            "|    explained_variance   | -1.35        |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | -0.0398      |\n",
            "|    n_updates            | 15280        |\n",
            "|    policy_gradient_loss | -0.0112      |\n",
            "|    value_loss           | 1.2e-05      |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 591          |\n",
            "|    iterations           | 3822         |\n",
            "|    time_elapsed         | 6611         |\n",
            "|    total_timesteps      | 3913728      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0042539346 |\n",
            "|    clip_fraction        | 0.13         |\n",
            "|    clip_range           | 0.1          |\n",
            "|    entropy_loss         | -1.47        |\n",
            "|    explained_variance   | -1.62        |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | -0.0376      |\n",
            "|    n_updates            | 15284        |\n",
            "|    policy_gradient_loss | -0.0116      |\n",
            "|    value_loss           | 1.08e-05     |\n",
            "------------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 591         |\n",
            "|    iterations           | 3823        |\n",
            "|    time_elapsed         | 6614        |\n",
            "|    total_timesteps      | 3914752     |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.004892975 |\n",
            "|    clip_fraction        | 0.144       |\n",
            "|    clip_range           | 0.1         |\n",
            "|    entropy_loss         | -1.42       |\n",
            "|    explained_variance   | -3.33       |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | -0.0293     |\n",
            "|    n_updates            | 15288       |\n",
            "|    policy_gradient_loss | -0.00942    |\n",
            "|    value_loss           | 1.27e-05    |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 591         |\n",
            "|    iterations           | 3824        |\n",
            "|    time_elapsed         | 6615        |\n",
            "|    total_timesteps      | 3915776     |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.004929676 |\n",
            "|    clip_fraction        | 0.139       |\n",
            "|    clip_range           | 0.1         |\n",
            "|    entropy_loss         | -1.38       |\n",
            "|    explained_variance   | -6.8        |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | -0.0318     |\n",
            "|    n_updates            | 15292       |\n",
            "|    policy_gradient_loss | -0.0111     |\n",
            "|    value_loss           | 1.22e-05    |\n",
            "-----------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 591          |\n",
            "|    iterations           | 3825         |\n",
            "|    time_elapsed         | 6617         |\n",
            "|    total_timesteps      | 3916800      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0047313496 |\n",
            "|    clip_fraction        | 0.151        |\n",
            "|    clip_range           | 0.1          |\n",
            "|    entropy_loss         | -1.44        |\n",
            "|    explained_variance   | -0.98        |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | -0.0428      |\n",
            "|    n_updates            | 15296        |\n",
            "|    policy_gradient_loss | -0.012       |\n",
            "|    value_loss           | 1.29e-05     |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 591          |\n",
            "|    iterations           | 3826         |\n",
            "|    time_elapsed         | 6619         |\n",
            "|    total_timesteps      | 3917824      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0047487207 |\n",
            "|    clip_fraction        | 0.146        |\n",
            "|    clip_range           | 0.1          |\n",
            "|    entropy_loss         | -1.44        |\n",
            "|    explained_variance   | -10.5        |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | -0.0388      |\n",
            "|    n_updates            | 15300        |\n",
            "|    policy_gradient_loss | -0.0129      |\n",
            "|    value_loss           | 1.47e-05     |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 591          |\n",
            "|    iterations           | 3827         |\n",
            "|    time_elapsed         | 6620         |\n",
            "|    total_timesteps      | 3918848      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0054348623 |\n",
            "|    clip_fraction        | 0.17         |\n",
            "|    clip_range           | 0.1          |\n",
            "|    entropy_loss         | -1.57        |\n",
            "|    explained_variance   | -2.47        |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | -0.0342      |\n",
            "|    n_updates            | 15304        |\n",
            "|    policy_gradient_loss | -0.00918     |\n",
            "|    value_loss           | 6.4e-06      |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 591          |\n",
            "|    iterations           | 3828         |\n",
            "|    time_elapsed         | 6622         |\n",
            "|    total_timesteps      | 3919872      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0033707118 |\n",
            "|    clip_fraction        | 0.153        |\n",
            "|    clip_range           | 0.1          |\n",
            "|    entropy_loss         | -1.56        |\n",
            "|    explained_variance   | -0.256       |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | -0.0251      |\n",
            "|    n_updates            | 15308        |\n",
            "|    policy_gradient_loss | -0.00877     |\n",
            "|    value_loss           | 3.4e-06      |\n",
            "------------------------------------------\n",
            "---------------------------------------\n",
            "| time/                   |           |\n",
            "|    fps                  | 591       |\n",
            "|    iterations           | 3829      |\n",
            "|    time_elapsed         | 6623      |\n",
            "|    total_timesteps      | 3920896   |\n",
            "| train/                  |           |\n",
            "|    approx_kl            | 0.0025664 |\n",
            "|    clip_fraction        | 0.093     |\n",
            "|    clip_range           | 0.1       |\n",
            "|    entropy_loss         | -1.53     |\n",
            "|    explained_variance   | -1.28     |\n",
            "|    learning_rate        | 0.00025   |\n",
            "|    loss                 | -0.0307   |\n",
            "|    n_updates            | 15312     |\n",
            "|    policy_gradient_loss | -0.00794  |\n",
            "|    value_loss           | 3.35e-06  |\n",
            "---------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 591         |\n",
            "|    iterations           | 3830        |\n",
            "|    time_elapsed         | 6625        |\n",
            "|    total_timesteps      | 3921920     |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.003906284 |\n",
            "|    clip_fraction        | 0.114       |\n",
            "|    clip_range           | 0.1         |\n",
            "|    entropy_loss         | -1.5        |\n",
            "|    explained_variance   | -2.47       |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | -0.042      |\n",
            "|    n_updates            | 15316       |\n",
            "|    policy_gradient_loss | -0.0148     |\n",
            "|    value_loss           | 4.02e-06    |\n",
            "-----------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 591          |\n",
            "|    iterations           | 3831         |\n",
            "|    time_elapsed         | 6628         |\n",
            "|    total_timesteps      | 3922944      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0037152746 |\n",
            "|    clip_fraction        | 0.131        |\n",
            "|    clip_range           | 0.1          |\n",
            "|    entropy_loss         | -1.45        |\n",
            "|    explained_variance   | -6.45        |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | -0.0332      |\n",
            "|    n_updates            | 15320        |\n",
            "|    policy_gradient_loss | -0.0118      |\n",
            "|    value_loss           | 6.17e-06     |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 591          |\n",
            "|    iterations           | 3832         |\n",
            "|    time_elapsed         | 6629         |\n",
            "|    total_timesteps      | 3923968      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0036509167 |\n",
            "|    clip_fraction        | 0.128        |\n",
            "|    clip_range           | 0.1          |\n",
            "|    entropy_loss         | -1.46        |\n",
            "|    explained_variance   | -4.87        |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | -0.0374      |\n",
            "|    n_updates            | 15324        |\n",
            "|    policy_gradient_loss | -0.0108      |\n",
            "|    value_loss           | 7.41e-06     |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 591          |\n",
            "|    iterations           | 3833         |\n",
            "|    time_elapsed         | 6631         |\n",
            "|    total_timesteps      | 3924992      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0034072031 |\n",
            "|    clip_fraction        | 0.112        |\n",
            "|    clip_range           | 0.1          |\n",
            "|    entropy_loss         | -1.51        |\n",
            "|    explained_variance   | -1.43        |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | -0.0282      |\n",
            "|    n_updates            | 15328        |\n",
            "|    policy_gradient_loss | -0.00673     |\n",
            "|    value_loss           | 2.72e-06     |\n",
            "------------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 591         |\n",
            "|    iterations           | 3834        |\n",
            "|    time_elapsed         | 6632        |\n",
            "|    total_timesteps      | 3926016     |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.004953472 |\n",
            "|    clip_fraction        | 0.155       |\n",
            "|    clip_range           | 0.1         |\n",
            "|    entropy_loss         | -1.5        |\n",
            "|    explained_variance   | -2.27       |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | -0.0357     |\n",
            "|    n_updates            | 15332       |\n",
            "|    policy_gradient_loss | -0.0103     |\n",
            "|    value_loss           | 4.24e-06    |\n",
            "-----------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 591          |\n",
            "|    iterations           | 3835         |\n",
            "|    time_elapsed         | 6634         |\n",
            "|    total_timesteps      | 3927040      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0029434497 |\n",
            "|    clip_fraction        | 0.111        |\n",
            "|    clip_range           | 0.1          |\n",
            "|    entropy_loss         | -1.52        |\n",
            "|    explained_variance   | -0.0132      |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | -0.0236      |\n",
            "|    n_updates            | 15336        |\n",
            "|    policy_gradient_loss | -0.00719     |\n",
            "|    value_loss           | 0.00706      |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 591          |\n",
            "|    iterations           | 3836         |\n",
            "|    time_elapsed         | 6636         |\n",
            "|    total_timesteps      | 3928064      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0017232527 |\n",
            "|    clip_fraction        | 0.101        |\n",
            "|    clip_range           | 0.1          |\n",
            "|    entropy_loss         | -1.6         |\n",
            "|    explained_variance   | -0.668       |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | -0.0357      |\n",
            "|    n_updates            | 15340        |\n",
            "|    policy_gradient_loss | -0.0104      |\n",
            "|    value_loss           | 4.78e-05     |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 591          |\n",
            "|    iterations           | 3837         |\n",
            "|    time_elapsed         | 6637         |\n",
            "|    total_timesteps      | 3929088      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0036217477 |\n",
            "|    clip_fraction        | 0.116        |\n",
            "|    clip_range           | 0.1          |\n",
            "|    entropy_loss         | -1.54        |\n",
            "|    explained_variance   | -1.96        |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | -0.0335      |\n",
            "|    n_updates            | 15344        |\n",
            "|    policy_gradient_loss | -0.0116      |\n",
            "|    value_loss           | 0.00012      |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 591          |\n",
            "|    iterations           | 3838         |\n",
            "|    time_elapsed         | 6639         |\n",
            "|    total_timesteps      | 3930112      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0058446047 |\n",
            "|    clip_fraction        | 0.128        |\n",
            "|    clip_range           | 0.1          |\n",
            "|    entropy_loss         | -1.57        |\n",
            "|    explained_variance   | -0.542       |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | -0.0437      |\n",
            "|    n_updates            | 15348        |\n",
            "|    policy_gradient_loss | -0.0128      |\n",
            "|    value_loss           | 2.96e-05     |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 591          |\n",
            "|    iterations           | 3839         |\n",
            "|    time_elapsed         | 6641         |\n",
            "|    total_timesteps      | 3931136      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0031470954 |\n",
            "|    clip_fraction        | 0.0781       |\n",
            "|    clip_range           | 0.1          |\n",
            "|    entropy_loss         | -1.61        |\n",
            "|    explained_variance   | -0.851       |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | -0.0438      |\n",
            "|    n_updates            | 15352        |\n",
            "|    policy_gradient_loss | -0.0115      |\n",
            "|    value_loss           | 5.31e-05     |\n",
            "------------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 591         |\n",
            "|    iterations           | 3840        |\n",
            "|    time_elapsed         | 6643        |\n",
            "|    total_timesteps      | 3932160     |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.003021702 |\n",
            "|    clip_fraction        | 0.114       |\n",
            "|    clip_range           | 0.1         |\n",
            "|    entropy_loss         | -1.59       |\n",
            "|    explained_variance   | 0.0782      |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | -0.0413     |\n",
            "|    n_updates            | 15356       |\n",
            "|    policy_gradient_loss | -0.0113     |\n",
            "|    value_loss           | 3.23e-05    |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 591         |\n",
            "|    iterations           | 3841        |\n",
            "|    time_elapsed         | 6644        |\n",
            "|    total_timesteps      | 3933184     |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.004056387 |\n",
            "|    clip_fraction        | 0.116       |\n",
            "|    clip_range           | 0.1         |\n",
            "|    entropy_loss         | -1.59       |\n",
            "|    explained_variance   | -1.34       |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | -0.0384     |\n",
            "|    n_updates            | 15360       |\n",
            "|    policy_gradient_loss | -0.00987    |\n",
            "|    value_loss           | 2.23e-05    |\n",
            "-----------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 591          |\n",
            "|    iterations           | 3842         |\n",
            "|    time_elapsed         | 6646         |\n",
            "|    total_timesteps      | 3934208      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0025700524 |\n",
            "|    clip_fraction        | 0.11         |\n",
            "|    clip_range           | 0.1          |\n",
            "|    entropy_loss         | -1.68        |\n",
            "|    explained_variance   | -0.54        |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | -0.0343      |\n",
            "|    n_updates            | 15364        |\n",
            "|    policy_gradient_loss | -0.00757     |\n",
            "|    value_loss           | 2.5e-05      |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 591          |\n",
            "|    iterations           | 3843         |\n",
            "|    time_elapsed         | 6647         |\n",
            "|    total_timesteps      | 3935232      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0033646056 |\n",
            "|    clip_fraction        | 0.0681       |\n",
            "|    clip_range           | 0.1          |\n",
            "|    entropy_loss         | -1.65        |\n",
            "|    explained_variance   | -2.78        |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | -0.0235      |\n",
            "|    n_updates            | 15368        |\n",
            "|    policy_gradient_loss | -0.00651     |\n",
            "|    value_loss           | 0.000505     |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 591          |\n",
            "|    iterations           | 3844         |\n",
            "|    time_elapsed         | 6649         |\n",
            "|    total_timesteps      | 3936256      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0032039843 |\n",
            "|    clip_fraction        | 0.0847       |\n",
            "|    clip_range           | 0.1          |\n",
            "|    entropy_loss         | -1.56        |\n",
            "|    explained_variance   | -1.82        |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | -0.0276      |\n",
            "|    n_updates            | 15372        |\n",
            "|    policy_gradient_loss | -0.00794     |\n",
            "|    value_loss           | 0.00013      |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 591          |\n",
            "|    iterations           | 3845         |\n",
            "|    time_elapsed         | 6651         |\n",
            "|    total_timesteps      | 3937280      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0018385474 |\n",
            "|    clip_fraction        | 0.0657       |\n",
            "|    clip_range           | 0.1          |\n",
            "|    entropy_loss         | -1.49        |\n",
            "|    explained_variance   | -0.00717     |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | -0.00195     |\n",
            "|    n_updates            | 15376        |\n",
            "|    policy_gradient_loss | -0.00227     |\n",
            "|    value_loss           | 0.0169       |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 591          |\n",
            "|    iterations           | 3846         |\n",
            "|    time_elapsed         | 6653         |\n",
            "|    total_timesteps      | 3938304      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0023361149 |\n",
            "|    clip_fraction        | 0.0789       |\n",
            "|    clip_range           | 0.1          |\n",
            "|    entropy_loss         | -1.47        |\n",
            "|    explained_variance   | 0.0109       |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | -0.0286      |\n",
            "|    n_updates            | 15380        |\n",
            "|    policy_gradient_loss | -0.00704     |\n",
            "|    value_loss           | 0.0078       |\n",
            "------------------------------------------\n",
            "----------------------------------------\n",
            "| time/                   |            |\n",
            "|    fps                  | 591        |\n",
            "|    iterations           | 3847       |\n",
            "|    time_elapsed         | 6655       |\n",
            "|    total_timesteps      | 3939328    |\n",
            "| train/                  |            |\n",
            "|    approx_kl            | 0.00462579 |\n",
            "|    clip_fraction        | 0.127      |\n",
            "|    clip_range           | 0.1        |\n",
            "|    entropy_loss         | -1.51      |\n",
            "|    explained_variance   | -1.41      |\n",
            "|    learning_rate        | 0.00025    |\n",
            "|    loss                 | -0.034     |\n",
            "|    n_updates            | 15384      |\n",
            "|    policy_gradient_loss | -0.0125    |\n",
            "|    value_loss           | 0.000138   |\n",
            "----------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 591          |\n",
            "|    iterations           | 3848         |\n",
            "|    time_elapsed         | 6656         |\n",
            "|    total_timesteps      | 3940352      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0045361426 |\n",
            "|    clip_fraction        | 0.111        |\n",
            "|    clip_range           | 0.1          |\n",
            "|    entropy_loss         | -1.55        |\n",
            "|    explained_variance   | -1.42        |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | -0.0364      |\n",
            "|    n_updates            | 15388        |\n",
            "|    policy_gradient_loss | -0.0122      |\n",
            "|    value_loss           | 0.000129     |\n",
            "------------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 591         |\n",
            "|    iterations           | 3849        |\n",
            "|    time_elapsed         | 6658        |\n",
            "|    total_timesteps      | 3941376     |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.003705526 |\n",
            "|    clip_fraction        | 0.134       |\n",
            "|    clip_range           | 0.1         |\n",
            "|    entropy_loss         | -1.55       |\n",
            "|    explained_variance   | -3.13       |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | -0.0477     |\n",
            "|    n_updates            | 15392       |\n",
            "|    policy_gradient_loss | -0.0129     |\n",
            "|    value_loss           | 3.83e-05    |\n",
            "-----------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 591          |\n",
            "|    iterations           | 3850         |\n",
            "|    time_elapsed         | 6659         |\n",
            "|    total_timesteps      | 3942400      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0041521746 |\n",
            "|    clip_fraction        | 0.0981       |\n",
            "|    clip_range           | 0.1          |\n",
            "|    entropy_loss         | -1.56        |\n",
            "|    explained_variance   | 0.0376       |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | -0.0272      |\n",
            "|    n_updates            | 15396        |\n",
            "|    policy_gradient_loss | -0.00788     |\n",
            "|    value_loss           | 0.00763      |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 591          |\n",
            "|    iterations           | 3851         |\n",
            "|    time_elapsed         | 6661         |\n",
            "|    total_timesteps      | 3943424      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0038568429 |\n",
            "|    clip_fraction        | 0.115        |\n",
            "|    clip_range           | 0.1          |\n",
            "|    entropy_loss         | -1.59        |\n",
            "|    explained_variance   | 0.0136       |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | -0.038       |\n",
            "|    n_updates            | 15400        |\n",
            "|    policy_gradient_loss | -0.0159      |\n",
            "|    value_loss           | 0.000147     |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 591          |\n",
            "|    iterations           | 3852         |\n",
            "|    time_elapsed         | 6663         |\n",
            "|    total_timesteps      | 3944448      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0035715392 |\n",
            "|    clip_fraction        | 0.115        |\n",
            "|    clip_range           | 0.1          |\n",
            "|    entropy_loss         | -1.61        |\n",
            "|    explained_variance   | -0.785       |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | -0.0387      |\n",
            "|    n_updates            | 15404        |\n",
            "|    policy_gradient_loss | -0.0125      |\n",
            "|    value_loss           | 0.000173     |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 591          |\n",
            "|    iterations           | 3853         |\n",
            "|    time_elapsed         | 6664         |\n",
            "|    total_timesteps      | 3945472      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0040704357 |\n",
            "|    clip_fraction        | 0.121        |\n",
            "|    clip_range           | 0.1          |\n",
            "|    entropy_loss         | -1.54        |\n",
            "|    explained_variance   | -1.72        |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | -0.0407      |\n",
            "|    n_updates            | 15408        |\n",
            "|    policy_gradient_loss | -0.012       |\n",
            "|    value_loss           | 0.000216     |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 591          |\n",
            "|    iterations           | 3854         |\n",
            "|    time_elapsed         | 6667         |\n",
            "|    total_timesteps      | 3946496      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0025707653 |\n",
            "|    clip_fraction        | 0.0464       |\n",
            "|    clip_range           | 0.1          |\n",
            "|    entropy_loss         | -1.49        |\n",
            "|    explained_variance   | -0.00709     |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | -0.023       |\n",
            "|    n_updates            | 15412        |\n",
            "|    policy_gradient_loss | -0.00599     |\n",
            "|    value_loss           | 0.0161       |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 591          |\n",
            "|    iterations           | 3855         |\n",
            "|    time_elapsed         | 6668         |\n",
            "|    total_timesteps      | 3947520      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0058745923 |\n",
            "|    clip_fraction        | 0.151        |\n",
            "|    clip_range           | 0.1          |\n",
            "|    entropy_loss         | -1.51        |\n",
            "|    explained_variance   | -6.08        |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | -0.0453      |\n",
            "|    n_updates            | 15416        |\n",
            "|    policy_gradient_loss | -0.0183      |\n",
            "|    value_loss           | 6.54e-05     |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 591          |\n",
            "|    iterations           | 3856         |\n",
            "|    time_elapsed         | 6670         |\n",
            "|    total_timesteps      | 3948544      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0052552945 |\n",
            "|    clip_fraction        | 0.154        |\n",
            "|    clip_range           | 0.1          |\n",
            "|    entropy_loss         | -1.51        |\n",
            "|    explained_variance   | -6.48        |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | -0.0425      |\n",
            "|    n_updates            | 15420        |\n",
            "|    policy_gradient_loss | -0.0129      |\n",
            "|    value_loss           | 3.69e-05     |\n",
            "------------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 591         |\n",
            "|    iterations           | 3857        |\n",
            "|    time_elapsed         | 6671        |\n",
            "|    total_timesteps      | 3949568     |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.007377058 |\n",
            "|    clip_fraction        | 0.18        |\n",
            "|    clip_range           | 0.1         |\n",
            "|    entropy_loss         | -1.47       |\n",
            "|    explained_variance   | 0.0215      |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | -0.0244     |\n",
            "|    n_updates            | 15424       |\n",
            "|    policy_gradient_loss | -0.00891    |\n",
            "|    value_loss           | 0.00804     |\n",
            "-----------------------------------------\n",
            "----------------------------------------\n",
            "| time/                   |            |\n",
            "|    fps                  | 591        |\n",
            "|    iterations           | 3858       |\n",
            "|    time_elapsed         | 6673       |\n",
            "|    total_timesteps      | 3950592    |\n",
            "| train/                  |            |\n",
            "|    approx_kl            | 0.00515824 |\n",
            "|    clip_fraction        | 0.132      |\n",
            "|    clip_range           | 0.1        |\n",
            "|    entropy_loss         | -1.57      |\n",
            "|    explained_variance   | -1.62      |\n",
            "|    learning_rate        | 0.00025    |\n",
            "|    loss                 | -0.0454    |\n",
            "|    n_updates            | 15428      |\n",
            "|    policy_gradient_loss | -0.0139    |\n",
            "|    value_loss           | 9.44e-05   |\n",
            "----------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 591          |\n",
            "|    iterations           | 3859         |\n",
            "|    time_elapsed         | 6675         |\n",
            "|    total_timesteps      | 3951616      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0033093658 |\n",
            "|    clip_fraction        | 0.141        |\n",
            "|    clip_range           | 0.1          |\n",
            "|    entropy_loss         | -1.66        |\n",
            "|    explained_variance   | -1.53        |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | -0.0352      |\n",
            "|    n_updates            | 15432        |\n",
            "|    policy_gradient_loss | -0.0123      |\n",
            "|    value_loss           | 4.82e-05     |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 592          |\n",
            "|    iterations           | 3860         |\n",
            "|    time_elapsed         | 6676         |\n",
            "|    total_timesteps      | 3952640      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0049955174 |\n",
            "|    clip_fraction        | 0.12         |\n",
            "|    clip_range           | 0.1          |\n",
            "|    entropy_loss         | -1.57        |\n",
            "|    explained_variance   | -2.1         |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | -0.0428      |\n",
            "|    n_updates            | 15436        |\n",
            "|    policy_gradient_loss | -0.0148      |\n",
            "|    value_loss           | 6.74e-05     |\n",
            "------------------------------------------\n",
            "----------------------------------------\n",
            "| time/                   |            |\n",
            "|    fps                  | 591        |\n",
            "|    iterations           | 3861       |\n",
            "|    time_elapsed         | 6678       |\n",
            "|    total_timesteps      | 3953664    |\n",
            "| train/                  |            |\n",
            "|    approx_kl            | 0.00444736 |\n",
            "|    clip_fraction        | 0.103      |\n",
            "|    clip_range           | 0.1        |\n",
            "|    entropy_loss         | -1.58      |\n",
            "|    explained_variance   | -5         |\n",
            "|    learning_rate        | 0.00025    |\n",
            "|    loss                 | -0.0482    |\n",
            "|    n_updates            | 15440      |\n",
            "|    policy_gradient_loss | -0.016     |\n",
            "|    value_loss           | 4.56e-05   |\n",
            "----------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 591         |\n",
            "|    iterations           | 3862        |\n",
            "|    time_elapsed         | 6680        |\n",
            "|    total_timesteps      | 3954688     |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.005770167 |\n",
            "|    clip_fraction        | 0.153       |\n",
            "|    clip_range           | 0.1         |\n",
            "|    entropy_loss         | -1.58       |\n",
            "|    explained_variance   | 0.0197      |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | -0.0241     |\n",
            "|    n_updates            | 15444       |\n",
            "|    policy_gradient_loss | -0.00805    |\n",
            "|    value_loss           | 0.00793     |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 591         |\n",
            "|    iterations           | 3863        |\n",
            "|    time_elapsed         | 6682        |\n",
            "|    total_timesteps      | 3955712     |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.003008794 |\n",
            "|    clip_fraction        | 0.0774      |\n",
            "|    clip_range           | 0.1         |\n",
            "|    entropy_loss         | -1.61       |\n",
            "|    explained_variance   | -2.43       |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | -0.0361     |\n",
            "|    n_updates            | 15448       |\n",
            "|    policy_gradient_loss | -0.00632    |\n",
            "|    value_loss           | 0.000145    |\n",
            "-----------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 591          |\n",
            "|    iterations           | 3864         |\n",
            "|    time_elapsed         | 6684         |\n",
            "|    total_timesteps      | 3956736      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0035507802 |\n",
            "|    clip_fraction        | 0.129        |\n",
            "|    clip_range           | 0.1          |\n",
            "|    entropy_loss         | -1.63        |\n",
            "|    explained_variance   | -1.26        |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | -0.0333      |\n",
            "|    n_updates            | 15452        |\n",
            "|    policy_gradient_loss | -0.0103      |\n",
            "|    value_loss           | 6.56e-05     |\n",
            "------------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 591         |\n",
            "|    iterations           | 3865        |\n",
            "|    time_elapsed         | 6685        |\n",
            "|    total_timesteps      | 3957760     |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.004170888 |\n",
            "|    clip_fraction        | 0.0925      |\n",
            "|    clip_range           | 0.1         |\n",
            "|    entropy_loss         | -1.63       |\n",
            "|    explained_variance   | -0.87       |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | -0.0402     |\n",
            "|    n_updates            | 15456       |\n",
            "|    policy_gradient_loss | -0.0126     |\n",
            "|    value_loss           | 5.97e-05    |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 591         |\n",
            "|    iterations           | 3866        |\n",
            "|    time_elapsed         | 6687        |\n",
            "|    total_timesteps      | 3958784     |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.003996251 |\n",
            "|    clip_fraction        | 0.115       |\n",
            "|    clip_range           | 0.1         |\n",
            "|    entropy_loss         | -1.59       |\n",
            "|    explained_variance   | -2.95       |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | -0.0364     |\n",
            "|    n_updates            | 15460       |\n",
            "|    policy_gradient_loss | -0.0137     |\n",
            "|    value_loss           | 4.18e-05    |\n",
            "-----------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 591          |\n",
            "|    iterations           | 3867         |\n",
            "|    time_elapsed         | 6688         |\n",
            "|    total_timesteps      | 3959808      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0026334887 |\n",
            "|    clip_fraction        | 0.115        |\n",
            "|    clip_range           | 0.1          |\n",
            "|    entropy_loss         | -1.62        |\n",
            "|    explained_variance   | -2.15        |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | -0.0428      |\n",
            "|    n_updates            | 15464        |\n",
            "|    policy_gradient_loss | -0.0127      |\n",
            "|    value_loss           | 2.11e-05     |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 592          |\n",
            "|    iterations           | 3868         |\n",
            "|    time_elapsed         | 6690         |\n",
            "|    total_timesteps      | 3960832      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0048975134 |\n",
            "|    clip_fraction        | 0.126        |\n",
            "|    clip_range           | 0.1          |\n",
            "|    entropy_loss         | -1.62        |\n",
            "|    explained_variance   | -1.55        |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | -0.0543      |\n",
            "|    n_updates            | 15468        |\n",
            "|    policy_gradient_loss | -0.0169      |\n",
            "|    value_loss           | 2.87e-05     |\n",
            "------------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 591         |\n",
            "|    iterations           | 3869        |\n",
            "|    time_elapsed         | 6692        |\n",
            "|    total_timesteps      | 3961856     |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.004030805 |\n",
            "|    clip_fraction        | 0.0999      |\n",
            "|    clip_range           | 0.1         |\n",
            "|    entropy_loss         | -1.64       |\n",
            "|    explained_variance   | -1.93       |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | -0.0385     |\n",
            "|    n_updates            | 15472       |\n",
            "|    policy_gradient_loss | -0.0144     |\n",
            "|    value_loss           | 2.03e-05    |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 591         |\n",
            "|    iterations           | 3870        |\n",
            "|    time_elapsed         | 6694        |\n",
            "|    total_timesteps      | 3962880     |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.004229695 |\n",
            "|    clip_fraction        | 0.093       |\n",
            "|    clip_range           | 0.1         |\n",
            "|    entropy_loss         | -1.6        |\n",
            "|    explained_variance   | -1.18       |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | -0.0388     |\n",
            "|    n_updates            | 15476       |\n",
            "|    policy_gradient_loss | -0.013      |\n",
            "|    value_loss           | 3.32e-05    |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 591         |\n",
            "|    iterations           | 3871        |\n",
            "|    time_elapsed         | 6696        |\n",
            "|    total_timesteps      | 3963904     |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.002443403 |\n",
            "|    clip_fraction        | 0.146       |\n",
            "|    clip_range           | 0.1         |\n",
            "|    entropy_loss         | -1.65       |\n",
            "|    explained_variance   | -0.72       |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | -0.0441     |\n",
            "|    n_updates            | 15480       |\n",
            "|    policy_gradient_loss | -0.0131     |\n",
            "|    value_loss           | 1.45e-05    |\n",
            "-----------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 591          |\n",
            "|    iterations           | 3872         |\n",
            "|    time_elapsed         | 6697         |\n",
            "|    total_timesteps      | 3964928      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0039115828 |\n",
            "|    clip_fraction        | 0.121        |\n",
            "|    clip_range           | 0.1          |\n",
            "|    entropy_loss         | -1.68        |\n",
            "|    explained_variance   | -2.74        |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | -0.029       |\n",
            "|    n_updates            | 15484        |\n",
            "|    policy_gradient_loss | -0.0108      |\n",
            "|    value_loss           | 1.47e-05     |\n",
            "------------------------------------------\n",
            "----------------------------------------\n",
            "| time/                   |            |\n",
            "|    fps                  | 591        |\n",
            "|    iterations           | 3873       |\n",
            "|    time_elapsed         | 6699       |\n",
            "|    total_timesteps      | 3965952    |\n",
            "| train/                  |            |\n",
            "|    approx_kl            | 0.00411854 |\n",
            "|    clip_fraction        | 0.162      |\n",
            "|    clip_range           | 0.1        |\n",
            "|    entropy_loss         | -1.64      |\n",
            "|    explained_variance   | -5.57      |\n",
            "|    learning_rate        | 0.00025    |\n",
            "|    loss                 | -0.034     |\n",
            "|    n_updates            | 15488      |\n",
            "|    policy_gradient_loss | -0.0107    |\n",
            "|    value_loss           | 1.42e-05   |\n",
            "----------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 591          |\n",
            "|    iterations           | 3874         |\n",
            "|    time_elapsed         | 6700         |\n",
            "|    total_timesteps      | 3966976      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0034514635 |\n",
            "|    clip_fraction        | 0.0979       |\n",
            "|    clip_range           | 0.1          |\n",
            "|    entropy_loss         | -1.57        |\n",
            "|    explained_variance   | -0.372       |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | -0.045       |\n",
            "|    n_updates            | 15492        |\n",
            "|    policy_gradient_loss | -0.0127      |\n",
            "|    value_loss           | 3.3e-05      |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 592          |\n",
            "|    iterations           | 3875         |\n",
            "|    time_elapsed         | 6702         |\n",
            "|    total_timesteps      | 3968000      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0024608336 |\n",
            "|    clip_fraction        | 0.0859       |\n",
            "|    clip_range           | 0.1          |\n",
            "|    entropy_loss         | -1.65        |\n",
            "|    explained_variance   | -0.54        |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | -0.0396      |\n",
            "|    n_updates            | 15496        |\n",
            "|    policy_gradient_loss | -0.0128      |\n",
            "|    value_loss           | 9.29e-06     |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 592          |\n",
            "|    iterations           | 3876         |\n",
            "|    time_elapsed         | 6704         |\n",
            "|    total_timesteps      | 3969024      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0033843548 |\n",
            "|    clip_fraction        | 0.108        |\n",
            "|    clip_range           | 0.1          |\n",
            "|    entropy_loss         | -1.66        |\n",
            "|    explained_variance   | -0.857       |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | -0.0426      |\n",
            "|    n_updates            | 15500        |\n",
            "|    policy_gradient_loss | -0.013       |\n",
            "|    value_loss           | 9.82e-06     |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 591          |\n",
            "|    iterations           | 3877         |\n",
            "|    time_elapsed         | 6706         |\n",
            "|    total_timesteps      | 3970048      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0033661835 |\n",
            "|    clip_fraction        | 0.127        |\n",
            "|    clip_range           | 0.1          |\n",
            "|    entropy_loss         | -1.65        |\n",
            "|    explained_variance   | -0.00551     |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | -0.0266      |\n",
            "|    n_updates            | 15504        |\n",
            "|    policy_gradient_loss | -0.00626     |\n",
            "|    value_loss           | 0.00798      |\n",
            "------------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 591         |\n",
            "|    iterations           | 3878        |\n",
            "|    time_elapsed         | 6708        |\n",
            "|    total_timesteps      | 3971072     |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.003237445 |\n",
            "|    clip_fraction        | 0.0928      |\n",
            "|    clip_range           | 0.1         |\n",
            "|    entropy_loss         | -1.7        |\n",
            "|    explained_variance   | 0.469       |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | -0.0465     |\n",
            "|    n_updates            | 15508       |\n",
            "|    policy_gradient_loss | -0.0135     |\n",
            "|    value_loss           | 8.79e-05    |\n",
            "-----------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 591          |\n",
            "|    iterations           | 3879         |\n",
            "|    time_elapsed         | 6709         |\n",
            "|    total_timesteps      | 3972096      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0035434181 |\n",
            "|    clip_fraction        | 0.0969       |\n",
            "|    clip_range           | 0.1          |\n",
            "|    entropy_loss         | -1.7         |\n",
            "|    explained_variance   | -0.146       |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | -0.0402      |\n",
            "|    n_updates            | 15512        |\n",
            "|    policy_gradient_loss | -0.00969     |\n",
            "|    value_loss           | 0.000122     |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 591          |\n",
            "|    iterations           | 3880         |\n",
            "|    time_elapsed         | 6711         |\n",
            "|    total_timesteps      | 3973120      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0044115307 |\n",
            "|    clip_fraction        | 0.114        |\n",
            "|    clip_range           | 0.1          |\n",
            "|    entropy_loss         | -1.67        |\n",
            "|    explained_variance   | -1.34        |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | -0.0447      |\n",
            "|    n_updates            | 15516        |\n",
            "|    policy_gradient_loss | -0.0143      |\n",
            "|    value_loss           | 4.86e-05     |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 592          |\n",
            "|    iterations           | 3881         |\n",
            "|    time_elapsed         | 6713         |\n",
            "|    total_timesteps      | 3974144      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0030234319 |\n",
            "|    clip_fraction        | 0.075        |\n",
            "|    clip_range           | 0.1          |\n",
            "|    entropy_loss         | -1.69        |\n",
            "|    explained_variance   | -1.13        |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | -0.0415      |\n",
            "|    n_updates            | 15520        |\n",
            "|    policy_gradient_loss | -0.0121      |\n",
            "|    value_loss           | 2.3e-05      |\n",
            "------------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 592         |\n",
            "|    iterations           | 3882        |\n",
            "|    time_elapsed         | 6714        |\n",
            "|    total_timesteps      | 3975168     |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.004438804 |\n",
            "|    clip_fraction        | 0.109       |\n",
            "|    clip_range           | 0.1         |\n",
            "|    entropy_loss         | -1.66       |\n",
            "|    explained_variance   | -1.61       |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | -0.0471     |\n",
            "|    n_updates            | 15524       |\n",
            "|    policy_gradient_loss | -0.0144     |\n",
            "|    value_loss           | 1.63e-05    |\n",
            "-----------------------------------------\n",
            "----------------------------------------\n",
            "| time/                   |            |\n",
            "|    fps                  | 592        |\n",
            "|    iterations           | 3883       |\n",
            "|    time_elapsed         | 6716       |\n",
            "|    total_timesteps      | 3976192    |\n",
            "| train/                  |            |\n",
            "|    approx_kl            | 0.00329992 |\n",
            "|    clip_fraction        | 0.0815     |\n",
            "|    clip_range           | 0.1        |\n",
            "|    entropy_loss         | -1.73      |\n",
            "|    explained_variance   | -0.0661    |\n",
            "|    learning_rate        | 0.00025    |\n",
            "|    loss                 | -0.0446    |\n",
            "|    n_updates            | 15528      |\n",
            "|    policy_gradient_loss | -0.0116    |\n",
            "|    value_loss           | 1.47e-05   |\n",
            "----------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 592          |\n",
            "|    iterations           | 3884         |\n",
            "|    time_elapsed         | 6718         |\n",
            "|    total_timesteps      | 3977216      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0044160886 |\n",
            "|    clip_fraction        | 0.111        |\n",
            "|    clip_range           | 0.1          |\n",
            "|    entropy_loss         | -1.67        |\n",
            "|    explained_variance   | -0.478       |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | -0.0426      |\n",
            "|    n_updates            | 15532        |\n",
            "|    policy_gradient_loss | -0.0142      |\n",
            "|    value_loss           | 2.11e-05     |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 591          |\n",
            "|    iterations           | 3885         |\n",
            "|    time_elapsed         | 6720         |\n",
            "|    total_timesteps      | 3978240      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0035552252 |\n",
            "|    clip_fraction        | 0.082        |\n",
            "|    clip_range           | 0.1          |\n",
            "|    entropy_loss         | -1.7         |\n",
            "|    explained_variance   | -2.43        |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | -0.0394      |\n",
            "|    n_updates            | 15536        |\n",
            "|    policy_gradient_loss | -0.0114      |\n",
            "|    value_loss           | 1.85e-05     |\n",
            "------------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 591         |\n",
            "|    iterations           | 3886        |\n",
            "|    time_elapsed         | 6722        |\n",
            "|    total_timesteps      | 3979264     |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.004183855 |\n",
            "|    clip_fraction        | 0.107       |\n",
            "|    clip_range           | 0.1         |\n",
            "|    entropy_loss         | -1.63       |\n",
            "|    explained_variance   | -2.73       |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | -0.0492     |\n",
            "|    n_updates            | 15540       |\n",
            "|    policy_gradient_loss | -0.0157     |\n",
            "|    value_loss           | 3.96e-05    |\n",
            "-----------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 591          |\n",
            "|    iterations           | 3887         |\n",
            "|    time_elapsed         | 6723         |\n",
            "|    total_timesteps      | 3980288      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0032699462 |\n",
            "|    clip_fraction        | 0.0911       |\n",
            "|    clip_range           | 0.1          |\n",
            "|    entropy_loss         | -1.68        |\n",
            "|    explained_variance   | -1.01        |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | -0.0454      |\n",
            "|    n_updates            | 15544        |\n",
            "|    policy_gradient_loss | -0.0118      |\n",
            "|    value_loss           | 2.01e-05     |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 591          |\n",
            "|    iterations           | 3888         |\n",
            "|    time_elapsed         | 6725         |\n",
            "|    total_timesteps      | 3981312      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0032198217 |\n",
            "|    clip_fraction        | 0.0964       |\n",
            "|    clip_range           | 0.1          |\n",
            "|    entropy_loss         | -1.67        |\n",
            "|    explained_variance   | -1.57        |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | -0.0562      |\n",
            "|    n_updates            | 15548        |\n",
            "|    policy_gradient_loss | -0.0156      |\n",
            "|    value_loss           | 2.16e-05     |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 592          |\n",
            "|    iterations           | 3889         |\n",
            "|    time_elapsed         | 6726         |\n",
            "|    total_timesteps      | 3982336      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0034200705 |\n",
            "|    clip_fraction        | 0.105        |\n",
            "|    clip_range           | 0.1          |\n",
            "|    entropy_loss         | -1.69        |\n",
            "|    explained_variance   | -2.25        |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | -0.0414      |\n",
            "|    n_updates            | 15552        |\n",
            "|    policy_gradient_loss | -0.0151      |\n",
            "|    value_loss           | 1.19e-05     |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 592          |\n",
            "|    iterations           | 3890         |\n",
            "|    time_elapsed         | 6728         |\n",
            "|    total_timesteps      | 3983360      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0035728517 |\n",
            "|    clip_fraction        | 0.0989       |\n",
            "|    clip_range           | 0.1          |\n",
            "|    entropy_loss         | -1.67        |\n",
            "|    explained_variance   | -2.76        |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | -0.0506      |\n",
            "|    n_updates            | 15556        |\n",
            "|    policy_gradient_loss | -0.0159      |\n",
            "|    value_loss           | 1.35e-05     |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 592          |\n",
            "|    iterations           | 3891         |\n",
            "|    time_elapsed         | 6730         |\n",
            "|    total_timesteps      | 3984384      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0024836087 |\n",
            "|    clip_fraction        | 0.0891       |\n",
            "|    clip_range           | 0.1          |\n",
            "|    entropy_loss         | -1.69        |\n",
            "|    explained_variance   | -1.61        |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | -0.0461      |\n",
            "|    n_updates            | 15560        |\n",
            "|    policy_gradient_loss | -0.0141      |\n",
            "|    value_loss           | 1.2e-05      |\n",
            "------------------------------------------\n",
            "----------------------------------------\n",
            "| time/                   |            |\n",
            "|    fps                  | 591        |\n",
            "|    iterations           | 3892       |\n",
            "|    time_elapsed         | 6732       |\n",
            "|    total_timesteps      | 3985408    |\n",
            "| train/                  |            |\n",
            "|    approx_kl            | 0.00419658 |\n",
            "|    clip_fraction        | 0.122      |\n",
            "|    clip_range           | 0.1        |\n",
            "|    entropy_loss         | -1.71      |\n",
            "|    explained_variance   | -2.43      |\n",
            "|    learning_rate        | 0.00025    |\n",
            "|    loss                 | -0.0424    |\n",
            "|    n_updates            | 15564      |\n",
            "|    policy_gradient_loss | -0.0157    |\n",
            "|    value_loss           | 1.1e-05    |\n",
            "----------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 591          |\n",
            "|    iterations           | 3893         |\n",
            "|    time_elapsed         | 6734         |\n",
            "|    total_timesteps      | 3986432      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0027512312 |\n",
            "|    clip_fraction        | 0.0762       |\n",
            "|    clip_range           | 0.1          |\n",
            "|    entropy_loss         | -1.66        |\n",
            "|    explained_variance   | -1.29        |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | -0.0431      |\n",
            "|    n_updates            | 15568        |\n",
            "|    policy_gradient_loss | -0.0135      |\n",
            "|    value_loss           | 1.1e-05      |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 591          |\n",
            "|    iterations           | 3894         |\n",
            "|    time_elapsed         | 6735         |\n",
            "|    total_timesteps      | 3987456      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0030114516 |\n",
            "|    clip_fraction        | 0.0842       |\n",
            "|    clip_range           | 0.1          |\n",
            "|    entropy_loss         | -1.7         |\n",
            "|    explained_variance   | -1.94        |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | -0.0415      |\n",
            "|    n_updates            | 15572        |\n",
            "|    policy_gradient_loss | -0.0123      |\n",
            "|    value_loss           | 6.47e-06     |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 591          |\n",
            "|    iterations           | 3895         |\n",
            "|    time_elapsed         | 6737         |\n",
            "|    total_timesteps      | 3988480      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0045504184 |\n",
            "|    clip_fraction        | 0.115        |\n",
            "|    clip_range           | 0.1          |\n",
            "|    entropy_loss         | -1.67        |\n",
            "|    explained_variance   | -4.91        |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | -0.0459      |\n",
            "|    n_updates            | 15576        |\n",
            "|    policy_gradient_loss | -0.0147      |\n",
            "|    value_loss           | 1.15e-05     |\n",
            "------------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 592         |\n",
            "|    iterations           | 3896        |\n",
            "|    time_elapsed         | 6738        |\n",
            "|    total_timesteps      | 3989504     |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.004075719 |\n",
            "|    clip_fraction        | 0.0906      |\n",
            "|    clip_range           | 0.1         |\n",
            "|    entropy_loss         | -1.67       |\n",
            "|    explained_variance   | 0.0453      |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | -0.0249     |\n",
            "|    n_updates            | 15580       |\n",
            "|    policy_gradient_loss | -0.0099     |\n",
            "|    value_loss           | 0.00754     |\n",
            "-----------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 592          |\n",
            "|    iterations           | 3897         |\n",
            "|    time_elapsed         | 6740         |\n",
            "|    total_timesteps      | 3990528      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0023020725 |\n",
            "|    clip_fraction        | 0.0408       |\n",
            "|    clip_range           | 0.1          |\n",
            "|    entropy_loss         | -1.64        |\n",
            "|    explained_variance   | -0.0089      |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | -0.0223      |\n",
            "|    n_updates            | 15584        |\n",
            "|    policy_gradient_loss | -0.00724     |\n",
            "|    value_loss           | 0.0172       |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 592          |\n",
            "|    iterations           | 3898         |\n",
            "|    time_elapsed         | 6741         |\n",
            "|    total_timesteps      | 3991552      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0049516093 |\n",
            "|    clip_fraction        | 0.151        |\n",
            "|    clip_range           | 0.1          |\n",
            "|    entropy_loss         | -1.54        |\n",
            "|    explained_variance   | -0.456       |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | -0.0466      |\n",
            "|    n_updates            | 15588        |\n",
            "|    policy_gradient_loss | -0.0155      |\n",
            "|    value_loss           | 9.11e-05     |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 592          |\n",
            "|    iterations           | 3899         |\n",
            "|    time_elapsed         | 6743         |\n",
            "|    total_timesteps      | 3992576      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0041685235 |\n",
            "|    clip_fraction        | 0.121        |\n",
            "|    clip_range           | 0.1          |\n",
            "|    entropy_loss         | -1.58        |\n",
            "|    explained_variance   | -0.0137      |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | -0.0428      |\n",
            "|    n_updates            | 15592        |\n",
            "|    policy_gradient_loss | -0.0149      |\n",
            "|    value_loss           | 4.78e-05     |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 592          |\n",
            "|    iterations           | 3900         |\n",
            "|    time_elapsed         | 6745         |\n",
            "|    total_timesteps      | 3993600      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0037888275 |\n",
            "|    clip_fraction        | 0.0894       |\n",
            "|    clip_range           | 0.1          |\n",
            "|    entropy_loss         | -1.56        |\n",
            "|    explained_variance   | -0.28        |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | -0.0429      |\n",
            "|    n_updates            | 15596        |\n",
            "|    policy_gradient_loss | -0.0133      |\n",
            "|    value_loss           | 2.14e-05     |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 592          |\n",
            "|    iterations           | 3901         |\n",
            "|    time_elapsed         | 6747         |\n",
            "|    total_timesteps      | 3994624      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0048335125 |\n",
            "|    clip_fraction        | 0.12         |\n",
            "|    clip_range           | 0.1          |\n",
            "|    entropy_loss         | -1.58        |\n",
            "|    explained_variance   | -0.0814      |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | -0.0339      |\n",
            "|    n_updates            | 15600        |\n",
            "|    policy_gradient_loss | -0.013       |\n",
            "|    value_loss           | 3.52e-05     |\n",
            "------------------------------------------\n",
            "----------------------------------------\n",
            "| time/                   |            |\n",
            "|    fps                  | 592        |\n",
            "|    iterations           | 3902       |\n",
            "|    time_elapsed         | 6749       |\n",
            "|    total_timesteps      | 3995648    |\n",
            "| train/                  |            |\n",
            "|    approx_kl            | 0.00403394 |\n",
            "|    clip_fraction        | 0.113      |\n",
            "|    clip_range           | 0.1        |\n",
            "|    entropy_loss         | -1.59      |\n",
            "|    explained_variance   | -0.248     |\n",
            "|    learning_rate        | 0.00025    |\n",
            "|    loss                 | -0.0506    |\n",
            "|    n_updates            | 15604      |\n",
            "|    policy_gradient_loss | -0.0156    |\n",
            "|    value_loss           | 3.91e-05   |\n",
            "----------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 592         |\n",
            "|    iterations           | 3903        |\n",
            "|    time_elapsed         | 6750        |\n",
            "|    total_timesteps      | 3996672     |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.004182863 |\n",
            "|    clip_fraction        | 0.151       |\n",
            "|    clip_range           | 0.1         |\n",
            "|    entropy_loss         | -1.6        |\n",
            "|    explained_variance   | -0.279      |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | -0.0518     |\n",
            "|    n_updates            | 15608       |\n",
            "|    policy_gradient_loss | -0.0165     |\n",
            "|    value_loss           | 1.95e-05    |\n",
            "-----------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 592          |\n",
            "|    iterations           | 3904         |\n",
            "|    time_elapsed         | 6752         |\n",
            "|    total_timesteps      | 3997696      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0036225508 |\n",
            "|    clip_fraction        | 0.104        |\n",
            "|    clip_range           | 0.1          |\n",
            "|    entropy_loss         | -1.67        |\n",
            "|    explained_variance   | 0.0836       |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | -0.046       |\n",
            "|    n_updates            | 15612        |\n",
            "|    policy_gradient_loss | -0.0139      |\n",
            "|    value_loss           | 1.33e-05     |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 592          |\n",
            "|    iterations           | 3905         |\n",
            "|    time_elapsed         | 6753         |\n",
            "|    total_timesteps      | 3998720      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0040229033 |\n",
            "|    clip_fraction        | 0.119        |\n",
            "|    clip_range           | 0.1          |\n",
            "|    entropy_loss         | -1.59        |\n",
            "|    explained_variance   | -0.359       |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | -0.0471      |\n",
            "|    n_updates            | 15616        |\n",
            "|    policy_gradient_loss | -0.0155      |\n",
            "|    value_loss           | 1.41e-05     |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 592          |\n",
            "|    iterations           | 3906         |\n",
            "|    time_elapsed         | 6755         |\n",
            "|    total_timesteps      | 3999744      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0040345523 |\n",
            "|    clip_fraction        | 0.121        |\n",
            "|    clip_range           | 0.1          |\n",
            "|    entropy_loss         | -1.55        |\n",
            "|    explained_variance   | -4.14        |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | -0.0464      |\n",
            "|    n_updates            | 15620        |\n",
            "|    policy_gradient_loss | -0.015       |\n",
            "|    value_loss           | 1.65e-05     |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 592          |\n",
            "|    iterations           | 3907         |\n",
            "|    time_elapsed         | 6757         |\n",
            "|    total_timesteps      | 4000768      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0037683314 |\n",
            "|    clip_fraction        | 0.126        |\n",
            "|    clip_range           | 0.1          |\n",
            "|    entropy_loss         | -1.53        |\n",
            "|    explained_variance   | -8.25        |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | -0.0432      |\n",
            "|    n_updates            | 15624        |\n",
            "|    policy_gradient_loss | -0.0147      |\n",
            "|    value_loss           | 1.46e-05     |\n",
            "------------------------------------------\n",
            "Training gereed.\n",
            "Model opgeslagen als ppo_model_warlords_4m\n",
            "Model opgeslagen als /content/drive/MyDrive/MARL_models/warlords_ppo_model_4m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "save_path = \"/content/drive/MyDrive/MARL_models\"\n",
        "\n",
        "\n",
        "os.makedirs(save_path, exist_ok=True)\n",
        "\n",
        "model_name = os.path.join(save_path, \"warlords_ppo_model\")\n",
        "agent.save(model_name)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0nYFI8LsqF1G",
        "outputId": "067f412f-cd67-4ab5-877f-e87cd35fec68"
      },
      "id": "0nYFI8LsqF1G",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model opgeslagen als /content/drive/MyDrive/MARL_models/warlords_ppo_model\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "agent.load(\"ppo_model_warlords\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ProZJWxRpZuo",
        "outputId": "0ffc531e-c3b1-4ec0-a03d-d40ad18729a9"
      },
      "id": "ProZJWxRpZuo",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model geladen van ppo_model_warlords\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_path = \"/content/drive/MyDrive/MARL_models/warlords_ppo_model_4m.zip\"\n",
        "agent.load(model_path)"
      ],
      "metadata": {
        "id": "YujIDpuSqzCs"
      },
      "id": "YujIDpuSqzCs",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "210914e9",
      "metadata": {
        "id": "210914e9"
      },
      "source": [
        "\n",
        "---\n",
        "<div style=\"background-color:LightBlue; text-align:center; vertical-align:middle; padding:50px 0; margin-top:5px; margin-bottom:5px\">\n",
        "    <h2 id=\"eda-title\" style=\"color:black; font-family: Verdana, sans-serif; font-size: 25px;\"><strong>H5: Training en Hyperparameter Search</strong></h2>\n",
        "</div>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1c0e45d6",
      "metadata": {
        "id": "1c0e45d6"
      },
      "source": [
        "<a name='1.1'></a>\n",
        "<h3>&sect;5.1: Training</h3>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Hoe verloopt de training van een PPO-agent?\n",
        "\n",
        "De training van een PPO-agent (Proximal Policy Optimization) in een omgeving zoals Atari Warlords bestaat uit een reeks vaste stappen die gericht zijn op stabiliteit en efficiënt leren. Tijdens elke trainingscyclus verzamelt de agent zogenaamde 'rollouts': sequenties van observaties, acties en rewards die worden gegenereerd door het huidige beleid. Op basis van deze trajecten berekent PPO met Generalized Advantage Estimation (GAE) hoe gunstig elke actie was ten opzichte van de verwachting, wat helpt om het leerproces stabieler en nauwkeuriger te maken.\n",
        "\n",
        "De kern van PPO ligt in het voorzichtig updaten van het beleid. In plaats van grote stappen (die tot instabiliteit kunnen leiden), worden policy-updates beperkt door een clipping-mechanisme. Dit voorkomt dat het geleerde beleid te veel verandert per trainingsstap, waardoor de kans op catastrofaal “vergeten” sterk wordt verminderd. De verzamelde rollouts worden verdeeld over mini-batches en gedurende meerdere epochs gebruikt om zowel het beleid (policy) als de value-functie (critic) te verbeteren. Tegelijkertijd stimuleert PPO via een entropiebonus dat de agent in het begin veel blijft exploreren, wat de kans op het vinden van sterke strategieën vergroot.\n",
        "\n",
        "Tijdens en na de training wordt de agent regelmatig geëvalueerd zonder extra ruis, zodat duidelijk wordt hoe effectief het geleerde beleid is in de praktijk. Door deze aanpak is PPO bijzonder geschikt voor complexe, visuele en multi-agent omgevingen, waarbij gecontroleerd leren en robuuste prestaties essentieel zijn.\n"
      ],
      "metadata": {
        "id": "vO98uFAF_FCz"
      },
      "id": "vO98uFAF_FCz"
    },
    {
      "cell_type": "markdown",
      "source": [
        "<div style=\"background-color:white; color:black; padding: 10px;\">\n",
        "    <strong>Omgeving opzetten</strong>\n",
        "</div>\n",
        "\n",
        "\n",
        "In deze stap initialiseren we de multi-agent Warlords-omgeving met behulp van PettingZoo. We passen verschillende bewerkingen toe op de raw game frames:\n",
        "- `warlords_v3.parallel_env()`: Laadt de 4-speler Warlords-omgeving waarbij alle agents gelijktijdig acties nemen.\n",
        "- `ss.black_death_v3(env)`: Zorgt ervoor dat agents die \"dood\" gaan toch in de omgeving blijven als placeholder, zodat de agent-count altijd gelijk blijft.\n",
        "- `ss.color_reduction_v0(env, mode='full')`: Zet de gekleurde frames om naar grijswaarden, waardoor de inputdimensie kleiner wordt en het leren efficiënter.\n",
        "- `ss.resize_v1(env, x_size=84, y_size=84)`: Schaal de beelden terug naar 84x84 pixels (standaard in Atari-RL-onderzoek).\n",
        "- `ss.frame_stack_v1(env, 4)`: Stapelt de laatste 4 frames, zodat het model ook bewegingsinformatie kan oppikken (belangrijk bij visuele input).\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "W5whiJBiBH11"
      },
      "id": "W5whiJBiBH11"
    },
    {
      "cell_type": "markdown",
      "source": [
        "<div style=\"background-color:white; color:black; padding: 10px;\">\n",
        "    <strong>Converteren naar een vectorized env voor Stable-Baselines3</strong>\n",
        "</div>\n",
        "\n",
        "Stable-Baselines3 werkt het best met vectorized environments, waarbij meerdere instanties van de omgeving parallel kunnen draaien:\n",
        "- `ss.pettingzoo_env_to_vec_env_v1(env)`: Zet de PettingZoo-omgeving om naar een formaat dat door SB3 wordt herkend.\n",
        "- `ss.concat_vec_envs_v1(...)`: Combineert meerdere vectorized omgevingen tot één, zodat batchgewijze training mogelijk is (hier draaien 2 parallelle omgevingen op 1 CPU).\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "5sisIiBjE1ji"
      },
      "id": "5sisIiBjE1ji"
    },
    {
      "cell_type": "markdown",
      "source": [
        "<div style=\"background-color:white; color:black; padding: 10px;\">\n",
        "    <strong>Defineren en trainen van het PPO model</strong>\n",
        "</div>\n",
        "\n",
        "We definiëren het PPO-model dat gebruikmaakt van een convolutioneel neuraal netwerk (CnnPolicy), geschikt voor visuele input zoals Atari-frames:\n",
        "- `PPO(CnnPolicy, vec_env, ...)`: Initialiseer het PPO-algoritme met de eerder gemaakte vectorized environment.\n",
        "- `total_timesteps`: Bepaalt hoe lang het model traint. Meer timesteps betekent meestal beter getrainde agenten.\n",
        "- `model.learn(...)`: Start het daadwerkelijke leerproces. Het model verzamelt data, leert van ervaringen en past het beleid continu aan.\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "vLtNh7tEozmE"
      },
      "id": "vLtNh7tEozmE"
    },
    {
      "cell_type": "markdown",
      "source": [
        "<div style=\"background-color:white; color:black; padding: 10px;\">\n",
        "    <strong>Opslaan van het getrainde model met timestamp</strong>\n",
        "</div>\n",
        "\n",
        "Na de training slaan we het model op, waarbij automatisch een timestamp aan de bestandsnaam wordt toegevoegd:\n",
        "- `time.strftime(...)`: Maakt een string van de huidige datum en tijd.\n",
        "- `model.save(model_name)`: Slaat het getrainde model op onder een unieke naam, zodat je het later gemakkelijk kunt laden en evalueren.\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "4-c6Bba0EduX"
      },
      "id": "4-c6Bba0EduX"
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Interpretatie van de PPO Trainingsoutput\n",
        "\n",
        "Tijdens het trainen van het PPO-model worden verschillende statistieken gelogd. Hieronder lichten we de belangrijkste waarden uit, zodat duidelijk wordt wat ze betekenen en hoe ze geïnterpreteerd kunnen worden:\n",
        "\n",
        "| **Metric**               | **Waarde**      | **Toelichting**                                                                                                                                             |\n",
        "|------------------------- |-----------------|-------------------------------------------------------------------------------------------------------------------------------------------------------------|\n",
        "| **fps**                  | 472             | *Frames per second* – het aantal frames (omgevingsstappen) dat per seconde wordt verwerkt. Een hoge waarde betekent dat het trainen efficiënt verloopt.     |\n",
        "| **iterations**           | 8               | Aantal PPO-updates die zijn uitgevoerd sinds de start van de training.                                                                                      |\n",
        "| **time_elapsed**         | 277             | Totale verstreken tijd (in seconden) sinds het begin van de training.                                                                                       |\n",
        "| **total_timesteps**      | 131072          | Het aantal omgevingsstappen (frames/acties) dat het model tot nu toe heeft gezien.                                                                          |\n",
        "\n",
        "### Train-metrics\n",
        "\n",
        "| **Metric**                   | **Waarde**        | **Toelichting**                                                                                                                                             |\n",
        "|------------------------------|-------------------|-------------------------------------------------------------------------------------------------------------------------------------------------------------|\n",
        "| **approx_kl**                | 0.00897           | Gemiddelde KL-divergence tussen het oude en het nieuwe beleid. Een lage waarde duidt op kleine wijzigingen per update, wat zorgt voor stabiel leren.         |\n",
        "| **clip_fraction**            | 0.088             | Percentage van de policy-updates die beperkt (“geclipped”) werden. Veel clipping betekent dat het model te grote stappen probeert te maken (mogelijk instabiel). |\n",
        "| **clip_range**               | 0.2               | Maximale toegestane relatieve verandering per update (standaard bij PPO).                                                                                   |\n",
        "| **entropy_loss**             | -1.77             | De entropie van het beleid: een maat voor exploratie. Een lagere (meer negatieve) waarde betekent dat het beleid voorspelbaarder wordt (minder exploratie).   |\n",
        "| **explained_variance**       | -0.0209           | Meet hoe goed de value-functie de daadwerkelijke rewards voorspelt (1.0 = perfect, 0 = slecht, <0 = erger dan gokken).                                      |\n",
        "| **learning_rate**            | 0.0003            | De snelheid waarmee het model leert; hogere waardes versnellen leren, maar kunnen leiden tot instabiliteit.                                                 |\n",
        "| **loss**                     | -0.0226           | Totale loss-functie (mix van policy, value en entropy loss) die wordt geminimaliseerd tijdens training.                                                     |\n",
        "| **n_updates**                | 70                | Totaal aantal policy-updates tot nu toe uitgevoerd.                                                                                                         |\n",
        "| **policy_gradient_loss**     | -0.0133           | De bijdrage van de policy-gradient aan de totale loss. Negatiever betekent sterkere updates in de richting van meer reward.                                 |\n",
        "| **value_loss**               | 0.00265           | Fout van de value-functie; hoe kleiner, hoe beter het model toekomstige rewards kan voorspellen.                                                            |\n",
        "\n",
        "---\n",
        "\n",
        "### Richting van de Waarden: Wat wil je zien?\n",
        "\n",
        "- **fps**: Hoger is beter – snellere training.\n",
        "- **iterations / n_updates / total_timesteps**: Hoger betekent meer getraind (maar let op overfitting).\n",
        "- **approx_kl**: Laag (bijv. tussen 0.01 en 0.05) = stabiel leren. Te hoog: beleid verandert te snel en wordt instabiel; te laag: leren gaat traag.\n",
        "- **clip_fraction**: Typisch rond 0.1–0.3. Te hoog kan instabiliteit betekenen, te laag kan duiden op te weinig leereffect.\n",
        "- **entropy_loss**: Minder negatief betekent meer exploratie. Naarmate het model zekerder wordt, daalt de entropie. Een te lage entropie betekent mogelijk te weinig exploratie.\n",
        "- **explained_variance**: Hoger is beter. Richtwaarde: richting 1.0 is perfect, 0 is slecht, <0 betekent dat de value-functie slechter presteert dan gokken.\n",
        "- **learning_rate**: Hogere waardes versnellen het leren maar verhogen het risico op instabiliteit.\n",
        "- **loss / value_loss**: Lager is beter – betekent dat het model beter de returns/value weet te voorspellen en de policy verbetert.\n",
        "\n",
        "#### **Samenvatting**\n",
        "Deze statistieken geven inzicht in hoe snel en stabiel het PPO-model leert. Let vooral op de **KL-divergence** (voor stabiliteit), **clip_fraction** (voor learning dynamics), en **explained_variance** (voor de nauwkeurigheid van de value-voorspelling).\n"
      ],
      "metadata": {
        "id": "fLeX-0iZqR8g"
      },
      "id": "fLeX-0iZqR8g"
    },
    {
      "cell_type": "markdown",
      "id": "459b8c33",
      "metadata": {
        "id": "459b8c33"
      },
      "source": [
        "<a name='1.1'></a>\n",
        "<h3>&sect;5.2: Selectie en tuning van hyperparameters</h3>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Hyperparameters**\n",
        "\n",
        "##### ***Overzicht keuzes***\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "| Hyperparameter        | Waarde    | Uitleg                                                                                 |\n",
        "|----------------------|-----------|----------------------------------------------------------------------------------------|\n",
        "| `Policy`              | CnnPolicy | Gebruikt convolutieneurale netwerken, geschikt voor beeldinput zoals bij Atari-games   |\n",
        "| `learning_rate`        | 2.5e-4    | Standaardwaarde voor PPO in Atari-omgevingen; zorgt voor een goede balans tussen snel leren en stabiliteit |\n",
        "| `gamma`                | 0.99      | Kortingfactor; waardeert toekomstige beloningen bijna net zo hoog als directe beloning |\n",
        "| `n_steps`              | 128       | Aantal stappen per update; bepaalt hoeveel ervaringen per batch worden verzameld       |\n",
        "| `batch_size`           | 256       | Grootte van elke batch die wordt gebruikt tijdens het updaten van het beleid           |\n",
        "| `ent_coef (entropie)`  | 0.01      | Coëfficiënt voor exploratie; hogere waarde zorgt voor meer exploratiegedrag            |\n",
        "| `verbose`              | 1         | Zorgt voor gedetailleerde logging tijdens het trainen                                  |\n",
        "\n",
        "#### **Experimenteren met hyperparameters**\n",
        "Tijdens het trainen heb ik geëxperimenteerd met verschillende waarden voor de learning rate, entropie-coëfficiënt en batch size:\n",
        "- **Learning rate:** Een hogere learning rate zorgde voor snellere training, maar maakte het model soms instabiel. 2.5e-4 bleek een goed compromis.\n",
        "- **Entropie-coëfficiënt (ent_coef):** Met een hogere waarde ging de agent meer experimenteren, maar duurde het langer voordat hij goed leerde. 0.01 gaf een goede balans.\n",
        "- **Batch size:** Grotere batches zorgden voor stabielere updates, maar vroegen meer geheugen.\n",
        "\n",
        "De uiteindelijke hyperparameterkeuzes zijn gebaseerd op wat het beste werkte voor deze specifieke omgeving en op basis van literatuur.\n",
        "\n"
      ],
      "metadata": {
        "id": "7glSKPkivIs3"
      },
      "id": "7glSKPkivIs3"
    },
    {
      "cell_type": "markdown",
      "id": "3eff6630",
      "metadata": {
        "id": "3eff6630"
      },
      "source": [
        "\n",
        "---\n",
        "<div style=\"background-color:LightBlue; text-align:center; vertical-align:middle; padding:50px 0; margin-top:5px; margin-bottom:5px\">\n",
        "    <h2 id=\"eda-title\" style=\"color:black; font-family: Verdana, sans-serif; font-size: 25px;\"><strong>H6: Evaluatie en Vergelijking</strong></h2>\n",
        "</div>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b824fae3",
      "metadata": {
        "id": "b824fae3"
      },
      "source": [
        "<a name='1.1'></a>\n",
        "<h3>&sect;6.1: Evaluatie t.o.v. baseline</h3>\n",
        "\n",
        "Om de prestaties van het getrainde model te kunnen beoordelen, is gekozen voor een vergelijking met een baseline. Deze baseline bestond uit agents die uitsluitend willekeurige acties uitvoerden, zonder enig leerproces. Tijdens de evaluatiefase is het PPO-model getest tegen deze random agents in 20 afzonderlijke episodes. De doelstelling was om vast te stellen of het getrainde model in staat zou zijn om significant beter te presteren dan niet-lerende tegenstanders.\n",
        "\n",
        "Uit de resultaten bleek dat de PPO-agent (`first_0`) slechts één van de twintig spellen wist te winnen, met een gemiddelde reward van -0.90. De andere agents, die allen random gedrag vertoonden, behaalden gemiddeld betere resultaten. Zo wist de best scorende random agent (`fourth_0`) acht keer te winnen, met een gemiddelde reward van -0.20.\n",
        "\n",
        "Op basis van deze gegevens kan worden geconcludeerd dat het PPO-model in deze vorm niet succesvol boven de baseline wist uit te stijgen. Mogelijke oorzaken hiervoor zijn dat de PPO-agent is getraind in een zelf-spelende omgeving en werd geëvalueerd tegen een totaal ander type gedrag, dat de trainingstijd relatief kort was en dat de visuele inputstructuur het leerproces heeft vertraagd. Daarnaast kan de interactiedynamiek met niet-lerende tegenstanders te weinig informatie hebben opgeleverd voor het ontwikkelen van effectief gedrag.\n",
        "\n",
        "De vergelijking met de baseline maakt duidelijk dat het model nog niet robuust genoeg is om zich structureel aan te passen aan variabele tegenstanders. Om de prestaties te verbeteren, zou het zinvol zijn om het model ook te trainen tegen willekeurige of gescripte agents, zodat het leert omgaan met inconsistente strategieën zoals die in de testfase zijn toegepast.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f5faffea",
      "metadata": {
        "id": "f5faffea"
      },
      "source": [
        "<a name='1.1'></a>\n",
        "<h3>&sect;6.2: Analyse met metrics</h3>\n",
        "\n",
        "<div style=\"display: flex; justify-content: center; align-items: center; margin-top: 10px;\">\n",
        "    <img src=\"\" alt=\"warlords_4m_training.png\" style=\"width: 1000px; height: auto;\">\n",
        "</div>\n",
        "\n",
        "Tijdens het trainen van het PPO-model zijn in totaal 4.000.768 timesteps doorlopen, verdeeld over 3907 iteraties. De training verliep met gemiddeld 592 frames per seconde en duurde ruim 6757 seconden. In de laatste log van het model is te zien dat de `entropy_loss` op -1.53 lag, wat aangeeft dat het model nog relatief veel spreiding had in zijn actievoorkeuren. De `explained_variance` lag op -8.25, wat suggereert dat het model moeite had met het verklaren van de waarde-inschattingen van de states, mogelijk veroorzaakt door instabiliteit of onvoldoende patroonherkenning.\n",
        "\n",
        "Ook de `value_loss` was laag (1.46e-05), wat erop kan wijzen dat de modelupdates klein bleven. De `policy_gradient_loss` van -0.0147 en `clip_fraction` van 0.126 zijn typisch voor PPO-modellen met behoudende updates, maar bevestigen wel dat het leerproces voorzichtig is verlopen.\n",
        "\n",
        "Na training is het model geëvalueerd op basis van twee hoofdmetrics: de gemiddelde reward per agent en het aantal keer dat een agent als laatste overbleef. In eerdere testresultaten over twintig episodes bleek dat de PPO-agent (`first_0`) een gemiddelde reward van -0.90 behaalde en slechts één keer wist te winnen. Ter vergelijking, een willekeurige tegenstander (`fourth_0`) behaalde acht overwinningen en een gemiddelde reward van -0.20.\n",
        "\n",
        "In een korte herhalingstest over drie episodes, uitgevoerd om de opzet opnieuw te verifiëren, bleek dat elk van de agents exact één keer wist te winnen. Hoewel dit door het lage aantal episodes niet representatief is, bevestigt het wel dat het model in zijn huidige vorm geen structureel voordeel behaalt ten opzichte van random gedrag.\n",
        "\n",
        "De combinatie van de trainingsmetrics en de evaluatieresultaten laat zien dat het model beperkte progressie heeft geboekt. Zowel het leerproces als de outputgedrag van de agent wijzen op een gebrek aan stabiel, adaptief gedrag. Verdere evaluatie met uitgebreidere logging of gedragsanalyse per timestep zou nodig zijn om dieper inzicht te krijgen in de keuzes die het model maakt.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "248de22d",
      "metadata": {
        "id": "248de22d"
      },
      "source": [
        "<a name='1.1'></a>\n",
        "<h3>&sect;6.3: Visualisatie van resultaten</h3>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "agents = list(eval_env.possible_agents)\n",
        "plt.figure(figsize=(8, 4))\n",
        "plt.bar(agents, [wins[a] for a in agents])\n",
        "plt.title(\"Aantal overwinningen per agent over 3 episodes\")\n",
        "plt.ylabel(\"Aantal overwinningen\")\n",
        "plt.xlabel(\"Agent\")\n",
        "plt.ylim(0, num_episodes)\n",
        "plt.grid(True, axis=\"y\", linestyle=\"--\", alpha=0.6)\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 407
        },
        "id": "K0pBM4C_gBNO",
        "outputId": "e13de098-a673-478f-ac94-358ea3cfe631"
      },
      "id": "K0pBM4C_gBNO",
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 800x400 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f653d2a0",
      "metadata": {
        "id": "f653d2a0"
      },
      "source": [
        "In de bovenstaande figuur is een snelle test uitgevoerd met drie episodes, waarin te zien is dat elk van de agents één keer heeft gewonnen. Door tijdsbeperkingen is het volledige experiment met twintig episodes niet opnieuw gedraaid. Eerdere runs lieten echter vergelijkbare patronen zien, waarbij de getrainde PPO-agent geen significant voordeel behaalde ten opzichte van willekeurige tegenstanders. Deze korte test bevestigt het beeld dat het model in de huidige vorm niet consistent beter presteert dan de baseline.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "935cd0bd",
      "metadata": {
        "id": "935cd0bd"
      },
      "source": [
        "\n",
        "---\n",
        "<div style=\"background-color:LightBlue; text-align:center; vertical-align:middle; padding:50px 0; margin-top:5px; margin-bottom:5px\">\n",
        "    <h2 id=\"eda-title\" style=\"color:black; font-family: Verdana, sans-serif; font-size: 25px;\"><strong>H7: Rapportage en Reflectie</strong></h2>\n",
        "</div>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<a name='7.1'></a>\n",
        "<h3>&sect;7.1 : Probleemstelling</h3>\n",
        "\n",
        "In hoofdstuk 3.1 is de probleemanalyse uiteengezet. Daarin is beschreven dat het trainen van een reinforcement learning-agent binnen een multi-agent omgeving, zoals de Atari-game Warlords, een extra laag complexiteit met zich meebrengt. De aanwezigheid van meerdere agents zorgt ervoor dat strategieën niet op zichzelf staan, maar voortdurend moeten worden bijgestuurd op basis van het gedrag van de andere spelers in de omgeving.\n",
        "\n",
        "Binnen dit project hebben wij onderzocht hoe wij een agent kunnen trainen die effectief leert omgaan met deze dynamiek. Hiervoor is het PPO-algoritme ingezet, dat zich in eerdere onderzoeken bewezen heeft als stabiele keuze binnen omgevingen met meerdere actoren.\n",
        "\n",
        "De centrale probleemstelling die wij tijdens het project hebben onderzocht, luidde als volgt:\n",
        "\n",
        "- Hoe trainen wij een reinforcement learning-agent in een multi-agent omgeving als Warlords zodanig dat deze effectief leert concurreren met andere agents, en hoe evalueren wij of deze aanpak beter presteert dan een baseline zoals een random policy?\n",
        "\n",
        "Deze probleemstelling heeft richting gegeven aan onze ontwerpkeuzes, de implementatie van het model en de manier waarop we de prestaties hebben geëvalueerd. In de volgende hoofdstukken wordt toegelicht hoe we dit traject technisch en analytisch hebben aangepakt."
      ],
      "metadata": {
        "id": "lVTlJQgq92oK"
      },
      "id": "lVTlJQgq92oK"
    },
    {
      "cell_type": "markdown",
      "id": "067d398a",
      "metadata": {
        "id": "067d398a"
      },
      "source": [
        "<a name='7.2'></a>\n",
        "<h3>&sect;7.2: Methodologie en aanpak</h3>\n",
        "\n",
        "\n",
        "\n",
        "Voor dit project hebben wij een eigen trainingsklasse ontwikkeld waarin PPO is toegepast op de multi-agent omgeving *Warlords*, afkomstig uit de PettingZoo-bibliotheek. Deze omgeving bestaat uit vier gelijktijdige agents die ieder hun eigen doel nastreven. Binnen deze context hebben wij één agent getraind met reinforcement learning, terwijl de overige drie agents willekeurige acties uitvoerden. Zo werd een gecontroleerde multi-agent setting gecreëerd waarin het leerproces van één agent centraal stond.\n",
        "\n",
        "De omgeving is voorbereid met behulp van SuperSuit-wrappers:\n",
        "- `black_death_v3` zorgt ervoor dat agents die zijn uitgeschakeld correct worden afgehandeld;\n",
        "- `color_reduction_v0` reduceert de visuele input tot grijstinten;\n",
        "- `resize_v1` schaalt de input terug naar 84x84 pixels;\n",
        "- `frame_stack_v1` voegt temporele informatie toe via frame-stacking.\n",
        "\n",
        "Daarna is de omgeving geconverteerd naar een vectorized variant via `pettingzoo_env_to_vec_env_v1` en `concat_vec_envs_v1`, zodat PPO parallel over meerdere instanties kon trainen. Dit verhoogde de efficiëntie en zorgde voor snellere convergentie.\n",
        "\n",
        "Het PPO-algoritme is ingezet met een convolutionele neurale netwerkpolicy (`CnnPolicy`) en de volgende hyperparameters:\n",
        "- Learning rate: 2.5e-4  \n",
        "- Batch size: 256  \n",
        "- N steps: 128  \n",
        "- N epochs: 4  \n",
        "- Entropy coefficient: 0.01  \n",
        "- GAE lambda: 0.95  \n",
        "- Discount factor (gamma): 0.99  \n",
        "- Clip range: 0.1  \n",
        "- Value function coefficient: 0.5  \n",
        "- Max gradient norm: 0.5  \n",
        "\n",
        "De agent is getraind op een totaal van 4 miljoen timesteps, verdeeld over twee parallelle instanties van de omgeving. Na het trainen is het model lokaal opgeslagen en opnieuw ingeladen voor evaluatie.\n",
        "\n",
        "Voor de evaluatie is het getrainde model 20 keer getest in nieuwe episodes. Hierbij zijn de totale beloning per agent en het aantal gewonnen rondes bijgehouden. De agent onder controle van het getrainde PPO-model speelde elke keer tegen drie agents met willekeurige acties. De gemiddelde reward en het aantal overwinningen zijn berekend over alle testepisodes. De resultaten van deze simulaties zijn gebruikt om het gedrag en de effectiviteit van het model te analyseren.\n",
        "\n",
        "De volledige trainings- en evaluatieprocedure is ondergebracht in een gestructureerde codebase, met duidelijke functies voor omgeving, training, laden en testen van het model. Dit maakt het systeem reproduceerbaar, transparant en geschikt voor verdere uitbreiding of vergelijking met alternatieve strategieën.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c40607f0",
      "metadata": {
        "id": "c40607f0"
      },
      "source": [
        "<a name='7.3'></a>\n",
        "<h3>&sect;7.3: Samenvatting van resultaten</h3>\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "Na het trainen van het PPO-model op 4 miljoen timesteps is het model geëvalueerd in 20 testepisodes. Tijdens deze evaluatie speelde de getrainde agent (`first_0`) tegen drie tegenstanders die willekeurige acties uitvoerden. Voor elke episode is geregistreerd wat de beloning per agent was, en welke agent als laatste overbleef in het spel.\n",
        "\n",
        "De resultaten laten zien dat de PPO-agent (`first_0`) gemiddeld slechter presteerde dan de drie random agents. Over 20 testgames behaalde deze agent een gemiddelde reward van -0.90 en wist hij slechts 1 keer als winnaar te eindigen. De overige agents, hoewel volledig gestuurd door random acties, scoorden beter op beide onderdelen.\n",
        "\n",
        "De resultaten per agent waren als volgt:\n",
        "\n",
        "| Agent          | Gem. Reward | Aantal Overwinningen |\n",
        "|----------------|-------------|-----------------------|\n",
        "| **first_0 (PPO)** | **-0.90**    | **1**                  |\n",
        "| second_0       | -0.50        | 5                     |\n",
        "| third_0        | -0.40        | 6                     |\n",
        "| fourth_0       | -0.20        | 8                     |\n",
        "\n",
        "Hoewel deze resultaten op het eerste gezicht teleurstellend lijken, is het belangrijk om de evaluatiecontext goed te begrijpen. De PPO-agent is namelijk getraind in een situatie waarbij alle agents door dezelfde PPO-policy werden bestuurd (zelf-spelend), maar is geëvalueerd in een omgeving met volledig willekeurige tegenstanders. Het gedrag van deze random agents wijkt sterk af van wat het model tijdens training heeft gezien.\n",
        "\n",
        "Dit verschil in dynamiek kan ervoor gezorgd hebben dat het geleerde beleid van de PPO-agent niet goed aansluit op de evaluatiesetting. Omdat de tegenstanders zich totaal onvoorspelbaar gedragen, is het moeilijk om hier consistente strategieën tegenover te zetten, zeker als daar tijdens de training geen sprake van was.\n",
        "\n",
        "De test bevestigt dat reinforcement learning binnen een multi-agent setting sterk afhankelijk is van de samenstelling en consistentie van de omgeving. Om betere prestaties te behalen, zou een volgende stap kunnen zijn om de PPO-agent ook te trainen tegen agents met niet-random gedrag, zodat hij beter leert omgaan met realistischere spelsituaties.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4bc393ce",
      "metadata": {
        "id": "4bc393ce"
      },
      "source": [
        "<a name='7.4'></a>\n",
        "<h3>&sect;7.4: Reflectie op model, prestaties en uitbreidingsmogelijkheden</h3>\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "Tijdens dit project is gekozen voor PPO als reinforcement learning-algoritme, vanwege de stabiliteit en geschiktheid voor visuele input in omgevingen met discrete actie-ruimtes. De PPO-agent is getraind in een zelf-spelende setting, waarbij alle agents in de omgeving gebruikmaakten van dezelfde policy. Dit zorgde voor een gecontroleerde en consistente leeromgeving, waarin het model voornamelijk leerde te reageren op zijn eigen gedrag.\n",
        "\n",
        "De uiteindelijke prestaties tijdens de evaluatie vielen tegen. De PPO-agent presteerde slechter dan de random agents waartegen hij getest werd. Een belangrijke verklaring hiervoor is het verschil tussen de trainings- en testomgeving. Tijdens het testen kreeg de agent te maken met drie volledig willekeurige tegenstanders. Dit soort gedrag wijkt sterk af van wat het model tijdens training heeft meegemaakt, waardoor het getrainde beleid niet goed bleek te generaliseren naar deze nieuwe situatie.\n",
        "\n",
        "Een andere mogelijke factor is de relatief korte trainingstijd. Vier miljoen timesteps lijkt veel, maar voor visuele input en complexe multi-agent interacties is dit vaak onvoldoende om stabiele strategieën aan te leren. Ook de complexiteit van de observatiestructuur (grijswaarden, 84x84 resolutie, 4 gestackte frames) kan het leerproces bemoeilijkt hebben.\n",
        "\n",
        "Ondanks de tegenvallende resultaten biedt het project waardevolle inzichten voor verdere uitbreiding. Enkele mogelijkheden voor verbetering zijn:\n",
        "- Trainen tegen bots met gescripte of semi-consistente strategieën in plaats van random gedrag.\n",
        "- Het trainen van meerdere agents tegelijk met onafhankelijke policies, zodat realistischere interacties ontstaan.\n",
        "- Het uitbreiden van de trainingstijd of gebruikmaken van curriculum learning (eerst eenvoudige tegenstanders, daarna moeilijker).\n",
        "- Het loggen van metrics en gedrag tijdens training, om het leerproces beter te kunnen volgen en analyseren.\n",
        "\n",
        "De resultaten benadrukken dat reinforcement learning in een multi-agent context sterk afhankelijk is van de kwaliteit van de omgeving en de tegenstanders. Een goed gekozen trainingsopstelling is cruciaal voor het succes van het eindmodel. Hoewel de prestatie van het huidige model beperkt was, vormt dit project een stevig fundament voor meer geavanceerde MARL-experimenten.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "![PPO agent 4 miljoen](game_9.mp4)"
      ],
      "metadata": {
        "id": "_x71NwGLbJkj"
      },
      "id": "_x71NwGLbJkj"
    },
    {
      "cell_type": "markdown",
      "id": "43cf89fe",
      "metadata": {
        "id": "43cf89fe"
      },
      "source": [
        "\n",
        "---\n",
        "<div style=\"background-color:LightBlue; text-align:center; vertical-align:middle; padding:50px 0; margin-top:5px; margin-bottom:5px\">\n",
        "    <h2 id=\"eda-title\" style=\"color:black; font-family: Verdana, sans-serif; font-size: 25px;\"><strong>H8: Literatuurlijst</strong></h2>\n",
        "</div>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Scharwächter, V. (2024, 15 juli). *Probleemanalyse maken voor je scriptie | Betekenis & Voorbeeld.* Scribbr. https://www.scribbr.nl/starten-met-je-scriptie/probleemanalyse/\n",
        "- PPO — Stable Baselines3 2.7.0a0 documentation. (z.d.). https://stable-baselines3.readthedocs.io/en/master/modules/ppo.html\n",
        "- PettingZoo documentation. (z.d.). https://pettingzoo.farama.org/environments/atari/warlords/\n",
        "- PettingZoo documentation. (z.d.-b). https://pettingzoo.farama.org/api/wrappers/supersuit_wrappers/"
      ],
      "metadata": {
        "id": "OxRcnCwjrS_6"
      },
      "id": "OxRcnCwjrS_6"
    },
    {
      "cell_type": "markdown",
      "id": "8c2bc62c",
      "metadata": {
        "id": "8c2bc62c"
      },
      "source": [
        "\n",
        "---\n",
        "<div style=\"background-color:LightBlue; text-align:center; vertical-align:middle; padding:50px 0; margin-top:5px; margin-bottom:5px\">\n",
        "    <h2 id=\"eda-title\" style=\"color:black; font-family: Verdana, sans-serif; font-size: 25px;\"><strong>H9: Beoordelingscriteria</strong></h2>\n",
        "</div>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "31b69975",
      "metadata": {
        "id": "31b69975"
      },
      "source": [
        "Je werk wordt beoordeeld op de volgende aspecten:\n",
        "1.\t**Keuze van algoritme en trainingsstrategie**: Is het gekozen algoritme geschikt voor de omgeving? Is de trainingsmethode van de agent relevant voor deze setting? Wordt er rekening gehouden met de aanwezigheid van meerdere agenten?\n",
        "2.\t**Technische diepgang**: Worden neural network-componenten (indien van toepassing) correct toegepast? Is er aandacht voor alle cruciale onderdelen van de DRL-pijplijn (zoals experience replay en policy updates)?\n",
        "3.\t**Implementatie en testen**: Is het multi-agent Reinforcement Learning-algoritme correct geïmplementeerd, met goed gestructureerde en werkende code? Is het getest in een multi-agentomgeving?\n",
        "4.\t**Rapportage**: Zijn de methodologie en keuzes goed onderbouwd met wetenschappelijke literatuur? Is het rapport helder en gestructureerd?\n",
        "5.\t**Reproduceerbaarheid**: Is de code duidelijk, goed gedocumenteerd en eenvoudig te reproduceren?\n",
        "6.\t**Bonuspunten**: Aan het einde van het project neemt je agent het in een toernooi op tegen je klasgenoten. (De details hierover volgen later.) Het winnende team van het toernooi krijgt 5 bonuspunten bovenop het aantal behaalde punten met de opdracht.\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.0"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}