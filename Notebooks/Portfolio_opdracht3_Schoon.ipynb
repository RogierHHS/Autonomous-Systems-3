{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "4e982cc9",
      "metadata": {
        "id": "4e982cc9"
      },
      "source": [
        "<div style=\"background-color:LightBlue; text-align:center; padding:20px;\">\n",
        "    <h2 style=\"color:black; font-family: Verdana, sans-serif;\"><strong>Multi-Agent Reinforcement Learning Project - Atari</strong></h2>\n",
        "    <p style=\"font-size: 14px; color: black; font-family: Verdana, sans-serif;\">\n",
        "        <table style=\"margin: auto; border-collapse: collapse; color: black;\">\n",
        "            <tr>\n",
        "                <th style=\"border: 0;\">Names</th>\n",
        "                <th style=\"border: 0;\">GitHub Username</th>\n",
        "            </tr>\n",
        "            <tr>\n",
        "                <td style=\"border: 0;\">Rogier Gernaat</td>\n",
        "                <td style=\"border: 0;\">RogierHHS</td>\n",
        "            </tr>\n",
        "            <tr>\n",
        "                <td style=\"border: 0;\">Daan Eising</td>\n",
        "                <td style=\"border: 0;\">DaanEising</td>\n",
        "            </tr>\n",
        "            <tr>\n",
        "                <td style=\"border: 0;\">Julia Boschman</td>\n",
        "                <td style=\"border: 0;\">JuliaBoschman</td>\n",
        "            </tr>\n",
        "            <tr>\n",
        "                <td style=\"border: 0;\">Jort Akershoek</td>\n",
        "                <td style=\"border: 0;\">JortAkershoek</td>\n",
        "            </tr>\n",
        "        </table>\n",
        "    </p></div>\n",
        "\n",
        "<div style=\"display: flex; justify-content: center; align-items: center; margin-top: 10px;\">\n",
        "    <img src=\"\" alt=\"fotoj van onze opdracht/GIF\" style=\"width: 1000px; height: auto;\">\n",
        "</div>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0851f3ab",
      "metadata": {
        "id": "0851f3ab"
      },
      "source": [
        "- ***Docent***: Vikram Radhakrishnan\n",
        "- ***Datum***: 08-04-2025"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "57553bbf",
      "metadata": {
        "id": "57553bbf"
      },
      "source": [
        "\n",
        "---\n",
        "<div style=\"background-color:LightBlue; text-align:center; vertical-align:middle; padding:50px 0; margin-top:5px; margin-bottom:5px\">\n",
        "    <h2 id=\"eda-title\" style=\"color:black; font-family: Verdana, sans-serif; font-size: 25px;\"><strong> Inhoudsopgave (Prototype morgen kunnen we hem nog ff aanpassen of anders indelen) </strong></h2>\n",
        "</div>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d7dc902d",
      "metadata": {
        "id": "d7dc902d"
      },
      "source": [
        "## **Inhoudsopgave**\n",
        "\n",
        "1. [H1: Inleiding](#1.0)\n",
        "   - [&sect;1.1: Imports en Setup](#1.1)  \n",
        "  \n",
        "2. [H2: Kiezen van Algoritme](#2.0)  \n",
        "   - [&sect;2.1: Kiezen van RL-Algoritme](#2.1)    \n",
        "   - [&sect;2.3: Kiezen van Trainingsstrategie](#2.3)  \n",
        "\n",
        "3. [H3: Probleemdefinitie](#3.0)  \n",
        "   - [&sect;3.1: Wat is het probleem?](#3.1)   \n",
        "\n",
        "4. [H4: Ontwerp en Implementatie](#4.0)  \n",
        "   - [&sect;4.1: Baseline strategie ontwikkelen](#4.1)  \n",
        "   - [&sect;4.2: Selectie van DRL algoritme en frameworks](#4.2)   \n",
        "   - [&sect;4.3: Implementatie MARL-agent](#4.3)  \n",
        "\n",
        "5. [H5: Training en Hyperparameter Search](#5.0)  \n",
        "   - [&sect;5.1: Training](#5.1)  \n",
        "   - [&sect;5.2: Selectie en tuning van hyperparameters](#5.2)  \n",
        "\n",
        "6. [H6: Evaluatie en Vergelijking](#6.0)  \n",
        "   - [&sect;6.1: Evaluatie t.o.v. baseline](#6.1)  \n",
        "   - [&sect;6.2: Analyse met metrics](#6.2)  \n",
        "   - [&sect;6.3: Visualisatie van resultaten](#6.3)  \n",
        "\n",
        "7. [H7: Rapportage en Reflectie](#7.0)  \n",
        "   - [&sect;7.1: Methodologie en aanpak](#7.1)  \n",
        "   - [&sect;7.2: Samenvatting van resultaten](#7.2)  \n",
        "   - [&sect;7.3: Reflectie op model, prestaties en uitbreidingsmogelijkheden](#7.3)  \n",
        "\n",
        "8. [H8: Literatuurlijst](#8.0)  \n",
        "\n",
        "9. [H9: Beoordelingscriteria](#9.0)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b59f4614",
      "metadata": {
        "id": "b59f4614"
      },
      "source": [
        "\n",
        "---\n",
        "<div style=\"background-color:LightBlue; text-align:center; vertical-align:middle; padding:50px 0; margin-top:5px; margin-bottom:5px\">\n",
        "    <h2 id=\"eda-title\" style=\"color:black; font-family: Verdana, sans-serif; font-size: 25px;\"><strong>H1: Inleiding </strong></h2>\n",
        "</div>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d4151918",
      "metadata": {
        "id": "d4151918"
      },
      "source": [
        "## inleiding bladiebladiebla"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b7cc6769",
      "metadata": {
        "id": "b7cc6769"
      },
      "source": [
        "<a name='1.1'></a>\n",
        "<h3>&sect;1.1: Imports en Setup</h3>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<div style=\"background-color:white; color:black; padding: 10px;\">\n",
        "    <strong>Pip install's</strong>\n",
        "</div>\n",
        "\n"
      ],
      "metadata": {
        "id": "L4NIctHLp1oS"
      },
      "id": "L4NIctHLp1oS"
    },
    {
      "cell_type": "code",
      "source": [
        "# Install the necessary libraries\n",
        "\n",
        "!pip install gym\n",
        "!pip install stable_baselines3\n",
        "!pip install gymnasium[atari]\n",
        "!pip install pettingzoo[atari]\n",
        "!pip install \"autorom[accept-rom-license]\"\n",
        "!pip install --find-links dist/ --no-cache-dir AutoROM[accept-rom-license]\n",
        "!pip install supersuit"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ULHKlbghpy0k",
        "outputId": "44d7a652-7de7-40bb-ac15-ea0ebdd293e9"
      },
      "id": "ULHKlbghpy0k",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: gym in /usr/local/lib/python3.11/dist-packages (0.25.2)\n",
            "Requirement already satisfied: numpy>=1.18.0 in /usr/local/lib/python3.11/dist-packages (from gym) (2.0.2)\n",
            "Requirement already satisfied: cloudpickle>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from gym) (3.1.1)\n",
            "Requirement already satisfied: gym-notices>=0.0.4 in /usr/local/lib/python3.11/dist-packages (from gym) (0.0.8)\n",
            "Collecting stable_baselines3\n",
            "  Downloading stable_baselines3-2.6.0-py3-none-any.whl.metadata (4.8 kB)\n",
            "Requirement already satisfied: gymnasium<1.2.0,>=0.29.1 in /usr/local/lib/python3.11/dist-packages (from stable_baselines3) (1.1.1)\n",
            "Requirement already satisfied: numpy<3.0,>=1.20 in /usr/local/lib/python3.11/dist-packages (from stable_baselines3) (2.0.2)\n",
            "Requirement already satisfied: torch<3.0,>=2.3 in /usr/local/lib/python3.11/dist-packages (from stable_baselines3) (2.6.0+cu124)\n",
            "Requirement already satisfied: cloudpickle in /usr/local/lib/python3.11/dist-packages (from stable_baselines3) (3.1.1)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from stable_baselines3) (2.2.2)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (from stable_baselines3) (3.10.0)\n",
            "Requirement already satisfied: typing-extensions>=4.3.0 in /usr/local/lib/python3.11/dist-packages (from gymnasium<1.2.0,>=0.29.1->stable_baselines3) (4.14.0)\n",
            "Requirement already satisfied: farama-notifications>=0.0.1 in /usr/local/lib/python3.11/dist-packages (from gymnasium<1.2.0,>=0.29.1->stable_baselines3) (0.0.4)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch<3.0,>=2.3->stable_baselines3) (3.18.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch<3.0,>=2.3->stable_baselines3) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch<3.0,>=2.3->stable_baselines3) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch<3.0,>=2.3->stable_baselines3) (2025.3.2)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch<3.0,>=2.3->stable_baselines3)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch<3.0,>=2.3->stable_baselines3)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch<3.0,>=2.3->stable_baselines3)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch<3.0,>=2.3->stable_baselines3)\n",
            "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch<3.0,>=2.3->stable_baselines3)\n",
            "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch<3.0,>=2.3->stable_baselines3)\n",
            "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.5.147 (from torch<3.0,>=2.3->stable_baselines3)\n",
            "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch<3.0,>=2.3->stable_baselines3)\n",
            "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch<3.0,>=2.3->stable_baselines3)\n",
            "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch<3.0,>=2.3->stable_baselines3) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch<3.0,>=2.3->stable_baselines3) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch<3.0,>=2.3->stable_baselines3) (12.4.127)\n",
            "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch<3.0,>=2.3->stable_baselines3)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch<3.0,>=2.3->stable_baselines3) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch<3.0,>=2.3->stable_baselines3) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch<3.0,>=2.3->stable_baselines3) (1.3.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->stable_baselines3) (1.3.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib->stable_baselines3) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib->stable_baselines3) (4.58.4)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->stable_baselines3) (1.4.8)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib->stable_baselines3) (24.2)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.11/dist-packages (from matplotlib->stable_baselines3) (11.2.1)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->stable_baselines3) (3.2.3)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib->stable_baselines3) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->stable_baselines3) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->stable_baselines3) (2025.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.7->matplotlib->stable_baselines3) (1.17.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch<3.0,>=2.3->stable_baselines3) (3.0.2)\n",
            "Downloading stable_baselines3-2.6.0-py3-none-any.whl (184 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m184.5/184.5 kB\u001b[0m \u001b[31m8.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m111.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m89.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m49.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m13.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m96.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, stable_baselines3\n",
            "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
            "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n",
            "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
            "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
            "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
            "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
            "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
            "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
            "Successfully installed nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127 stable_baselines3-2.6.0\n",
            "Requirement already satisfied: gymnasium[atari] in /usr/local/lib/python3.11/dist-packages (1.1.1)\n",
            "Requirement already satisfied: numpy>=1.21.0 in /usr/local/lib/python3.11/dist-packages (from gymnasium[atari]) (2.0.2)\n",
            "Requirement already satisfied: cloudpickle>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from gymnasium[atari]) (3.1.1)\n",
            "Requirement already satisfied: typing-extensions>=4.3.0 in /usr/local/lib/python3.11/dist-packages (from gymnasium[atari]) (4.14.0)\n",
            "Requirement already satisfied: farama-notifications>=0.0.1 in /usr/local/lib/python3.11/dist-packages (from gymnasium[atari]) (0.0.4)\n",
            "Requirement already satisfied: ale_py>=0.9 in /usr/local/lib/python3.11/dist-packages (from gymnasium[atari]) (0.11.1)\n",
            "Collecting pettingzoo[atari]\n",
            "  Downloading pettingzoo-1.25.0-py3-none-any.whl.metadata (8.9 kB)\n",
            "Requirement already satisfied: numpy>=1.21.0 in /usr/local/lib/python3.11/dist-packages (from pettingzoo[atari]) (2.0.2)\n",
            "Requirement already satisfied: gymnasium>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from pettingzoo[atari]) (1.1.1)\n",
            "Collecting multi_agent_ale_py>=0.1.11 (from pettingzoo[atari])\n",
            "  Downloading multi-agent-ale-py-0.1.11.tar.gz (551 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m552.0/552.0 kB\u001b[0m \u001b[31m15.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: pygame>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from pettingzoo[atari]) (2.6.1)\n",
            "Requirement already satisfied: cloudpickle>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from gymnasium>=1.0.0->pettingzoo[atari]) (3.1.1)\n",
            "Requirement already satisfied: typing-extensions>=4.3.0 in /usr/local/lib/python3.11/dist-packages (from gymnasium>=1.0.0->pettingzoo[atari]) (4.14.0)\n",
            "Requirement already satisfied: farama-notifications>=0.0.1 in /usr/local/lib/python3.11/dist-packages (from gymnasium>=1.0.0->pettingzoo[atari]) (0.0.4)\n",
            "Downloading pettingzoo-1.25.0-py3-none-any.whl (852 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m852.5/852.5 kB\u001b[0m \u001b[31m45.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: multi_agent_ale_py\n",
            "  Building wheel for multi_agent_ale_py (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for multi_agent_ale_py: filename=multi_agent_ale_py-0.1.11-cp311-cp311-linux_x86_64.whl size=721821 sha256=23d0b6504ace9e1f1733ecfb4fac9f8baf2a387fc969d0f2979240483d968b14\n",
            "  Stored in directory: /root/.cache/pip/wheels/1d/81/76/771ec8e34292c8a71dd6c4a52a1c0401f4d93cbfb54e02fce4\n",
            "Successfully built multi_agent_ale_py\n",
            "Installing collected packages: multi_agent_ale_py, pettingzoo\n",
            "Successfully installed multi_agent_ale_py-0.1.11 pettingzoo-1.25.0\n",
            "Collecting autorom[accept-rom-license]\n",
            "  Downloading AutoROM-0.6.1-py3-none-any.whl.metadata (2.4 kB)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.11/dist-packages (from autorom[accept-rom-license]) (8.2.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from autorom[accept-rom-license]) (2.32.3)\n",
            "Collecting AutoROM.accept-rom-license (from autorom[accept-rom-license])\n",
            "  Downloading AutoROM.accept-rom-license-0.6.1.tar.gz (434 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m434.7/434.7 kB\u001b[0m \u001b[31m14.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->autorom[accept-rom-license]) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->autorom[accept-rom-license]) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->autorom[accept-rom-license]) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->autorom[accept-rom-license]) (2025.6.15)\n",
            "Downloading AutoROM-0.6.1-py3-none-any.whl (9.4 kB)\n",
            "Building wheels for collected packages: AutoROM.accept-rom-license\n",
            "  Building wheel for AutoROM.accept-rom-license (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for AutoROM.accept-rom-license: filename=autorom_accept_rom_license-0.6.1-py3-none-any.whl size=446709 sha256=8b32068de60c7b47f10188a36cc151257b552918d847f1ac46a1b69ed9131ae9\n",
            "  Stored in directory: /root/.cache/pip/wheels/bc/fc/c6/8aa657c0d2089982f2dabd110efc68c61eb49831fdb7397351\n",
            "Successfully built AutoROM.accept-rom-license\n",
            "Installing collected packages: AutoROM.accept-rom-license, autorom\n",
            "Successfully installed AutoROM.accept-rom-license-0.6.1 autorom-0.6.1\n",
            "Looking in links: dist/\n",
            "Requirement already satisfied: AutoROM[accept-rom-license] in /usr/local/lib/python3.11/dist-packages (0.6.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.11/dist-packages (from AutoROM[accept-rom-license]) (8.2.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from AutoROM[accept-rom-license]) (2.32.3)\n",
            "Requirement already satisfied: AutoROM.accept-rom-license in /usr/local/lib/python3.11/dist-packages (from AutoROM[accept-rom-license]) (0.6.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->AutoROM[accept-rom-license]) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->AutoROM[accept-rom-license]) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->AutoROM[accept-rom-license]) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->AutoROM[accept-rom-license]) (2025.6.15)\n",
            "Collecting supersuit\n",
            "  Downloading supersuit-3.10.0-py3-none-any.whl.metadata (3.1 kB)\n",
            "Requirement already satisfied: numpy>=1.19.0 in /usr/local/lib/python3.11/dist-packages (from supersuit) (2.0.2)\n",
            "Requirement already satisfied: gymnasium>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from supersuit) (1.1.1)\n",
            "Collecting tinyscaler>=1.2.6 (from supersuit)\n",
            "  Downloading tinyscaler-1.2.8-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.2 kB)\n",
            "Requirement already satisfied: cloudpickle>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from gymnasium>=1.0.0->supersuit) (3.1.1)\n",
            "Requirement already satisfied: typing-extensions>=4.3.0 in /usr/local/lib/python3.11/dist-packages (from gymnasium>=1.0.0->supersuit) (4.14.0)\n",
            "Requirement already satisfied: farama-notifications>=0.0.1 in /usr/local/lib/python3.11/dist-packages (from gymnasium>=1.0.0->supersuit) (0.0.4)\n",
            "Downloading supersuit-3.10.0-py3-none-any.whl (50 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.2/50.2 kB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tinyscaler-1.2.8-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (563 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m563.3/563.3 kB\u001b[0m \u001b[31m15.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: tinyscaler, supersuit\n",
            "Successfully installed supersuit-3.10.0 tinyscaler-1.2.8\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "id": "12e99777",
      "metadata": {
        "id": "12e99777"
      },
      "source": [
        "<div style=\"background-color:white; color:black; padding: 10px;\">\n",
        "    <strong>Importeren van de library's</strong>\n",
        "</div>\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "593b2447",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "593b2447",
        "outputId": "4ac53897-1446-405e-bce0-08c8136b0269"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "AutoROM will download the Atari 2600 ROMs.\n",
            "They will be installed to:\n",
            "\t/usr/local/lib/python3.11/dist-packages/AutoROM/roms\n",
            "\t/usr/local/lib/python3.11/dist-packages/multi_agent_ale_py/roms\n",
            "\n",
            "Existing ROMs will be overwritten.\n",
            "\n",
            "I own a license to these Atari 2600 ROMs.\n",
            "I agree to not distribute these ROMs and wish to proceed: [Y/n]: y\n",
            "Installed /usr/local/lib/python3.11/dist-packages/AutoROM/roms/adventure.bin\n",
            "Installed /usr/local/lib/python3.11/dist-packages/multi_agent_ale_py/roms/adventure.bin\n",
            "Installed /usr/local/lib/python3.11/dist-packages/AutoROM/roms/air_raid.bin\n",
            "Installed /usr/local/lib/python3.11/dist-packages/multi_agent_ale_py/roms/air_raid.bin\n",
            "Installed /usr/local/lib/python3.11/dist-packages/AutoROM/roms/alien.bin\n",
            "Installed /usr/local/lib/python3.11/dist-packages/multi_agent_ale_py/roms/alien.bin\n",
            "Installed /usr/local/lib/python3.11/dist-packages/AutoROM/roms/amidar.bin\n",
            "Installed /usr/local/lib/python3.11/dist-packages/multi_agent_ale_py/roms/amidar.bin\n",
            "Installed /usr/local/lib/python3.11/dist-packages/AutoROM/roms/assault.bin\n",
            "Installed /usr/local/lib/python3.11/dist-packages/multi_agent_ale_py/roms/assault.bin\n",
            "Installed /usr/local/lib/python3.11/dist-packages/AutoROM/roms/asterix.bin\n",
            "Installed /usr/local/lib/python3.11/dist-packages/multi_agent_ale_py/roms/asterix.bin\n",
            "Installed /usr/local/lib/python3.11/dist-packages/AutoROM/roms/asteroids.bin\n",
            "Installed /usr/local/lib/python3.11/dist-packages/multi_agent_ale_py/roms/asteroids.bin\n",
            "Installed /usr/local/lib/python3.11/dist-packages/AutoROM/roms/atlantis.bin\n",
            "Installed /usr/local/lib/python3.11/dist-packages/multi_agent_ale_py/roms/atlantis.bin\n",
            "Installed /usr/local/lib/python3.11/dist-packages/AutoROM/roms/atlantis2.bin\n",
            "Installed /usr/local/lib/python3.11/dist-packages/multi_agent_ale_py/roms/atlantis2.bin\n",
            "Installed /usr/local/lib/python3.11/dist-packages/AutoROM/roms/backgammon.bin\n",
            "Installed /usr/local/lib/python3.11/dist-packages/multi_agent_ale_py/roms/backgammon.bin\n",
            "Installed /usr/local/lib/python3.11/dist-packages/AutoROM/roms/bank_heist.bin\n",
            "Installed /usr/local/lib/python3.11/dist-packages/multi_agent_ale_py/roms/bank_heist.bin\n",
            "Installed /usr/local/lib/python3.11/dist-packages/AutoROM/roms/basic_math.bin\n",
            "Installed /usr/local/lib/python3.11/dist-packages/multi_agent_ale_py/roms/basic_math.bin\n",
            "Installed /usr/local/lib/python3.11/dist-packages/AutoROM/roms/battle_zone.bin\n",
            "Installed /usr/local/lib/python3.11/dist-packages/multi_agent_ale_py/roms/battle_zone.bin\n",
            "Installed /usr/local/lib/python3.11/dist-packages/AutoROM/roms/beam_rider.bin\n",
            "Installed /usr/local/lib/python3.11/dist-packages/multi_agent_ale_py/roms/beam_rider.bin\n",
            "Installed /usr/local/lib/python3.11/dist-packages/AutoROM/roms/berzerk.bin\n",
            "Installed /usr/local/lib/python3.11/dist-packages/multi_agent_ale_py/roms/berzerk.bin\n",
            "Installed /usr/local/lib/python3.11/dist-packages/AutoROM/roms/blackjack.bin\n",
            "Installed /usr/local/lib/python3.11/dist-packages/multi_agent_ale_py/roms/blackjack.bin\n",
            "Installed /usr/local/lib/python3.11/dist-packages/AutoROM/roms/bowling.bin\n",
            "Installed /usr/local/lib/python3.11/dist-packages/multi_agent_ale_py/roms/bowling.bin\n",
            "Installed /usr/local/lib/python3.11/dist-packages/AutoROM/roms/boxing.bin\n",
            "Installed /usr/local/lib/python3.11/dist-packages/multi_agent_ale_py/roms/boxing.bin\n",
            "Installed /usr/local/lib/python3.11/dist-packages/AutoROM/roms/breakout.bin\n",
            "Installed /usr/local/lib/python3.11/dist-packages/multi_agent_ale_py/roms/breakout.bin\n",
            "Installed /usr/local/lib/python3.11/dist-packages/AutoROM/roms/carnival.bin\n",
            "Installed /usr/local/lib/python3.11/dist-packages/multi_agent_ale_py/roms/carnival.bin\n",
            "Installed /usr/local/lib/python3.11/dist-packages/AutoROM/roms/casino.bin\n",
            "Installed /usr/local/lib/python3.11/dist-packages/multi_agent_ale_py/roms/casino.bin\n",
            "Installed /usr/local/lib/python3.11/dist-packages/AutoROM/roms/centipede.bin\n",
            "Installed /usr/local/lib/python3.11/dist-packages/multi_agent_ale_py/roms/centipede.bin\n",
            "Installed /usr/local/lib/python3.11/dist-packages/AutoROM/roms/chopper_command.bin\n",
            "Installed /usr/local/lib/python3.11/dist-packages/multi_agent_ale_py/roms/chopper_command.bin\n",
            "Installed /usr/local/lib/python3.11/dist-packages/AutoROM/roms/combat.bin\n",
            "Installed /usr/local/lib/python3.11/dist-packages/multi_agent_ale_py/roms/combat.bin\n",
            "Installed /usr/local/lib/python3.11/dist-packages/AutoROM/roms/crazy_climber.bin\n",
            "Installed /usr/local/lib/python3.11/dist-packages/multi_agent_ale_py/roms/crazy_climber.bin\n",
            "Installed /usr/local/lib/python3.11/dist-packages/AutoROM/roms/crossbow.bin\n",
            "Installed /usr/local/lib/python3.11/dist-packages/multi_agent_ale_py/roms/crossbow.bin\n",
            "Installed /usr/local/lib/python3.11/dist-packages/AutoROM/roms/darkchambers.bin\n",
            "Installed /usr/local/lib/python3.11/dist-packages/multi_agent_ale_py/roms/darkchambers.bin\n",
            "Installed /usr/local/lib/python3.11/dist-packages/AutoROM/roms/defender.bin\n",
            "Installed /usr/local/lib/python3.11/dist-packages/multi_agent_ale_py/roms/defender.bin\n",
            "Installed /usr/local/lib/python3.11/dist-packages/AutoROM/roms/demon_attack.bin\n",
            "Installed /usr/local/lib/python3.11/dist-packages/multi_agent_ale_py/roms/demon_attack.bin\n",
            "Installed /usr/local/lib/python3.11/dist-packages/AutoROM/roms/donkey_kong.bin\n",
            "Installed /usr/local/lib/python3.11/dist-packages/multi_agent_ale_py/roms/donkey_kong.bin\n",
            "Installed /usr/local/lib/python3.11/dist-packages/AutoROM/roms/double_dunk.bin\n",
            "Installed /usr/local/lib/python3.11/dist-packages/multi_agent_ale_py/roms/double_dunk.bin\n",
            "Installed /usr/local/lib/python3.11/dist-packages/AutoROM/roms/earthworld.bin\n",
            "Installed /usr/local/lib/python3.11/dist-packages/multi_agent_ale_py/roms/earthworld.bin\n",
            "Installed /usr/local/lib/python3.11/dist-packages/AutoROM/roms/elevator_action.bin\n",
            "Installed /usr/local/lib/python3.11/dist-packages/multi_agent_ale_py/roms/elevator_action.bin\n",
            "Installed /usr/local/lib/python3.11/dist-packages/AutoROM/roms/enduro.bin\n",
            "Installed /usr/local/lib/python3.11/dist-packages/multi_agent_ale_py/roms/enduro.bin\n",
            "Installed /usr/local/lib/python3.11/dist-packages/AutoROM/roms/entombed.bin\n",
            "Installed /usr/local/lib/python3.11/dist-packages/multi_agent_ale_py/roms/entombed.bin\n",
            "Installed /usr/local/lib/python3.11/dist-packages/AutoROM/roms/et.bin\n",
            "Installed /usr/local/lib/python3.11/dist-packages/multi_agent_ale_py/roms/et.bin\n",
            "Installed /usr/local/lib/python3.11/dist-packages/AutoROM/roms/fishing_derby.bin\n",
            "Installed /usr/local/lib/python3.11/dist-packages/multi_agent_ale_py/roms/fishing_derby.bin\n",
            "Installed /usr/local/lib/python3.11/dist-packages/AutoROM/roms/flag_capture.bin\n",
            "Installed /usr/local/lib/python3.11/dist-packages/multi_agent_ale_py/roms/flag_capture.bin\n",
            "Installed /usr/local/lib/python3.11/dist-packages/AutoROM/roms/freeway.bin\n",
            "Installed /usr/local/lib/python3.11/dist-packages/multi_agent_ale_py/roms/freeway.bin\n",
            "Installed /usr/local/lib/python3.11/dist-packages/AutoROM/roms/frogger.bin\n",
            "Installed /usr/local/lib/python3.11/dist-packages/multi_agent_ale_py/roms/frogger.bin\n",
            "Installed /usr/local/lib/python3.11/dist-packages/AutoROM/roms/frostbite.bin\n",
            "Installed /usr/local/lib/python3.11/dist-packages/multi_agent_ale_py/roms/frostbite.bin\n",
            "Installed /usr/local/lib/python3.11/dist-packages/AutoROM/roms/galaxian.bin\n",
            "Installed /usr/local/lib/python3.11/dist-packages/multi_agent_ale_py/roms/galaxian.bin\n",
            "Installed /usr/local/lib/python3.11/dist-packages/AutoROM/roms/gopher.bin\n",
            "Installed /usr/local/lib/python3.11/dist-packages/multi_agent_ale_py/roms/gopher.bin\n",
            "Installed /usr/local/lib/python3.11/dist-packages/AutoROM/roms/gravitar.bin\n",
            "Installed /usr/local/lib/python3.11/dist-packages/multi_agent_ale_py/roms/gravitar.bin\n",
            "Installed /usr/local/lib/python3.11/dist-packages/AutoROM/roms/hangman.bin\n",
            "Installed /usr/local/lib/python3.11/dist-packages/multi_agent_ale_py/roms/hangman.bin\n",
            "Installed /usr/local/lib/python3.11/dist-packages/AutoROM/roms/haunted_house.bin\n",
            "Installed /usr/local/lib/python3.11/dist-packages/multi_agent_ale_py/roms/haunted_house.bin\n",
            "Installed /usr/local/lib/python3.11/dist-packages/AutoROM/roms/hero.bin\n",
            "Installed /usr/local/lib/python3.11/dist-packages/multi_agent_ale_py/roms/hero.bin\n",
            "Installed /usr/local/lib/python3.11/dist-packages/AutoROM/roms/human_cannonball.bin\n",
            "Installed /usr/local/lib/python3.11/dist-packages/multi_agent_ale_py/roms/human_cannonball.bin\n",
            "Installed /usr/local/lib/python3.11/dist-packages/AutoROM/roms/ice_hockey.bin\n",
            "Installed /usr/local/lib/python3.11/dist-packages/multi_agent_ale_py/roms/ice_hockey.bin\n",
            "Installed /usr/local/lib/python3.11/dist-packages/AutoROM/roms/jamesbond.bin\n",
            "Installed /usr/local/lib/python3.11/dist-packages/multi_agent_ale_py/roms/jamesbond.bin\n",
            "Installed /usr/local/lib/python3.11/dist-packages/AutoROM/roms/journey_escape.bin\n",
            "Installed /usr/local/lib/python3.11/dist-packages/multi_agent_ale_py/roms/journey_escape.bin\n",
            "Installed /usr/local/lib/python3.11/dist-packages/AutoROM/roms/joust.bin\n",
            "Installed /usr/local/lib/python3.11/dist-packages/multi_agent_ale_py/roms/joust.bin\n",
            "Installed /usr/local/lib/python3.11/dist-packages/AutoROM/roms/kaboom.bin\n",
            "Installed /usr/local/lib/python3.11/dist-packages/multi_agent_ale_py/roms/kaboom.bin\n",
            "Installed /usr/local/lib/python3.11/dist-packages/AutoROM/roms/kangaroo.bin\n",
            "Installed /usr/local/lib/python3.11/dist-packages/multi_agent_ale_py/roms/kangaroo.bin\n",
            "Installed /usr/local/lib/python3.11/dist-packages/AutoROM/roms/keystone_kapers.bin\n",
            "Installed /usr/local/lib/python3.11/dist-packages/multi_agent_ale_py/roms/keystone_kapers.bin\n",
            "Installed /usr/local/lib/python3.11/dist-packages/AutoROM/roms/king_kong.bin\n",
            "Installed /usr/local/lib/python3.11/dist-packages/multi_agent_ale_py/roms/king_kong.bin\n",
            "Installed /usr/local/lib/python3.11/dist-packages/AutoROM/roms/klax.bin\n",
            "Installed /usr/local/lib/python3.11/dist-packages/multi_agent_ale_py/roms/klax.bin\n",
            "Installed /usr/local/lib/python3.11/dist-packages/AutoROM/roms/koolaid.bin\n",
            "Installed /usr/local/lib/python3.11/dist-packages/multi_agent_ale_py/roms/koolaid.bin\n",
            "Installed /usr/local/lib/python3.11/dist-packages/AutoROM/roms/krull.bin\n",
            "Installed /usr/local/lib/python3.11/dist-packages/multi_agent_ale_py/roms/krull.bin\n",
            "Installed /usr/local/lib/python3.11/dist-packages/AutoROM/roms/kung_fu_master.bin\n",
            "Installed /usr/local/lib/python3.11/dist-packages/multi_agent_ale_py/roms/kung_fu_master.bin\n",
            "Installed /usr/local/lib/python3.11/dist-packages/AutoROM/roms/laser_gates.bin\n",
            "Installed /usr/local/lib/python3.11/dist-packages/multi_agent_ale_py/roms/laser_gates.bin\n",
            "Installed /usr/local/lib/python3.11/dist-packages/AutoROM/roms/lost_luggage.bin\n",
            "Installed /usr/local/lib/python3.11/dist-packages/multi_agent_ale_py/roms/lost_luggage.bin\n",
            "Installed /usr/local/lib/python3.11/dist-packages/AutoROM/roms/mario_bros.bin\n",
            "Installed /usr/local/lib/python3.11/dist-packages/multi_agent_ale_py/roms/mario_bros.bin\n",
            "Installed /usr/local/lib/python3.11/dist-packages/AutoROM/roms/maze_craze.bin\n",
            "Installed /usr/local/lib/python3.11/dist-packages/multi_agent_ale_py/roms/maze_craze.bin\n",
            "Installed /usr/local/lib/python3.11/dist-packages/AutoROM/roms/miniature_golf.bin\n",
            "Installed /usr/local/lib/python3.11/dist-packages/multi_agent_ale_py/roms/miniature_golf.bin\n",
            "Installed /usr/local/lib/python3.11/dist-packages/AutoROM/roms/montezuma_revenge.bin\n",
            "Installed /usr/local/lib/python3.11/dist-packages/multi_agent_ale_py/roms/montezuma_revenge.bin\n",
            "Installed /usr/local/lib/python3.11/dist-packages/AutoROM/roms/mr_do.bin\n",
            "Installed /usr/local/lib/python3.11/dist-packages/multi_agent_ale_py/roms/mr_do.bin\n",
            "Installed /usr/local/lib/python3.11/dist-packages/AutoROM/roms/ms_pacman.bin\n",
            "Installed /usr/local/lib/python3.11/dist-packages/multi_agent_ale_py/roms/ms_pacman.bin\n",
            "Installed /usr/local/lib/python3.11/dist-packages/AutoROM/roms/name_this_game.bin\n",
            "Installed /usr/local/lib/python3.11/dist-packages/multi_agent_ale_py/roms/name_this_game.bin\n",
            "Installed /usr/local/lib/python3.11/dist-packages/AutoROM/roms/othello.bin\n",
            "Installed /usr/local/lib/python3.11/dist-packages/multi_agent_ale_py/roms/othello.bin\n",
            "Installed /usr/local/lib/python3.11/dist-packages/AutoROM/roms/pacman.bin\n",
            "Installed /usr/local/lib/python3.11/dist-packages/multi_agent_ale_py/roms/pacman.bin\n",
            "Installed /usr/local/lib/python3.11/dist-packages/AutoROM/roms/phoenix.bin\n",
            "Installed /usr/local/lib/python3.11/dist-packages/multi_agent_ale_py/roms/phoenix.bin\n",
            "Installed /usr/local/lib/python3.11/dist-packages/AutoROM/roms/pitfall.bin\n",
            "Installed /usr/local/lib/python3.11/dist-packages/multi_agent_ale_py/roms/pitfall.bin\n",
            "Installed /usr/local/lib/python3.11/dist-packages/AutoROM/roms/pitfall2.bin\n",
            "Installed /usr/local/lib/python3.11/dist-packages/multi_agent_ale_py/roms/pitfall2.bin\n",
            "Installed /usr/local/lib/python3.11/dist-packages/AutoROM/roms/pong.bin\n",
            "Installed /usr/local/lib/python3.11/dist-packages/multi_agent_ale_py/roms/pong.bin\n",
            "Installed /usr/local/lib/python3.11/dist-packages/AutoROM/roms/pooyan.bin\n",
            "Installed /usr/local/lib/python3.11/dist-packages/multi_agent_ale_py/roms/pooyan.bin\n",
            "Installed /usr/local/lib/python3.11/dist-packages/AutoROM/roms/private_eye.bin\n",
            "Installed /usr/local/lib/python3.11/dist-packages/multi_agent_ale_py/roms/private_eye.bin\n",
            "Installed /usr/local/lib/python3.11/dist-packages/AutoROM/roms/qbert.bin\n",
            "Installed /usr/local/lib/python3.11/dist-packages/multi_agent_ale_py/roms/qbert.bin\n",
            "Installed /usr/local/lib/python3.11/dist-packages/AutoROM/roms/riverraid.bin\n",
            "Installed /usr/local/lib/python3.11/dist-packages/multi_agent_ale_py/roms/riverraid.bin\n",
            "Installed /usr/local/lib/python3.11/dist-packages/AutoROM/roms/road_runner.bin\n",
            "Installed /usr/local/lib/python3.11/dist-packages/multi_agent_ale_py/roms/road_runner.bin\n",
            "Installed /usr/local/lib/python3.11/dist-packages/AutoROM/roms/robotank.bin\n",
            "Installed /usr/local/lib/python3.11/dist-packages/multi_agent_ale_py/roms/robotank.bin\n",
            "Installed /usr/local/lib/python3.11/dist-packages/AutoROM/roms/seaquest.bin\n",
            "Installed /usr/local/lib/python3.11/dist-packages/multi_agent_ale_py/roms/seaquest.bin\n",
            "Installed /usr/local/lib/python3.11/dist-packages/AutoROM/roms/sir_lancelot.bin\n",
            "Installed /usr/local/lib/python3.11/dist-packages/multi_agent_ale_py/roms/sir_lancelot.bin\n",
            "Installed /usr/local/lib/python3.11/dist-packages/AutoROM/roms/skiing.bin\n",
            "Installed /usr/local/lib/python3.11/dist-packages/multi_agent_ale_py/roms/skiing.bin\n",
            "Installed /usr/local/lib/python3.11/dist-packages/AutoROM/roms/solaris.bin\n",
            "Installed /usr/local/lib/python3.11/dist-packages/multi_agent_ale_py/roms/solaris.bin\n",
            "Installed /usr/local/lib/python3.11/dist-packages/AutoROM/roms/space_invaders.bin\n",
            "Installed /usr/local/lib/python3.11/dist-packages/multi_agent_ale_py/roms/space_invaders.bin\n",
            "Installed /usr/local/lib/python3.11/dist-packages/AutoROM/roms/space_war.bin\n",
            "Installed /usr/local/lib/python3.11/dist-packages/multi_agent_ale_py/roms/space_war.bin\n",
            "Installed /usr/local/lib/python3.11/dist-packages/AutoROM/roms/star_gunner.bin\n",
            "Installed /usr/local/lib/python3.11/dist-packages/multi_agent_ale_py/roms/star_gunner.bin\n",
            "Installed /usr/local/lib/python3.11/dist-packages/AutoROM/roms/superman.bin\n",
            "Installed /usr/local/lib/python3.11/dist-packages/multi_agent_ale_py/roms/superman.bin\n",
            "Installed /usr/local/lib/python3.11/dist-packages/AutoROM/roms/surround.bin\n",
            "Installed /usr/local/lib/python3.11/dist-packages/multi_agent_ale_py/roms/surround.bin\n",
            "Installed /usr/local/lib/python3.11/dist-packages/AutoROM/roms/tennis.bin\n",
            "Installed /usr/local/lib/python3.11/dist-packages/multi_agent_ale_py/roms/tennis.bin\n",
            "Installed /usr/local/lib/python3.11/dist-packages/AutoROM/roms/tetris.bin\n",
            "Installed /usr/local/lib/python3.11/dist-packages/multi_agent_ale_py/roms/tetris.bin\n",
            "Installed /usr/local/lib/python3.11/dist-packages/AutoROM/roms/tic_tac_toe_3d.bin\n",
            "Installed /usr/local/lib/python3.11/dist-packages/multi_agent_ale_py/roms/tic_tac_toe_3d.bin\n",
            "Installed /usr/local/lib/python3.11/dist-packages/AutoROM/roms/time_pilot.bin\n",
            "Installed /usr/local/lib/python3.11/dist-packages/multi_agent_ale_py/roms/time_pilot.bin\n",
            "Installed /usr/local/lib/python3.11/dist-packages/AutoROM/roms/trondead.bin\n",
            "Installed /usr/local/lib/python3.11/dist-packages/multi_agent_ale_py/roms/trondead.bin\n",
            "Installed /usr/local/lib/python3.11/dist-packages/AutoROM/roms/turmoil.bin\n",
            "Installed /usr/local/lib/python3.11/dist-packages/multi_agent_ale_py/roms/turmoil.bin\n",
            "Installed /usr/local/lib/python3.11/dist-packages/AutoROM/roms/tutankham.bin\n",
            "Installed /usr/local/lib/python3.11/dist-packages/multi_agent_ale_py/roms/tutankham.bin\n",
            "Installed /usr/local/lib/python3.11/dist-packages/AutoROM/roms/up_n_down.bin\n",
            "Installed /usr/local/lib/python3.11/dist-packages/multi_agent_ale_py/roms/up_n_down.bin\n",
            "Installed /usr/local/lib/python3.11/dist-packages/AutoROM/roms/venture.bin\n",
            "Installed /usr/local/lib/python3.11/dist-packages/multi_agent_ale_py/roms/venture.bin\n",
            "Installed /usr/local/lib/python3.11/dist-packages/AutoROM/roms/video_checkers.bin\n",
            "Installed /usr/local/lib/python3.11/dist-packages/multi_agent_ale_py/roms/video_checkers.bin\n",
            "Installed /usr/local/lib/python3.11/dist-packages/AutoROM/roms/video_chess.bin\n",
            "Installed /usr/local/lib/python3.11/dist-packages/multi_agent_ale_py/roms/video_chess.bin\n",
            "Installed /usr/local/lib/python3.11/dist-packages/AutoROM/roms/video_cube.bin\n",
            "Installed /usr/local/lib/python3.11/dist-packages/multi_agent_ale_py/roms/video_cube.bin\n",
            "Installed /usr/local/lib/python3.11/dist-packages/AutoROM/roms/video_pinball.bin\n",
            "Installed /usr/local/lib/python3.11/dist-packages/multi_agent_ale_py/roms/video_pinball.bin\n",
            "Installed /usr/local/lib/python3.11/dist-packages/AutoROM/roms/warlords.bin\n",
            "Installed /usr/local/lib/python3.11/dist-packages/multi_agent_ale_py/roms/warlords.bin\n",
            "Installed /usr/local/lib/python3.11/dist-packages/AutoROM/roms/wizard_of_wor.bin\n",
            "Installed /usr/local/lib/python3.11/dist-packages/multi_agent_ale_py/roms/wizard_of_wor.bin\n",
            "Installed /usr/local/lib/python3.11/dist-packages/AutoROM/roms/word_zapper.bin\n",
            "Installed /usr/local/lib/python3.11/dist-packages/multi_agent_ale_py/roms/word_zapper.bin\n",
            "Installed /usr/local/lib/python3.11/dist-packages/AutoROM/roms/yars_revenge.bin\n",
            "Installed /usr/local/lib/python3.11/dist-packages/multi_agent_ale_py/roms/yars_revenge.bin\n",
            "Installed /usr/local/lib/python3.11/dist-packages/AutoROM/roms/zaxxon.bin\n",
            "Installed /usr/local/lib/python3.11/dist-packages/multi_agent_ale_py/roms/zaxxon.bin\n",
            "Done!\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import sys\n",
        "import gymnasium as gym\n",
        "from stable_baselines3 import PPO\n",
        "from google.colab import drive\n",
        "# Start AutoROM\n",
        "\n",
        "!AutoROM\n",
        "\n",
        "# Import libraries\n",
        "from pettingzoo.atari import warlords_v3\n",
        "from pettingzoo.utils import BaseParallelWrapper\n",
        "from collections import defaultdict, Counter\n",
        "import importlib\n",
        "import os\n",
        "import imageio"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<div style=\"background-color:white; color:black; padding: 10px;\">\n",
        "    <strong>Mounten van colab drive en inladen van de agents</strong>\n",
        "</div>"
      ],
      "metadata": {
        "id": "041sv7N4qs7r"
      },
      "id": "041sv7N4qs7r"
    },
    {
      "cell_type": "code",
      "source": [
        "drive.mount('/content/drive')\n",
        "sys.path.append('/content/drive/MyDrive/Autonomous Systems')\n",
        "print(os.listdir('/content/drive/MyDrive/Autonomous Systems'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5w-qIX5DqtDb",
        "outputId": "7954bc20-c3b8-4393-d6ae-324e7244d273"
      },
      "id": "5w-qIX5DqtDb",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "id": "438c13d8",
      "metadata": {
        "id": "438c13d8"
      },
      "source": [
        "\n",
        "---\n",
        "<div style=\"background-color:LightBlue; text-align:center; vertical-align:middle; padding:50px 0; margin-top:5px; margin-bottom:5px\">\n",
        "    <h2 id=\"eda-title\" style=\"color:black; font-family: Verdana, sans-serif; font-size: 25px;\"><strong>H2: Kiezen van Algoritme </strong></h2>\n",
        "</div>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "732b4263",
      "metadata": {
        "id": "732b4263"
      },
      "source": [
        "<a name='1.1'></a>\n",
        "<h3>&sect;2.1: Kiezen van RL-Algoritme</h3>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6c1c9536",
      "metadata": {
        "id": "6c1c9536"
      },
      "source": [
        "a.\tJouw agent zal deelnemen en interacten met andere agenten in de Atari-omgeving \"Warlords\"."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<div style=\"background-color:white; color:black; padding: 10px;\">\n",
        "    <strong>Agent 1: (Rogier) DQN - Deep Q-Network</strong>\n",
        "</div>\n",
        "\n"
      ],
      "metadata": {
        "id": "WRwBHRpV864G"
      },
      "id": "WRwBHRpV864G"
    },
    {
      "cell_type": "markdown",
      "source": [
        "## §2.1: Kiezen van RL-Algoritme\n",
        "\n",
        "In deze opdracht staat de Atari-game **Warlords** centraal: een klassieke arcadegame waarbij vier spelers (agents) gelijktijdig strijden op een speelveld. Iedere agent verdedigt zijn eigen kasteel en probeert de anderen uit te schakelen, wat resulteert in een typisch **multi-agent scenario** met zowel competitie als wisselende interactiepatronen tussen agents. Voor deze complexe en dynamische omgeving is het belangrijk om een reinforcement learning-algoritme te kiezen dat bewezen effectief is bij problemen met een hoge mate van onzekerheid, veel mogelijke toestanden en meerdere spelers.\n",
        "\n",
        "We kiezen voor het **Proximal Policy Optimization (PPO)** algoritme als basis voor onze agent. PPO is een krachtig, modern en veelgebruikt algoritme binnen deep reinforcement learning. Het is ontworpen voor stabiliteit en efficiëntie bij het optimaliseren van beleid (policies), en heeft uitstekende prestaties laten zien in visuele, dynamische omgevingen zoals Atari-games. PPO leert direct van ruwe pixeldata via een convolutioneel neuraal netwerk en maakt gebruik van policy-gradient updates die gecontroleerd worden uitgevoerd om instabiliteit te voorkomen.\n",
        "\n",
        "### Waarom PPO?\n",
        "\n",
        "- **Geschikt voor visuele input:**  \n",
        "  PPO werkt uitstekend met ruwe spelbeelden (frames) als input, en kan daardoor zelfstandig complexe strategieën ontwikkelen zonder handmatige feature engineering. De convolutionele neurale netwerken van PPO zijn uitermate geschikt voor het herkennen van visuele patronen in Atari-omgevingen.\n",
        "\n",
        "- **Stabiel en robuust leren:**  \n",
        "  Door het gebruik van trust-region updates (clipping), mini-batch learning en advantage schatting (GAE), blijft het leerproces gecontroleerd en raakt het model minder snel verstrikt in abrupte of onstabiele policy-wijzigingen. Dit is cruciaal in chaotische multi-agent omgevingen zoals Warlords.\n",
        "\n",
        "- **Multi-agent compatibiliteit:**  \n",
        "  PPO laat zich eenvoudig toepassen op multi-agent settings, bijvoorbeeld via parameter sharing (één policy voor meerdere agents) of door individuele policies te trainen per agent. Dit maakt het flexibel inzetbaar voor uiteenlopende experimenten.\n",
        "\n",
        "- **Breed onderzocht en veel gebruikt:**  \n",
        "  PPO behoort tot de standaardbenchmarks in reinforcement learning en is in tal van studies succesvol ingezet voor Atari-omgevingen en multi-agent settings. Er zijn veel goed onderhouden frameworks beschikbaar (zoals Stable-Baselines3 en PettingZoo), wat snelle en correcte implementatie mogelijk maakt.\n",
        "\n",
        "### Concreet voordeel voor deze opdracht\n",
        "\n",
        "- **Algoritmische robuustheid:**  \n",
        "  PPO is bijzonder effectief in dynamische en onvoorspelbare omgevingen waar het gedrag van andere agents voortdurend verandert. Dankzij gecontroleerde policy-updates en efficiënte verwerking van ervaringen is PPO in staat om robuuste strategieën te ontwikkelen.\n",
        "\n",
        "- **Vergelijkbaarheid:**  \n",
        "  PPO is een veelgebruikte standaard in de literatuur rondom Atari en multi-agent reinforcement learning. Hierdoor zijn onze resultaten goed te vergelijken met bestaande benchmarks en alternatieve algoritmes (zoals DQN of random policies).\n",
        "\n",
        "- **Transparantie en reproduceerbaarheid:**  \n",
        "  Dankzij de brede adoptie en solide implementaties in frameworks als Stable-Baselines3 en PettingZoo zijn onze experimenten eenvoudig te reproduceren, uit te breiden en te valideren door andere studenten of onderzoekers.\n"
      ],
      "metadata": {
        "id": "aTDt5gr586-3"
      },
      "id": "aTDt5gr586-3"
    },
    {
      "cell_type": "markdown",
      "source": [
        "<div style=\"background-color:white; color:black; padding: 10px;\">\n",
        "    <strong>Agent 2: (Julia) PPO - Proximal Policy Optimization</strong>\n",
        "</div>\n",
        "\n"
      ],
      "metadata": {
        "id": "Hth3awtZ7i_v"
      },
      "id": "Hth3awtZ7i_v"
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Uitleg van PPO**\n",
        "\n",
        "Proximal Policy Optimization (PPO) is een geavanceerd reinforcement learning-algoritme dat veel wordt gebruikt voor het trainen van agents in complexe omgevingen zoals Atari-spellen. PPO verbetert eerdere policy-gradient-methodes door bij elke stap de aanpassing van het beleid (“policy”) te beperken. Hierdoor wordt het leerproces stabieler en is de kans kleiner dat de agent ineens “vergeet” wat hij geleerd heeft.\n",
        "\n",
        "PPO werkt door het beleid steeds een klein beetje aan te passen op basis van ervaringen uit de omgeving. Hierdoor leert de agent efficiënter en zijn de resultaten vaak beter reproduceerbaar. PPO is ook geschikt voor situaties met hoge-dimensionale input, zoals beelden, en werkt goed in multi-agent omgevingen zoals Warlords.\n",
        "\n",
        "DhanushKumar (2024)\n",
        "\n",
        "### **Motivatie**\n",
        "\n",
        "Voor deze opdracht heb ik gekozen voor het algoritme Proximal Policy Optimization (PPO). De belangrijkste reden hiervoor is dat PPO bekend staat om zijn stabiliteit en efficiëntie bij het trainen van agents in complexe omgevingen met hoge-dimensionale input, zoals de Atari-game Warlords, Schulman et al. (2017). Omdat PPO de aanpassingen aan het beleid per stap beperkt, blijft het leerproces gecontroleerd en voorkom je dat de agent tijdens het trainen “vergeet” wat eerder geleerd is. Dit is vooral belangrijk in multi-agent omgevingen, waar het gedrag van andere agents de situatie voortdurend beïnvloedt.\n",
        "\n",
        "Daarnaast is PPO eenvoudig te implementeren dankzij bestaande libraries zoals stable-baselines3, waardoor het mogelijk is om snel te experimenteren met verschillende hyperparameters. De standaardwaarden die ik voor de belangrijkste hyperparameters heb gekozen, zijn gebaseerd op aanbevelingen uit de literatuur en eerdere succesvolle toepassingen in vergelijkbare omgevingen (The 37 Implementation Details Of Proximal Policy Optimization · The ICLR Blog Track, 2022). PPO is bovendien goed schaalbaar, waardoor het geschikt is om in een multi-agent setting zoals Warlords verschillende agents onafhankelijk van elkaar te trainen en te vergelijken.\n",
        "\n",
        "Door deze eigenschappen is PPO naar mijn mening de meest geschikte keuze voor deze opdracht, omdat het zorgt voor betrouwbare leerresultaten en flexibiliteit biedt bij het uitvoeren van experimenten met verschillende agents en trainingsinstellingen.\n",
        "\n",
        "### **Aanpak**\n",
        "\n",
        "Voor deze opdracht heb ik een PPO-agent geïmplementeerd met behulp van de stable-baselines3 library. PPO is gekozen vanwege de stabiele prestaties en de robuustheid bij het trainen in omgevingen met beeldinput, zoals “Warlords”. De agent gebruikt een convolutioneel neuraal netwerk om de observaties te verwerken.\n",
        "De belangrijkste hyperparameters zijn gekozen op basis van aanbevolen waarden uit wetenschappelijke literatuur voor Atari-omgevingen, maar kunnen verder geoptimaliseerd worden.\n",
        "Mijn implementatie maakt het makkelijk om het model op te slaan, opnieuw te laden en te evalueren, zodat experimenten goed reproduceerbaar zijn."
      ],
      "metadata": {
        "id": "cZW97gbO7eh5"
      },
      "id": "cZW97gbO7eh5"
    },
    {
      "cell_type": "markdown",
      "id": "e9d941ae",
      "metadata": {
        "id": "e9d941ae"
      },
      "source": [
        "<a name='1.1'></a>\n",
        "<h3>&sect;2.3: Kiezen van Trainingsstrategie</h3>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5b7196ea",
      "metadata": {
        "id": "5b7196ea"
      },
      "source": [
        "b.\tKies een geschikt RL-algoritme en trainingsstrategie voor je agent. Beschrijf en motiveer je keuzes."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<div style=\"background-color:white; color:black; padding: 10px;\">\n",
        "    <strong>Agent 1: (Rogier) DQN - Deep Q-Network </strong>\n",
        "</div>\n",
        "\n"
      ],
      "metadata": {
        "id": "05IP74Mw9UG2"
      },
      "id": "05IP74Mw9UG2"
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Trainingsstrategie in Multi-Agent Warlords\n",
        "\n",
        "Om optimaal gebruik te maken van het gekozen algoritme, hanteren we een trainingsstrategie die inspeelt op de uitdagingen van multi-agent reinforcement learning:\n",
        "\n",
        "1. **Multi-agent omgeving:**  \n",
        "   In Warlords zijn altijd meerdere agents actief. Onze PPO-agent wordt getraind door herhaaldelijk games te spelen tegen vooraf ingestelde tegenstanders, zoals random agents of (indien gewenst) andere PPO-agents. Dit zorgt ervoor dat de agent leert in een realistische, competitieve setting.\n",
        "\n",
        "2. **Variatie in tegenstanders:**  \n",
        "   Door de agent bloot te stellen aan verschillende typen tegenstanders (van random tot geavanceerd), voorkomen we dat de agent eenzijdige strategieën aanleert. Zo ontwikkelt de agent robuustere, meer generaliseerbare strategieën.\n",
        "\n",
        "3. **Observatie- en actie-preprocessing:**  \n",
        "   We gebruiken beeldverwerkingstechnieken zoals grijswaardenconversie, rescaling en stacking van frames. Dit zorgt ervoor dat de agent alleen de essentiële informatie uit het spel verwerkt, waardoor het leerproces efficiënter verloopt.\n",
        "\n",
        "4. **On-policy leren & rollouts:**  \n",
        "   PPO werkt met zogenoemde rollouts: de agent verzamelt verse trajecten door de omgeving en leert direct van deze actuele ervaringen. Dit betekent dat elke policy-update gebaseerd is op recent gedrag, wat bijdraagt aan stabiliteit en effectieve policy-veranderingen.\n",
        "\n",
        "5. **Regelmatige evaluatie en hyperparameter tuning:**  \n",
        "   Tijdens de training evalueren we regelmatig de prestaties van de agent door deze te laten spelen tegen de baseline (zoals een random agent). Daarnaast experimenteren we met verschillende hyperparameters, zoals learning rate, batch size, en de clipping-range van PPO, om de optimale instellingen te bepalen.\n",
        "\n",
        "6. **Logging en visualisatie:**  \n",
        "   Alle trainingsresultaten (zoals reward curves, winpercentages, etc.) worden gelogd en gevisualiseerd. Hierdoor kunnen we het leerproces volgen en analyseren, en waar nodig de strategie bijstellen.\n",
        "\n",
        "### Samenvattend\n",
        "\n",
        "Deze aanpak zorgt ervoor dat onze PPO-agent niet alleen leert van het eigen gedrag, maar zich ook kan aanpassen aan verschillende soorten tegenstanders. Door systematisch te trainen, evalueren en hyperparameters te tunen, halen we het maximale uit ons algoritme en maken we de voordelen van reinforcement learning in een multi-agent context helder zichtbaar.\n"
      ],
      "metadata": {
        "id": "QdDPbh7p9UNL"
      },
      "id": "QdDPbh7p9UNL"
    },
    {
      "cell_type": "markdown",
      "source": [
        "<div style=\"background-color:white; color:black; padding: 10px;\">\n",
        "    <strong>Agent 2: (Julia) PPO - Proximal Policy Optimization (Hier mist denk ik nog wat of ik heb het niet goed doorgelezen)(Julia morgen)</strong>\n",
        "</div>\n",
        "\n"
      ],
      "metadata": {
        "id": "OnqBjKqn7uln"
      },
      "id": "OnqBjKqn7uln"
    },
    {
      "cell_type": "markdown",
      "id": "6107d561",
      "metadata": {
        "id": "6107d561"
      },
      "source": [
        "\n",
        "---\n",
        "<div style=\"background-color:LightBlue; text-align:center; vertical-align:middle; padding:50px 0; margin-top:5px; margin-bottom:5px\">\n",
        "    <h2 id=\"eda-title\" style=\"color:black; font-family: Verdana, sans-serif; font-size: 25px;\"><strong>H3: Probleemdefinitie </strong></h2>\n",
        "</div>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6bcbb909",
      "metadata": {
        "id": "6bcbb909"
      },
      "source": [
        "<a name='1.1'></a>\n",
        "<h3>&sect;3.1: Wat is het probleem?</h3>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "31d9d8c7",
      "metadata": {
        "id": "31d9d8c7"
      },
      "source": [
        "c.\tResultaat: Een helder uitgewerkte motivatie in je rapport (“Inleiding & Probleemanalyse”)."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Probleemanalyse\n",
        "De opkomst van multi-agent omgevingen in toepassingen zoals robotica, games en logistiek vraagt om slimme algoritmes die kunnen concurreren én samenwerken. In de praktijk betekent dit dat agents hun strategieën continu moeten bijstellen op basis van het gedrag van andere agents in hun omgeving. In de Atari-game Warlords komen vier agents tegelijkertijd in actie, waarbij hun succes afhankelijk is van zowel hun eigen keuzes als die van hun tegenstanders.\n",
        "\n",
        "Single-agent reinforcement learning is onvoldoende, omdat hierbij wordt aangenomen dat de omgeving stationair is (niet verandert door anderen). In multi-agent settings verandert de omgeving echter continu, omdat andere agents ook leren en hun gedrag aanpassen. Dit vraagt om een benadering waarbij agents niet alleen leren van hun eigen ervaringen, maar ook van de interacties met anderen.\n",
        "\n",
        "Met multi-agent reinforcement learning (MARL) kunnen agents hun beleid optimaliseren terwijl ze rekening houden met de strategieën van anderen. Hierdoor ontstaan vaak complexe en onverwachte gedragingen die in single-agent settings niet mogelijk zijn. Bovendien kunnen MARL-methoden worden ingezet om situaties te modelleren waarin competitie, samenwerking of beide tegelijk nodig zijn.\n",
        "\n",
        "##### Relevantie van het probleem\n",
        "- In veel echte omgevingen zijn meerdere autonome beslissers actief (bijvoorbeeld zelfrijdende auto's in verkeer).\n",
        "- Het ontwerpen van robuuste agents in zulke settings helpt bij het ontwikkelen van realistische, schaalbare en adaptieve AI-systemen.\n",
        "- In de context van games als Warlords kan MARL inzichten bieden in hoe intelligente strategieën en tegenstrategieën ontstaan in competitieve settings.\n",
        "\n",
        "##### Samenvatting probleemstelling (één zin):\n",
        "\"Hoe kunnen we effectieve, lerende agents ontwikkelen die optimaal presteren in een competitieve multi-agent omgeving, waarbij rekening wordt gehouden met de voortdurende interactie en dynamiek tussen verschillende agents?\"\n",
        "\n",
        "Scharwächter (2024)\n",
        "\n",
        "#### Doelstelling\n",
        "Het doel van deze opdracht is om een multi-agent reinforcement learning systeem te ontwerpen, implementeren en evalueren voor de Atari Warlords-omgeving. Dit gebeurt door vier verschillende MARL-algoritmes (PPO, MADDPG, [keuze Peet] en [keuze Jort]) te trainen en hun prestaties te vergelijken met een baseline. Het eindresultaat is een reproduceerbaar systeem en een rapport met een diepgaande analyse van de werking en effectiviteit van de gekozen algoritmen."
      ],
      "metadata": {
        "id": "9ydUYqpqrNmw"
      },
      "id": "9ydUYqpqrNmw"
    },
    {
      "cell_type": "markdown",
      "id": "18f470aa",
      "metadata": {
        "id": "18f470aa"
      },
      "source": [
        "\n",
        "---\n",
        "<div style=\"background-color:LightBlue; text-align:center; vertical-align:middle; padding:50px 0; margin-top:5px; margin-bottom:5px\">\n",
        "    <h2 id=\"eda-title\" style=\"color:black; font-family: Verdana, sans-serif; font-size: 25px;\"><strong>H4: Ontwerp en Implementatie</strong></h2>\n",
        "</div>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "086bad36",
      "metadata": {
        "id": "086bad36"
      },
      "source": [
        "<a name='1.1'></a>\n",
        "<h3>&sect;4.1: Baseline strategie ontwikkelen</h3>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0cffc336",
      "metadata": {
        "id": "0cffc336"
      },
      "source": [
        "a.\tOntwikkel een baseline zoals bijvoorbeeld een rule-based policy een random policy of een andere simpele heuristiek.  "
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<div style=\"background-color:white; color:black; padding: 10px;\">\n",
        "    <strong>Baseline: Random Agent</strong>\n",
        "</div>\n",
        "\n",
        "Als startpunt voor het vergelijken van verschillende algoritmes is het belangrijk om een baseline te definiëren. In deze opdracht gebruiken we een random agent als baseline. Dit is een agent die bij elke stap willekeurig een van de mogelijke acties kiest, ongeacht de observatie of situatie in het spel.\n",
        "\n",
        "**Waarom een random agent als baseline?**\n",
        "\n",
        "Een random agent biedt een objectief referentiepunt: het laat zien wat de prestaties zouden zijn zonder enige vorm van intelligentie, strategie of leren. Door de resultaten van geavanceerdere agents (zoals een rule-based agent of een reinforcement learning agent zoals PPO) te vergelijken met deze random agent, kun je duidelijk aantonen of jouw aanpak daadwerkelijk beter presteert dan toeval.\n",
        "\n",
        "**Implementatie**\n",
        "\n",
        "De implementatie van de random agent is heel eenvoudig. De agent kiest telkens een willekeurige actie uit het totale aantal toegestane acties van de omgeving. In het geval van Atari Warlords zijn dit bijvoorbeeld zes mogelijke acties.\n"
      ],
      "metadata": {
        "id": "hmQKYc-6tRob"
      },
      "id": "hmQKYc-6tRob"
    },
    {
      "cell_type": "code",
      "source": [
        "class AgentRandomPolicy:\n",
        "    def act(self, observation):\n",
        "        # Return a random action (6 possible in ALE Warlords)\n",
        "        return np.random.randint(6)\n"
      ],
      "metadata": {
        "id": "IXQkWF0RsqFo"
      },
      "id": "IXQkWF0RsqFo",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "b41eef89",
      "metadata": {
        "id": "b41eef89"
      },
      "source": [
        "<a name='1.1'></a>\n",
        "<h3>&sect;4.2: Selectie van DRL algoritme en frameworks</h3>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6e23682d",
      "metadata": {
        "id": "6e23682d"
      },
      "source": [
        "b.\tKies een passend DRL-algoritme, die geschikt is voor een multi-agent setting. Kies geschikte packages en frameworks."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<div style=\"background-color:white; color:black; padding: 10px;\">\n",
        "    <strong>Dit is uitgewerkt maar niet iedereen zijn agent staat er nu bij sinds ik dat nog niet weet en of je packages etc zijn uitgelegd. Iedereen moet dat hier zelf in toevoegen <strong> </div>\n",
        "\n"
      ],
      "metadata": {
        "id": "4K5_Zj8T-a1N"
      },
      "id": "4K5_Zj8T-a1N"
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Keuze van Algoritme\n",
        "\n",
        "Voor deze opdracht, waarin de agent moet presteren in de **multi-agent omgeving van Atari Warlords**, kiezen we voor het **Proximal Policy Optimization (PPO)** algoritme. PPO is momenteel één van de meest gebruikte en robuuste algoritmes voor deep reinforcement learning, vooral geschikt voor problemen met complexe visuele input en multi-agent interactie. De belangrijkste voordelen van PPO:\n",
        "\n",
        "- **Stabiel leren van ruwe pixels:** PPO maakt gebruik van convolutionele neurale netwerken (CNN’s) om direct van visuele observaties te leren, zonder handmatig feature engineering.\n",
        "- **Uitstekende prestaties in Atari-omgevingen:** PPO heeft zich bewezen als benchmark-algoritme in veel Atari-games, mede dankzij de balans tussen exploratie en exploitatie.\n",
        "- **Direct geschikt voor multi-agent settings:** PPO kan eenvoudig worden ingezet met *parameter sharing* (één policy voor meerdere agents) of individuele policies per agent, wat het flexibel maakt voor uiteenlopende MARL-experimenten.\n",
        "\n",
        "### Keuze & Motivatie\n",
        "\n",
        "In deze opdracht trainen we een **PPO-agent** in de multi-agent Warlords-omgeving. Hierbij nemen onze agenten het op tegen ingebouwde tegenstanders, zoals random agents. Zo kunnen we de kracht van deep RL aantonen in vergelijking met simpele baseline strategieën.\n",
        "\n",
        "#### Waarom PPO in deze context?\n",
        "\n",
        "- **Stabiele policy learning:** PPO minimaliseert het risico op instabiliteit door gecontroleerde policy-updates (clipping), wat vooral belangrijk is in chaotische multi-agent omgevingen.\n",
        "- **Visual input:** Warlords levert observaties als pixeldata, wat naadloos aansluit op de CNN-architectuur van PPO.\n",
        "- **Flexibiliteit:** PPO werkt zowel met discrete als continue actie-ruimtes en laat zich makkelijk combineren met moderne MARL frameworks.\n",
        "\n",
        "---\n",
        "\n",
        "### Packages en Frameworks\n",
        "\n",
        "Voor de implementatie en evaluatie maken we gebruik van de volgende frameworks en libraries:\n",
        "\n",
        "#### 1. **Stable-Baselines3**\n",
        "- Biedt een krachtige en stabiele implementatie van PPO, met uitgebreide ondersteuning voor logging en evaluatie.\n",
        "- Direct compatibel met vectorized en custom omgevingen.\n",
        "\n",
        "#### 2. **PettingZoo**\n",
        "- De standaard voor multi-agent reinforcement learning omgevingen, met een ruime keuze aan benchmarkomgevingen zoals Atari Warlords.\n",
        "- Zorgt voor een uniforme interface en maakt snelle experimentatie mogelijk.\n",
        "\n",
        "#### 3. **Supersuit**\n",
        "- Bibliotheek voor preprocessing (o.a. frames resizen, kleuren reduceren en frame stacking), essentieel voor efficiënte training op visuele data.\n",
        "\n",
        "---\n",
        "\n",
        "### Samenvatting van de strategie\n",
        "\n",
        "- We trainen een PPO-agent in de **PettingZoo Atari Warlords** omgeving tegen baseline agents (zoals random).\n",
        "- PPO stelt ons in staat om efficiënt en stabiel te leren in deze multi-agent setting, met als doel beter te presteren dan eenvoudige baselines.\n",
        "- Door te bouwen op bewezen frameworks en preprocessing pipelines is onze aanpak **reproduceerbaar, schaalbaar en robuust**.\n",
        "\n",
        "---\n"
      ],
      "metadata": {
        "id": "sm8SLNH6wAbI"
      },
      "id": "sm8SLNH6wAbI"
    },
    {
      "cell_type": "markdown",
      "id": "e51ff2f0",
      "metadata": {
        "id": "e51ff2f0"
      },
      "source": [
        "<a name='1.1'></a>\n",
        "<h3>&sect;4.3: Implementatie MARL-agent</h3>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "327a104c",
      "metadata": {
        "id": "327a104c"
      },
      "source": [
        "d.\tResultaat: Een werkend MARL-systeem dat klaar is voor training en evaluatie."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<div style=\"background-color:white; color:black; padding: 10px;\">\n",
        "    <strong>(Rogier) PPO Agent ( DEZE FUNCTIE NOG ZETTEN BIJ DE TRAINING STAP )</strong>\n",
        "</div>"
      ],
      "metadata": {
        "id": "3us4a2TXs3IY"
      },
      "id": "3us4a2TXs3IY"
    },
    {
      "cell_type": "markdown",
      "source": [
        "In de onderstaande cel definiëren we de klasse MARLAgentPPO, een modulair systeem dat geschikt is voor het trainen van PPO-agenten in een multi-agent setting met behulp van de PettingZoo-omgeving warlords_v3. De klasse bevat methoden voor het instellen van de omgeving, het trainen van het model, en het opslaan of laden van een getraind PPO-model.\n",
        "\n",
        " -   De omgeving wordt gepreprocessed met behulp van Supersuit-wrappers (zoals black_death, color_reduction, resizing en frame stacking).\n",
        "\n",
        "-  Vervolgens wordt de omgeving geconverteerd naar een vectorized environment die compatibel is met Stable-Baselines3.\n",
        "\n",
        "-   De train()-methode traint het PPO-model met een CnnPolicy, geschikt voor de beeldinvoer van Atari-games.\n",
        "\n",
        "-  Met save() en load() kunnen getrainde modellen eenvoudig worden opgeslagen of ingeladen.\n",
        "\n",
        "Deze klasse maakt het mogelijk om met ons MARL-systeem op een reproduceerbare en schaalbare manier PPO-agenten te trainen in een multi-agent omgeving.\n",
        "\n",
        "(PPO — Stable Baselines3 2.7.0a0 Documentation, z.d.)"
      ],
      "metadata": {
        "id": "QVf1ym4iZO3C"
      },
      "id": "QVf1ym4iZO3C"
    },
    {
      "cell_type": "markdown",
      "source": [
        "# MARL PPO met meer parameters"
      ],
      "metadata": {
        "id": "morKGfwKC5pq"
      },
      "id": "morKGfwKC5pq"
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "import supersuit as ss\n",
        "from stable_baselines3 import PPO\n",
        "from stable_baselines3.ppo import CnnPolicy\n",
        "from pettingzoo.atari import warlords_v3\n",
        "\n",
        "class MARLAgentPPO:\n",
        "    \"\"\"\n",
        "    Multi-Agent RL systeem voor de Atari Warlords omgeving.\n",
        "    Ondersteunt setup, training, evaluatie en het opslaan/laden van PPO-modellen.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(\n",
        "        self,\n",
        "        num_vec_envs=2,\n",
        "        frame_stack=4,\n",
        "        x_size=84,\n",
        "        y_size=84,\n",
        "        batch_size=256,\n",
        "        total_timesteps=4_000_000,\n",
        "        verbose=1\n",
        "    ):\n",
        "        \"\"\"\n",
        "        Initialiseer de omgeving en hyperparameters.\n",
        "        \"\"\"\n",
        "        self.num_vec_envs = num_vec_envs\n",
        "        self.frame_stack = frame_stack\n",
        "        self.x_size = x_size\n",
        "        self.y_size = y_size\n",
        "        self.batch_size = batch_size\n",
        "        self.total_timesteps = total_timesteps\n",
        "        self.verbose = verbose\n",
        "\n",
        "        self.env = self._make_env()\n",
        "        self.vec_env = self._make_vec_env()\n",
        "        self.model = None\n",
        "\n",
        "    def _make_env(self):\n",
        "        \"\"\"\n",
        "        Zet de Warlords-omgeving klaar met preprocessing-wrappers.\n",
        "        \"\"\"\n",
        "        env = warlords_v3.parallel_env()\n",
        "        env = ss.black_death_v3(env)\n",
        "        env = ss.color_reduction_v0(env, mode='full')\n",
        "        env = ss.resize_v1(env, x_size=self.x_size, y_size=self.y_size)\n",
        "        env = ss.frame_stack_v1(env, self.frame_stack)\n",
        "        return env\n",
        "\n",
        "    def _make_vec_env(self):\n",
        "        \"\"\"\n",
        "        Converteer naar een vectorized environment voor Stable-Baselines3.\n",
        "        \"\"\"\n",
        "        vec_env = ss.pettingzoo_env_to_vec_env_v1(self.env)\n",
        "        vec_env = ss.concat_vec_envs_v1(\n",
        "            vec_env,\n",
        "            num_vec_envs=self.num_vec_envs,\n",
        "            num_cpus=1,\n",
        "            base_class=\"stable_baselines3\"\n",
        "        )\n",
        "        return vec_env\n",
        "\n",
        "    def train(self):\n",
        "        \"\"\"\n",
        "        Initialiseer en train het PPO-model met geoptimaliseerde hyperparameters.\n",
        "        \"\"\"\n",
        "        print(\"Start training...\")\n",
        "        self.model = PPO(\n",
        "            CnnPolicy,\n",
        "            self.vec_env,\n",
        "            verbose=self.verbose,\n",
        "            batch_size=self.batch_size,\n",
        "            n_steps=128,\n",
        "            n_epochs=4,\n",
        "            learning_rate=2.5e-4,\n",
        "            ent_coef=0.01,\n",
        "            gae_lambda=0.95,\n",
        "            gamma=0.99,\n",
        "            clip_range=0.1,\n",
        "            vf_coef=0.5,\n",
        "            max_grad_norm=0.5,\n",
        "            tensorboard_log=\"./ppo_warlords_tensorboard/\"\n",
        "        )\n",
        "        self.model.learn(total_timesteps=self.total_timesteps)\n",
        "        print(\"Training gereed.\")\n",
        "\n",
        "    def save(self, model_name=None):\n",
        "        \"\"\"\n",
        "        Sla het getrainde model op, optioneel met custom naam.\n",
        "        \"\"\"\n",
        "        if self.model is None:\n",
        "            raise ValueError(\"Model is nog niet getraind.\")\n",
        "        if model_name is None:\n",
        "            timestamp = time.strftime(\"%Y%m%d-%H%M%S\")\n",
        "            model_name = f\"warlords_ppo_model_{timestamp}\"\n",
        "        self.model.save(model_name)\n",
        "        print(f\"Model opgeslagen als {model_name}\")\n",
        "\n",
        "    def load(self, path):\n",
        "        \"\"\"\n",
        "        Laad een eerder getraind PPO-model.\n",
        "        \"\"\"\n",
        "        self.model = PPO.load(path)\n",
        "        print(f\"Model geladen van {path}\")\n"
      ],
      "metadata": {
        "id": "LatI8v0NC3q8"
      },
      "id": "LatI8v0NC3q8",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "agent2 = MARLAgentPPO()\n",
        "agent2.train()\n",
        "agent2.save(\"ppo_model_warlords_4m\")\n",
        "save_path = \"/content/drive/MyDrive/MARL_models\"\n",
        "import os\n",
        "\n",
        "# Zorg dat de map bestaat\n",
        "os.makedirs(save_path, exist_ok=True)\n",
        "\n",
        "# Sla model op met een custom naam en pad\n",
        "model_name = os.path.join(save_path, \"warlords_ppo_model_4m\")\n",
        "agent2.save(model_name)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "214zLTC8D34j",
        "outputId": "5e17f931-8ef3-4d37-ffee-64a667efc6ef"
      },
      "id": "214zLTC8D34j",
      "execution_count": null,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Start training...\n",
            "Using cuda device\n",
            "Wrapping the env in a VecTransposeImage.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/stable_baselines3/common/vec_env/base_vec_env.py:78: UserWarning: The `render_mode` attribute is not defined in your environment. It will be set to None.\n",
            "  warnings.warn(\"The `render_mode` attribute is not defined in your environment. It will be set to None.\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1;30;43mStreaming output truncated to the last 5000 lines.\u001b[0m\n",
            "|    approx_kl            | 0.0024425047 |\n",
            "|    clip_fraction        | 0.0933       |\n",
            "|    clip_range           | 0.1          |\n",
            "|    entropy_loss         | -1.72        |\n",
            "|    explained_variance   | 0.219        |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | -0.0296      |\n",
            "|    n_updates            | 14516        |\n",
            "|    policy_gradient_loss | -0.00833     |\n",
            "|    value_loss           | 1.77e-05     |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 591          |\n",
            "|    iterations           | 3631         |\n",
            "|    time_elapsed         | 6289         |\n",
            "|    total_timesteps      | 3718144      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0040649907 |\n",
            "|    clip_fraction        | 0.151        |\n",
            "|    clip_range           | 0.1          |\n",
            "|    entropy_loss         | -1.72        |\n",
            "|    explained_variance   | 0.32         |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | -0.0348      |\n",
            "|    n_updates            | 14520        |\n",
            "|    policy_gradient_loss | -0.0115      |\n",
            "|    value_loss           | 7.97e-06     |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 591          |\n",
            "|    iterations           | 3632         |\n",
            "|    time_elapsed         | 6291         |\n",
            "|    total_timesteps      | 3719168      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0022883913 |\n",
            "|    clip_fraction        | 0.0747       |\n",
            "|    clip_range           | 0.1          |\n",
            "|    entropy_loss         | -1.72        |\n",
            "|    explained_variance   | 0.199        |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | -0.0447      |\n",
            "|    n_updates            | 14524        |\n",
            "|    policy_gradient_loss | -0.0103      |\n",
            "|    value_loss           | 5.33e-06     |\n",
            "------------------------------------------\n",
            "----------------------------------------\n",
            "| time/                   |            |\n",
            "|    fps                  | 591        |\n",
            "|    iterations           | 3633       |\n",
            "|    time_elapsed         | 6292       |\n",
            "|    total_timesteps      | 3720192    |\n",
            "| train/                  |            |\n",
            "|    approx_kl            | 0.00407524 |\n",
            "|    clip_fraction        | 0.125      |\n",
            "|    clip_range           | 0.1        |\n",
            "|    entropy_loss         | -1.71      |\n",
            "|    explained_variance   | 0.0202     |\n",
            "|    learning_rate        | 0.00025    |\n",
            "|    loss                 | -0.0389    |\n",
            "|    n_updates            | 14528      |\n",
            "|    policy_gradient_loss | -0.0118    |\n",
            "|    value_loss           | 6.68e-06   |\n",
            "----------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 591         |\n",
            "|    iterations           | 3634        |\n",
            "|    time_elapsed         | 6294        |\n",
            "|    total_timesteps      | 3721216     |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.005329633 |\n",
            "|    clip_fraction        | 0.156       |\n",
            "|    clip_range           | 0.1         |\n",
            "|    entropy_loss         | -1.72       |\n",
            "|    explained_variance   | 0.0257      |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | -0.0297     |\n",
            "|    n_updates            | 14532       |\n",
            "|    policy_gradient_loss | -0.0128     |\n",
            "|    value_loss           | 5.78e-06    |\n",
            "-----------------------------------------\n",
            "----------------------------------------\n",
            "| time/                   |            |\n",
            "|    fps                  | 591        |\n",
            "|    iterations           | 3635       |\n",
            "|    time_elapsed         | 6295       |\n",
            "|    total_timesteps      | 3722240    |\n",
            "| train/                  |            |\n",
            "|    approx_kl            | 0.00251583 |\n",
            "|    clip_fraction        | 0.0615     |\n",
            "|    clip_range           | 0.1        |\n",
            "|    entropy_loss         | -1.71      |\n",
            "|    explained_variance   | -2.17      |\n",
            "|    learning_rate        | 0.00025    |\n",
            "|    loss                 | -0.043     |\n",
            "|    n_updates            | 14536      |\n",
            "|    policy_gradient_loss | -0.0118    |\n",
            "|    value_loss           | 1.28e-05   |\n",
            "----------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 591         |\n",
            "|    iterations           | 3636        |\n",
            "|    time_elapsed         | 6298        |\n",
            "|    total_timesteps      | 3723264     |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.003879455 |\n",
            "|    clip_fraction        | 0.102       |\n",
            "|    clip_range           | 0.1         |\n",
            "|    entropy_loss         | -1.69       |\n",
            "|    explained_variance   | -0.214      |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | -0.0393     |\n",
            "|    n_updates            | 14540       |\n",
            "|    policy_gradient_loss | -0.00957    |\n",
            "|    value_loss           | 9.75e-06    |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 591         |\n",
            "|    iterations           | 3637        |\n",
            "|    time_elapsed         | 6299        |\n",
            "|    total_timesteps      | 3724288     |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.004752664 |\n",
            "|    clip_fraction        | 0.122       |\n",
            "|    clip_range           | 0.1         |\n",
            "|    entropy_loss         | -1.65       |\n",
            "|    explained_variance   | -7.4        |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | -0.0417     |\n",
            "|    n_updates            | 14544       |\n",
            "|    policy_gradient_loss | -0.0141     |\n",
            "|    value_loss           | 1.62e-05    |\n",
            "-----------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 591          |\n",
            "|    iterations           | 3638         |\n",
            "|    time_elapsed         | 6301         |\n",
            "|    total_timesteps      | 3725312      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0034300694 |\n",
            "|    clip_fraction        | 0.0898       |\n",
            "|    clip_range           | 0.1          |\n",
            "|    entropy_loss         | -1.63        |\n",
            "|    explained_variance   | -2.77        |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | -0.0412      |\n",
            "|    n_updates            | 14548        |\n",
            "|    policy_gradient_loss | -0.0153      |\n",
            "|    value_loss           | 2.24e-05     |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 591          |\n",
            "|    iterations           | 3639         |\n",
            "|    time_elapsed         | 6303         |\n",
            "|    total_timesteps      | 3726336      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0043338197 |\n",
            "|    clip_fraction        | 0.122        |\n",
            "|    clip_range           | 0.1          |\n",
            "|    entropy_loss         | -1.65        |\n",
            "|    explained_variance   | -1.87        |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | -0.045       |\n",
            "|    n_updates            | 14552        |\n",
            "|    policy_gradient_loss | -0.0133      |\n",
            "|    value_loss           | 1.17e-05     |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 591          |\n",
            "|    iterations           | 3640         |\n",
            "|    time_elapsed         | 6304         |\n",
            "|    total_timesteps      | 3727360      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0013662623 |\n",
            "|    clip_fraction        | 0.0649       |\n",
            "|    clip_range           | 0.1          |\n",
            "|    entropy_loss         | -1.68        |\n",
            "|    explained_variance   | -0.000122    |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | -0.00952     |\n",
            "|    n_updates            | 14556        |\n",
            "|    policy_gradient_loss | -0.00158     |\n",
            "|    value_loss           | 0.0169       |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 591          |\n",
            "|    iterations           | 3641         |\n",
            "|    time_elapsed         | 6306         |\n",
            "|    total_timesteps      | 3728384      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0038477068 |\n",
            "|    clip_fraction        | 0.152        |\n",
            "|    clip_range           | 0.1          |\n",
            "|    entropy_loss         | -1.56        |\n",
            "|    explained_variance   | -9           |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | -0.0369      |\n",
            "|    n_updates            | 14560        |\n",
            "|    policy_gradient_loss | -0.0157      |\n",
            "|    value_loss           | 1.99e-05     |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 591          |\n",
            "|    iterations           | 3642         |\n",
            "|    time_elapsed         | 6307         |\n",
            "|    total_timesteps      | 3729408      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0032923755 |\n",
            "|    clip_fraction        | 0.137        |\n",
            "|    clip_range           | 0.1          |\n",
            "|    entropy_loss         | -1.67        |\n",
            "|    explained_variance   | -4.69        |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | -0.0459      |\n",
            "|    n_updates            | 14564        |\n",
            "|    policy_gradient_loss | -0.0125      |\n",
            "|    value_loss           | 1.51e-05     |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 591          |\n",
            "|    iterations           | 3643         |\n",
            "|    time_elapsed         | 6309         |\n",
            "|    total_timesteps      | 3730432      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0042750156 |\n",
            "|    clip_fraction        | 0.132        |\n",
            "|    clip_range           | 0.1          |\n",
            "|    entropy_loss         | -1.66        |\n",
            "|    explained_variance   | -22          |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | -0.0434      |\n",
            "|    n_updates            | 14568        |\n",
            "|    policy_gradient_loss | -0.0127      |\n",
            "|    value_loss           | 7.54e-06     |\n",
            "------------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 591         |\n",
            "|    iterations           | 3644        |\n",
            "|    time_elapsed         | 6312        |\n",
            "|    total_timesteps      | 3731456     |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.004222627 |\n",
            "|    clip_fraction        | 0.109       |\n",
            "|    clip_range           | 0.1         |\n",
            "|    entropy_loss         | -1.66       |\n",
            "|    explained_variance   | -10.4       |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | -0.0411     |\n",
            "|    n_updates            | 14572       |\n",
            "|    policy_gradient_loss | -0.0076     |\n",
            "|    value_loss           | 5.56e-06    |\n",
            "-----------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 591          |\n",
            "|    iterations           | 3645         |\n",
            "|    time_elapsed         | 6313         |\n",
            "|    total_timesteps      | 3732480      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0026938242 |\n",
            "|    clip_fraction        | 0.115        |\n",
            "|    clip_range           | 0.1          |\n",
            "|    entropy_loss         | -1.7         |\n",
            "|    explained_variance   | -7.9         |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | -0.0329      |\n",
            "|    n_updates            | 14576        |\n",
            "|    policy_gradient_loss | -0.00963     |\n",
            "|    value_loss           | 2.24e-06     |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 591          |\n",
            "|    iterations           | 3646         |\n",
            "|    time_elapsed         | 6315         |\n",
            "|    total_timesteps      | 3733504      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0036510227 |\n",
            "|    clip_fraction        | 0.0964       |\n",
            "|    clip_range           | 0.1          |\n",
            "|    entropy_loss         | -1.69        |\n",
            "|    explained_variance   | -4.36        |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | -0.0331      |\n",
            "|    n_updates            | 14580        |\n",
            "|    policy_gradient_loss | -0.00784     |\n",
            "|    value_loss           | 1.98e-06     |\n",
            "------------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 591         |\n",
            "|    iterations           | 3647        |\n",
            "|    time_elapsed         | 6316        |\n",
            "|    total_timesteps      | 3734528     |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.002995336 |\n",
            "|    clip_fraction        | 0.13        |\n",
            "|    clip_range           | 0.1         |\n",
            "|    entropy_loss         | -1.68       |\n",
            "|    explained_variance   | -7.58       |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | -0.0315     |\n",
            "|    n_updates            | 14584       |\n",
            "|    policy_gradient_loss | -0.00801    |\n",
            "|    value_loss           | 1.41e-06    |\n",
            "-----------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 591          |\n",
            "|    iterations           | 3648         |\n",
            "|    time_elapsed         | 6318         |\n",
            "|    total_timesteps      | 3735552      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0021192562 |\n",
            "|    clip_fraction        | 0.0603       |\n",
            "|    clip_range           | 0.1          |\n",
            "|    entropy_loss         | -1.65        |\n",
            "|    explained_variance   | -14.5        |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | -0.0327      |\n",
            "|    n_updates            | 14588        |\n",
            "|    policy_gradient_loss | -0.00803     |\n",
            "|    value_loss           | 4.68e-06     |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 591          |\n",
            "|    iterations           | 3649         |\n",
            "|    time_elapsed         | 6320         |\n",
            "|    total_timesteps      | 3736576      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0036245068 |\n",
            "|    clip_fraction        | 0.114        |\n",
            "|    clip_range           | 0.1          |\n",
            "|    entropy_loss         | -1.68        |\n",
            "|    explained_variance   | -13.9        |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | -0.0393      |\n",
            "|    n_updates            | 14592        |\n",
            "|    policy_gradient_loss | -0.0104      |\n",
            "|    value_loss           | 2.46e-06     |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 591          |\n",
            "|    iterations           | 3650         |\n",
            "|    time_elapsed         | 6321         |\n",
            "|    total_timesteps      | 3737600      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0038721703 |\n",
            "|    clip_fraction        | 0.132        |\n",
            "|    clip_range           | 0.1          |\n",
            "|    entropy_loss         | -1.72        |\n",
            "|    explained_variance   | -4.33        |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | -0.031       |\n",
            "|    n_updates            | 14596        |\n",
            "|    policy_gradient_loss | -0.0081      |\n",
            "|    value_loss           | 1.88e-06     |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 591          |\n",
            "|    iterations           | 3651         |\n",
            "|    time_elapsed         | 6323         |\n",
            "|    total_timesteps      | 3738624      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0028790287 |\n",
            "|    clip_fraction        | 0.0884       |\n",
            "|    clip_range           | 0.1          |\n",
            "|    entropy_loss         | -1.69        |\n",
            "|    explained_variance   | -5.66        |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | -0.0406      |\n",
            "|    n_updates            | 14600        |\n",
            "|    policy_gradient_loss | -0.00777     |\n",
            "|    value_loss           | 3.12e-06     |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 591          |\n",
            "|    iterations           | 3652         |\n",
            "|    time_elapsed         | 6325         |\n",
            "|    total_timesteps      | 3739648      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0034437398 |\n",
            "|    clip_fraction        | 0.0745       |\n",
            "|    clip_range           | 0.1          |\n",
            "|    entropy_loss         | -1.7         |\n",
            "|    explained_variance   | -5.67        |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | -0.033       |\n",
            "|    n_updates            | 14604        |\n",
            "|    policy_gradient_loss | -0.00742     |\n",
            "|    value_loss           | 2.37e-06     |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 591          |\n",
            "|    iterations           | 3653         |\n",
            "|    time_elapsed         | 6327         |\n",
            "|    total_timesteps      | 3740672      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0031259824 |\n",
            "|    clip_fraction        | 0.0796       |\n",
            "|    clip_range           | 0.1          |\n",
            "|    entropy_loss         | -1.66        |\n",
            "|    explained_variance   | -3.61        |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | -0.0406      |\n",
            "|    n_updates            | 14608        |\n",
            "|    policy_gradient_loss | -0.00845     |\n",
            "|    value_loss           | 3.02e-06     |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 591          |\n",
            "|    iterations           | 3654         |\n",
            "|    time_elapsed         | 6328         |\n",
            "|    total_timesteps      | 3741696      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0025226916 |\n",
            "|    clip_fraction        | 0.151        |\n",
            "|    clip_range           | 0.1          |\n",
            "|    entropy_loss         | -1.66        |\n",
            "|    explained_variance   | -2.63        |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | -0.0361      |\n",
            "|    n_updates            | 14612        |\n",
            "|    policy_gradient_loss | -0.00894     |\n",
            "|    value_loss           | 2.4e-06      |\n",
            "------------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 591         |\n",
            "|    iterations           | 3655        |\n",
            "|    time_elapsed         | 6330        |\n",
            "|    total_timesteps      | 3742720     |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.002564635 |\n",
            "|    clip_fraction        | 0.0613      |\n",
            "|    clip_range           | 0.1         |\n",
            "|    entropy_loss         | -1.65       |\n",
            "|    explained_variance   | -16.5       |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | -0.0329     |\n",
            "|    n_updates            | 14616       |\n",
            "|    policy_gradient_loss | -0.00968    |\n",
            "|    value_loss           | 2.96e-06    |\n",
            "-----------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 591          |\n",
            "|    iterations           | 3656         |\n",
            "|    time_elapsed         | 6332         |\n",
            "|    total_timesteps      | 3743744      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0036355618 |\n",
            "|    clip_fraction        | 0.127        |\n",
            "|    clip_range           | 0.1          |\n",
            "|    entropy_loss         | -1.66        |\n",
            "|    explained_variance   | -1.86        |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | -0.0321      |\n",
            "|    n_updates            | 14620        |\n",
            "|    policy_gradient_loss | -0.00821     |\n",
            "|    value_loss           | 2.38e-06     |\n",
            "------------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 591         |\n",
            "|    iterations           | 3657        |\n",
            "|    time_elapsed         | 6333        |\n",
            "|    total_timesteps      | 3744768     |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.002272547 |\n",
            "|    clip_fraction        | 0.131       |\n",
            "|    clip_range           | 0.1         |\n",
            "|    entropy_loss         | -1.66       |\n",
            "|    explained_variance   | -7.44       |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | -0.039      |\n",
            "|    n_updates            | 14624       |\n",
            "|    policy_gradient_loss | -0.00915    |\n",
            "|    value_loss           | 1.82e-06    |\n",
            "-----------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 591          |\n",
            "|    iterations           | 3658         |\n",
            "|    time_elapsed         | 6335         |\n",
            "|    total_timesteps      | 3745792      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0022767917 |\n",
            "|    clip_fraction        | 0.0803       |\n",
            "|    clip_range           | 0.1          |\n",
            "|    entropy_loss         | -1.64        |\n",
            "|    explained_variance   | -9.57        |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | -0.0364      |\n",
            "|    n_updates            | 14628        |\n",
            "|    policy_gradient_loss | -0.00927     |\n",
            "|    value_loss           | 2.67e-06     |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 591          |\n",
            "|    iterations           | 3659         |\n",
            "|    time_elapsed         | 6337         |\n",
            "|    total_timesteps      | 3746816      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0032051555 |\n",
            "|    clip_fraction        | 0.128        |\n",
            "|    clip_range           | 0.1          |\n",
            "|    entropy_loss         | -1.67        |\n",
            "|    explained_variance   | -3.68        |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | -0.033       |\n",
            "|    n_updates            | 14632        |\n",
            "|    policy_gradient_loss | -0.00914     |\n",
            "|    value_loss           | 2.47e-06     |\n",
            "------------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 591         |\n",
            "|    iterations           | 3660        |\n",
            "|    time_elapsed         | 6339        |\n",
            "|    total_timesteps      | 3747840     |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.002393554 |\n",
            "|    clip_fraction        | 0.102       |\n",
            "|    clip_range           | 0.1         |\n",
            "|    entropy_loss         | -1.68       |\n",
            "|    explained_variance   | -10.4       |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | -0.0353     |\n",
            "|    n_updates            | 14636       |\n",
            "|    policy_gradient_loss | -0.00926    |\n",
            "|    value_loss           | 1.94e-06    |\n",
            "-----------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 591          |\n",
            "|    iterations           | 3661         |\n",
            "|    time_elapsed         | 6341         |\n",
            "|    total_timesteps      | 3748864      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0034583476 |\n",
            "|    clip_fraction        | 0.138        |\n",
            "|    clip_range           | 0.1          |\n",
            "|    entropy_loss         | -1.66        |\n",
            "|    explained_variance   | -3.45        |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | -0.0345      |\n",
            "|    n_updates            | 14640        |\n",
            "|    policy_gradient_loss | -0.0115      |\n",
            "|    value_loss           | 3.18e-06     |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 591          |\n",
            "|    iterations           | 3662         |\n",
            "|    time_elapsed         | 6342         |\n",
            "|    total_timesteps      | 3749888      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0034884394 |\n",
            "|    clip_fraction        | 0.154        |\n",
            "|    clip_range           | 0.1          |\n",
            "|    entropy_loss         | -1.63        |\n",
            "|    explained_variance   | -3.12        |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | -0.0378      |\n",
            "|    n_updates            | 14644        |\n",
            "|    policy_gradient_loss | -0.00857     |\n",
            "|    value_loss           | 4.19e-06     |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 591          |\n",
            "|    iterations           | 3663         |\n",
            "|    time_elapsed         | 6344         |\n",
            "|    total_timesteps      | 3750912      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0033049788 |\n",
            "|    clip_fraction        | 0.117        |\n",
            "|    clip_range           | 0.1          |\n",
            "|    entropy_loss         | -1.68        |\n",
            "|    explained_variance   | -0.0021      |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | -0.0235      |\n",
            "|    n_updates            | 14648        |\n",
            "|    policy_gradient_loss | -0.00509     |\n",
            "|    value_loss           | 0.00635      |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 591          |\n",
            "|    iterations           | 3664         |\n",
            "|    time_elapsed         | 6346         |\n",
            "|    total_timesteps      | 3751936      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0041155275 |\n",
            "|    clip_fraction        | 0.13         |\n",
            "|    clip_range           | 0.1          |\n",
            "|    entropy_loss         | -1.69        |\n",
            "|    explained_variance   | 0.422        |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | -0.0386      |\n",
            "|    n_updates            | 14652        |\n",
            "|    policy_gradient_loss | -0.0106      |\n",
            "|    value_loss           | 3.3e-05      |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 591          |\n",
            "|    iterations           | 3665         |\n",
            "|    time_elapsed         | 6347         |\n",
            "|    total_timesteps      | 3752960      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0016842631 |\n",
            "|    clip_fraction        | 0.0298       |\n",
            "|    clip_range           | 0.1          |\n",
            "|    entropy_loss         | -1.71        |\n",
            "|    explained_variance   | 0.0415       |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | -0.0249      |\n",
            "|    n_updates            | 14656        |\n",
            "|    policy_gradient_loss | -0.00428     |\n",
            "|    value_loss           | 0.00785      |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 591          |\n",
            "|    iterations           | 3666         |\n",
            "|    time_elapsed         | 6349         |\n",
            "|    total_timesteps      | 3753984      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0032050773 |\n",
            "|    clip_fraction        | 0.0935       |\n",
            "|    clip_range           | 0.1          |\n",
            "|    entropy_loss         | -1.67        |\n",
            "|    explained_variance   | -2.39        |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | -0.021       |\n",
            "|    n_updates            | 14660        |\n",
            "|    policy_gradient_loss | -0.00689     |\n",
            "|    value_loss           | 0.00014      |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 591          |\n",
            "|    iterations           | 3667         |\n",
            "|    time_elapsed         | 6351         |\n",
            "|    total_timesteps      | 3755008      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0029643222 |\n",
            "|    clip_fraction        | 0.082        |\n",
            "|    clip_range           | 0.1          |\n",
            "|    entropy_loss         | -1.73        |\n",
            "|    explained_variance   | 0.101        |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | -0.0285      |\n",
            "|    n_updates            | 14664        |\n",
            "|    policy_gradient_loss | -0.00849     |\n",
            "|    value_loss           | 3.76e-05     |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 591          |\n",
            "|    iterations           | 3668         |\n",
            "|    time_elapsed         | 6353         |\n",
            "|    total_timesteps      | 3756032      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0022626203 |\n",
            "|    clip_fraction        | 0.0898       |\n",
            "|    clip_range           | 0.1          |\n",
            "|    entropy_loss         | -1.72        |\n",
            "|    explained_variance   | -0.147       |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | -0.0375      |\n",
            "|    n_updates            | 14668        |\n",
            "|    policy_gradient_loss | -0.00978     |\n",
            "|    value_loss           | 3.35e-05     |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 591          |\n",
            "|    iterations           | 3669         |\n",
            "|    time_elapsed         | 6355         |\n",
            "|    total_timesteps      | 3757056      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0028756564 |\n",
            "|    clip_fraction        | 0.0789       |\n",
            "|    clip_range           | 0.1          |\n",
            "|    entropy_loss         | -1.73        |\n",
            "|    explained_variance   | 0.233        |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | -0.0409      |\n",
            "|    n_updates            | 14672        |\n",
            "|    policy_gradient_loss | -0.00925     |\n",
            "|    value_loss           | 2.36e-05     |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 591          |\n",
            "|    iterations           | 3670         |\n",
            "|    time_elapsed         | 6356         |\n",
            "|    total_timesteps      | 3758080      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0024154393 |\n",
            "|    clip_fraction        | 0.0688       |\n",
            "|    clip_range           | 0.1          |\n",
            "|    entropy_loss         | -1.68        |\n",
            "|    explained_variance   | -0.00454     |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | -0.019       |\n",
            "|    n_updates            | 14676        |\n",
            "|    policy_gradient_loss | -0.00474     |\n",
            "|    value_loss           | 0.00801      |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 591          |\n",
            "|    iterations           | 3671         |\n",
            "|    time_elapsed         | 6358         |\n",
            "|    total_timesteps      | 3759104      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0029852414 |\n",
            "|    clip_fraction        | 0.0784       |\n",
            "|    clip_range           | 0.1          |\n",
            "|    entropy_loss         | -1.72        |\n",
            "|    explained_variance   | 0.537        |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | -0.0409      |\n",
            "|    n_updates            | 14680        |\n",
            "|    policy_gradient_loss | -0.0102      |\n",
            "|    value_loss           | 5.97e-05     |\n",
            "------------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 591         |\n",
            "|    iterations           | 3672        |\n",
            "|    time_elapsed         | 6359        |\n",
            "|    total_timesteps      | 3760128     |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.004555689 |\n",
            "|    clip_fraction        | 0.206       |\n",
            "|    clip_range           | 0.1         |\n",
            "|    entropy_loss         | -1.72       |\n",
            "|    explained_variance   | 0.473       |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | -0.045      |\n",
            "|    n_updates            | 14684       |\n",
            "|    policy_gradient_loss | -0.0119     |\n",
            "|    value_loss           | 6.16e-05    |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 591         |\n",
            "|    iterations           | 3673        |\n",
            "|    time_elapsed         | 6361        |\n",
            "|    total_timesteps      | 3761152     |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.003067829 |\n",
            "|    clip_fraction        | 0.084       |\n",
            "|    clip_range           | 0.1         |\n",
            "|    entropy_loss         | -1.73       |\n",
            "|    explained_variance   | 0.677       |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | -0.036      |\n",
            "|    n_updates            | 14688       |\n",
            "|    policy_gradient_loss | -0.00967    |\n",
            "|    value_loss           | 2.79e-05    |\n",
            "-----------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 591          |\n",
            "|    iterations           | 3674         |\n",
            "|    time_elapsed         | 6363         |\n",
            "|    total_timesteps      | 3762176      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0013966769 |\n",
            "|    clip_fraction        | 0.0256       |\n",
            "|    clip_range           | 0.1          |\n",
            "|    entropy_loss         | -1.72        |\n",
            "|    explained_variance   | 0.565        |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | -0.0299      |\n",
            "|    n_updates            | 14692        |\n",
            "|    policy_gradient_loss | -0.00665     |\n",
            "|    value_loss           | 2.76e-05     |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 591          |\n",
            "|    iterations           | 3675         |\n",
            "|    time_elapsed         | 6365         |\n",
            "|    total_timesteps      | 3763200      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0038530377 |\n",
            "|    clip_fraction        | 0.104        |\n",
            "|    clip_range           | 0.1          |\n",
            "|    entropy_loss         | -1.73        |\n",
            "|    explained_variance   | 0.694        |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | -0.0303      |\n",
            "|    n_updates            | 14696        |\n",
            "|    policy_gradient_loss | -0.0094      |\n",
            "|    value_loss           | 1.6e-05      |\n",
            "------------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 591         |\n",
            "|    iterations           | 3676        |\n",
            "|    time_elapsed         | 6367        |\n",
            "|    total_timesteps      | 3764224     |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.002537118 |\n",
            "|    clip_fraction        | 0.0427      |\n",
            "|    clip_range           | 0.1         |\n",
            "|    entropy_loss         | -1.7        |\n",
            "|    explained_variance   | 0.646       |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | -0.0387     |\n",
            "|    n_updates            | 14700       |\n",
            "|    policy_gradient_loss | -0.00933    |\n",
            "|    value_loss           | 1.62e-05    |\n",
            "-----------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 591          |\n",
            "|    iterations           | 3677         |\n",
            "|    time_elapsed         | 6368         |\n",
            "|    total_timesteps      | 3765248      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0019014702 |\n",
            "|    clip_fraction        | 0.0459       |\n",
            "|    clip_range           | 0.1          |\n",
            "|    entropy_loss         | -1.7         |\n",
            "|    explained_variance   | 0.567        |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | -0.0364      |\n",
            "|    n_updates            | 14704        |\n",
            "|    policy_gradient_loss | -0.0106      |\n",
            "|    value_loss           | 1.84e-05     |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 591          |\n",
            "|    iterations           | 3678         |\n",
            "|    time_elapsed         | 6370         |\n",
            "|    total_timesteps      | 3766272      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0017272562 |\n",
            "|    clip_fraction        | 0.0542       |\n",
            "|    clip_range           | 0.1          |\n",
            "|    entropy_loss         | -1.73        |\n",
            "|    explained_variance   | 0.658        |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | -0.0373      |\n",
            "|    n_updates            | 14708        |\n",
            "|    policy_gradient_loss | -0.00984     |\n",
            "|    value_loss           | 1.16e-05     |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 591          |\n",
            "|    iterations           | 3679         |\n",
            "|    time_elapsed         | 6371         |\n",
            "|    total_timesteps      | 3767296      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0024606453 |\n",
            "|    clip_fraction        | 0.0322       |\n",
            "|    clip_range           | 0.1          |\n",
            "|    entropy_loss         | -1.7         |\n",
            "|    explained_variance   | 0.0195       |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | -0.0196      |\n",
            "|    n_updates            | 14712        |\n",
            "|    policy_gradient_loss | -0.00154     |\n",
            "|    value_loss           | 0.00476      |\n",
            "------------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 591         |\n",
            "|    iterations           | 3680        |\n",
            "|    time_elapsed         | 6373        |\n",
            "|    total_timesteps      | 3768320     |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.001981824 |\n",
            "|    clip_fraction        | 0.0754      |\n",
            "|    clip_range           | 0.1         |\n",
            "|    entropy_loss         | -1.67       |\n",
            "|    explained_variance   | 5.1e-05     |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | -0.0196     |\n",
            "|    n_updates            | 14716       |\n",
            "|    policy_gradient_loss | -0.00584    |\n",
            "|    value_loss           | 0.017       |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 591         |\n",
            "|    iterations           | 3681        |\n",
            "|    time_elapsed         | 6374        |\n",
            "|    total_timesteps      | 3769344     |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.005217725 |\n",
            "|    clip_fraction        | 0.125       |\n",
            "|    clip_range           | 0.1         |\n",
            "|    entropy_loss         | -1.6        |\n",
            "|    explained_variance   | -0.897      |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | -0.043      |\n",
            "|    n_updates            | 14720       |\n",
            "|    policy_gradient_loss | -0.0166     |\n",
            "|    value_loss           | 4.26e-05    |\n",
            "-----------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 591          |\n",
            "|    iterations           | 3682         |\n",
            "|    time_elapsed         | 6377         |\n",
            "|    total_timesteps      | 3770368      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0027747515 |\n",
            "|    clip_fraction        | 0.0823       |\n",
            "|    clip_range           | 0.1          |\n",
            "|    entropy_loss         | -1.62        |\n",
            "|    explained_variance   | -1.44        |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | -0.038       |\n",
            "|    n_updates            | 14724        |\n",
            "|    policy_gradient_loss | -0.0102      |\n",
            "|    value_loss           | 2.47e-05     |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 591          |\n",
            "|    iterations           | 3683         |\n",
            "|    time_elapsed         | 6379         |\n",
            "|    total_timesteps      | 3771392      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0026800523 |\n",
            "|    clip_fraction        | 0.0674       |\n",
            "|    clip_range           | 0.1          |\n",
            "|    entropy_loss         | -1.66        |\n",
            "|    explained_variance   | 0.283        |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | -0.0443      |\n",
            "|    n_updates            | 14728        |\n",
            "|    policy_gradient_loss | -0.011       |\n",
            "|    value_loss           | 1.13e-05     |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 591          |\n",
            "|    iterations           | 3684         |\n",
            "|    time_elapsed         | 6380         |\n",
            "|    total_timesteps      | 3772416      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0028254718 |\n",
            "|    clip_fraction        | 0.0969       |\n",
            "|    clip_range           | 0.1          |\n",
            "|    entropy_loss         | -1.67        |\n",
            "|    explained_variance   | -1.15        |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | -0.0445      |\n",
            "|    n_updates            | 14732        |\n",
            "|    policy_gradient_loss | -0.0134      |\n",
            "|    value_loss           | 2.31e-05     |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 591          |\n",
            "|    iterations           | 3685         |\n",
            "|    time_elapsed         | 6382         |\n",
            "|    total_timesteps      | 3773440      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0036416063 |\n",
            "|    clip_fraction        | 0.0852       |\n",
            "|    clip_range           | 0.1          |\n",
            "|    entropy_loss         | -1.67        |\n",
            "|    explained_variance   | -1.45        |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | -0.0403      |\n",
            "|    n_updates            | 14736        |\n",
            "|    policy_gradient_loss | -0.0148      |\n",
            "|    value_loss           | 1.44e-05     |\n",
            "------------------------------------------\n",
            "----------------------------------------\n",
            "| time/                   |            |\n",
            "|    fps                  | 591        |\n",
            "|    iterations           | 3686       |\n",
            "|    time_elapsed         | 6383       |\n",
            "|    total_timesteps      | 3774464    |\n",
            "| train/                  |            |\n",
            "|    approx_kl            | 0.00382066 |\n",
            "|    clip_fraction        | 0.111      |\n",
            "|    clip_range           | 0.1        |\n",
            "|    entropy_loss         | -1.63      |\n",
            "|    explained_variance   | -2.52      |\n",
            "|    learning_rate        | 0.00025    |\n",
            "|    loss                 | -0.0434    |\n",
            "|    n_updates            | 14740      |\n",
            "|    policy_gradient_loss | -0.0166    |\n",
            "|    value_loss           | 1.93e-05   |\n",
            "----------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 591         |\n",
            "|    iterations           | 3687        |\n",
            "|    time_elapsed         | 6385        |\n",
            "|    total_timesteps      | 3775488     |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.003915878 |\n",
            "|    clip_fraction        | 0.146       |\n",
            "|    clip_range           | 0.1         |\n",
            "|    entropy_loss         | -1.6        |\n",
            "|    explained_variance   | -2.61       |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | -0.0417     |\n",
            "|    n_updates            | 14744       |\n",
            "|    policy_gradient_loss | -0.0129     |\n",
            "|    value_loss           | 1.24e-05    |\n",
            "-----------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 591          |\n",
            "|    iterations           | 3688         |\n",
            "|    time_elapsed         | 6386         |\n",
            "|    total_timesteps      | 3776512      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0032900716 |\n",
            "|    clip_fraction        | 0.084        |\n",
            "|    clip_range           | 0.1          |\n",
            "|    entropy_loss         | -1.65        |\n",
            "|    explained_variance   | -1.76        |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | -0.0463      |\n",
            "|    n_updates            | 14748        |\n",
            "|    policy_gradient_loss | -0.0152      |\n",
            "|    value_loss           | 1.41e-05     |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 591          |\n",
            "|    iterations           | 3689         |\n",
            "|    time_elapsed         | 6388         |\n",
            "|    total_timesteps      | 3777536      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0039001158 |\n",
            "|    clip_fraction        | 0.112        |\n",
            "|    clip_range           | 0.1          |\n",
            "|    entropy_loss         | -1.57        |\n",
            "|    explained_variance   | -3.06        |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | -0.0453      |\n",
            "|    n_updates            | 14752        |\n",
            "|    policy_gradient_loss | -0.0164      |\n",
            "|    value_loss           | 2.27e-05     |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 591          |\n",
            "|    iterations           | 3690         |\n",
            "|    time_elapsed         | 6391         |\n",
            "|    total_timesteps      | 3778560      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0030641167 |\n",
            "|    clip_fraction        | 0.0994       |\n",
            "|    clip_range           | 0.1          |\n",
            "|    entropy_loss         | -1.63        |\n",
            "|    explained_variance   | -1.67        |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | -0.0465      |\n",
            "|    n_updates            | 14756        |\n",
            "|    policy_gradient_loss | -0.0144      |\n",
            "|    value_loss           | 1.1e-05      |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 591          |\n",
            "|    iterations           | 3691         |\n",
            "|    time_elapsed         | 6392         |\n",
            "|    total_timesteps      | 3779584      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0035326136 |\n",
            "|    clip_fraction        | 0.0869       |\n",
            "|    clip_range           | 0.1          |\n",
            "|    entropy_loss         | -1.63        |\n",
            "|    explained_variance   | -0.949       |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | -0.0449      |\n",
            "|    n_updates            | 14760        |\n",
            "|    policy_gradient_loss | -0.0118      |\n",
            "|    value_loss           | 1.05e-05     |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 591          |\n",
            "|    iterations           | 3692         |\n",
            "|    time_elapsed         | 6394         |\n",
            "|    total_timesteps      | 3780608      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0044664564 |\n",
            "|    clip_fraction        | 0.107        |\n",
            "|    clip_range           | 0.1          |\n",
            "|    entropy_loss         | -1.64        |\n",
            "|    explained_variance   | -2.5         |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | -0.0393      |\n",
            "|    n_updates            | 14764        |\n",
            "|    policy_gradient_loss | -0.0133      |\n",
            "|    value_loss           | 7.92e-06     |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 591          |\n",
            "|    iterations           | 3693         |\n",
            "|    time_elapsed         | 6395         |\n",
            "|    total_timesteps      | 3781632      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0035963913 |\n",
            "|    clip_fraction        | 0.122        |\n",
            "|    clip_range           | 0.1          |\n",
            "|    entropy_loss         | -1.66        |\n",
            "|    explained_variance   | -0.452       |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | -0.0394      |\n",
            "|    n_updates            | 14768        |\n",
            "|    policy_gradient_loss | -0.0122      |\n",
            "|    value_loss           | 4.87e-06     |\n",
            "------------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 591         |\n",
            "|    iterations           | 3694        |\n",
            "|    time_elapsed         | 6397        |\n",
            "|    total_timesteps      | 3782656     |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.003268447 |\n",
            "|    clip_fraction        | 0.108       |\n",
            "|    clip_range           | 0.1         |\n",
            "|    entropy_loss         | -1.66       |\n",
            "|    explained_variance   | -0.67       |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | -0.039      |\n",
            "|    n_updates            | 14772       |\n",
            "|    policy_gradient_loss | -0.0128     |\n",
            "|    value_loss           | 4.85e-06    |\n",
            "-----------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 591          |\n",
            "|    iterations           | 3695         |\n",
            "|    time_elapsed         | 6398         |\n",
            "|    total_timesteps      | 3783680      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0032764059 |\n",
            "|    clip_fraction        | 0.0754       |\n",
            "|    clip_range           | 0.1          |\n",
            "|    entropy_loss         | -1.64        |\n",
            "|    explained_variance   | -0.00716     |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | -0.023       |\n",
            "|    n_updates            | 14776        |\n",
            "|    policy_gradient_loss | -0.00779     |\n",
            "|    value_loss           | 0.00808      |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 591          |\n",
            "|    iterations           | 3696         |\n",
            "|    time_elapsed         | 6400         |\n",
            "|    total_timesteps      | 3784704      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0037332273 |\n",
            "|    clip_fraction        | 0.0896       |\n",
            "|    clip_range           | 0.1          |\n",
            "|    entropy_loss         | -1.69        |\n",
            "|    explained_variance   | -0.704       |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | -0.0328      |\n",
            "|    n_updates            | 14780        |\n",
            "|    policy_gradient_loss | -0.0128      |\n",
            "|    value_loss           | 0.000171     |\n",
            "------------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 591         |\n",
            "|    iterations           | 3697        |\n",
            "|    time_elapsed         | 6402        |\n",
            "|    total_timesteps      | 3785728     |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.004925601 |\n",
            "|    clip_fraction        | 0.123       |\n",
            "|    clip_range           | 0.1         |\n",
            "|    entropy_loss         | -1.63       |\n",
            "|    explained_variance   | -0.216      |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | -0.0515     |\n",
            "|    n_updates            | 14784       |\n",
            "|    policy_gradient_loss | -0.0129     |\n",
            "|    value_loss           | 9.11e-05    |\n",
            "-----------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 591          |\n",
            "|    iterations           | 3698         |\n",
            "|    time_elapsed         | 6404         |\n",
            "|    total_timesteps      | 3786752      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0038130525 |\n",
            "|    clip_fraction        | 0.138        |\n",
            "|    clip_range           | 0.1          |\n",
            "|    entropy_loss         | -1.64        |\n",
            "|    explained_variance   | 0.366        |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | -0.0447      |\n",
            "|    n_updates            | 14788        |\n",
            "|    policy_gradient_loss | -0.0145      |\n",
            "|    value_loss           | 3.46e-05     |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 591          |\n",
            "|    iterations           | 3699         |\n",
            "|    time_elapsed         | 6406         |\n",
            "|    total_timesteps      | 3787776      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0035749879 |\n",
            "|    clip_fraction        | 0.107        |\n",
            "|    clip_range           | 0.1          |\n",
            "|    entropy_loss         | -1.64        |\n",
            "|    explained_variance   | 0.214        |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | -0.0429      |\n",
            "|    n_updates            | 14792        |\n",
            "|    policy_gradient_loss | -0.0141      |\n",
            "|    value_loss           | 3.2e-05      |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 591          |\n",
            "|    iterations           | 3700         |\n",
            "|    time_elapsed         | 6407         |\n",
            "|    total_timesteps      | 3788800      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0038328604 |\n",
            "|    clip_fraction        | 0.102        |\n",
            "|    clip_range           | 0.1          |\n",
            "|    entropy_loss         | -1.67        |\n",
            "|    explained_variance   | 0.333        |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | -0.0471      |\n",
            "|    n_updates            | 14796        |\n",
            "|    policy_gradient_loss | -0.0157      |\n",
            "|    value_loss           | 1.79e-05     |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 591          |\n",
            "|    iterations           | 3701         |\n",
            "|    time_elapsed         | 6409         |\n",
            "|    total_timesteps      | 3789824      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0024075597 |\n",
            "|    clip_fraction        | 0.0352       |\n",
            "|    clip_range           | 0.1          |\n",
            "|    entropy_loss         | -1.61        |\n",
            "|    explained_variance   | -0.000409    |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | -0.015       |\n",
            "|    n_updates            | 14800        |\n",
            "|    policy_gradient_loss | -0.00651     |\n",
            "|    value_loss           | 0.016        |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 591          |\n",
            "|    iterations           | 3702         |\n",
            "|    time_elapsed         | 6411         |\n",
            "|    total_timesteps      | 3790848      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0034060264 |\n",
            "|    clip_fraction        | 0.134        |\n",
            "|    clip_range           | 0.1          |\n",
            "|    entropy_loss         | -1.63        |\n",
            "|    explained_variance   | -0.384       |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | -0.0432      |\n",
            "|    n_updates            | 14804        |\n",
            "|    policy_gradient_loss | -0.0135      |\n",
            "|    value_loss           | 1.33e-05     |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 591          |\n",
            "|    iterations           | 3703         |\n",
            "|    time_elapsed         | 6412         |\n",
            "|    total_timesteps      | 3791872      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0038006378 |\n",
            "|    clip_fraction        | 0.119        |\n",
            "|    clip_range           | 0.1          |\n",
            "|    entropy_loss         | -1.56        |\n",
            "|    explained_variance   | -2.59        |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | -0.0398      |\n",
            "|    n_updates            | 14808        |\n",
            "|    policy_gradient_loss | -0.013       |\n",
            "|    value_loss           | 1.54e-05     |\n",
            "------------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 591         |\n",
            "|    iterations           | 3704        |\n",
            "|    time_elapsed         | 6414        |\n",
            "|    total_timesteps      | 3792896     |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.004375378 |\n",
            "|    clip_fraction        | 0.122       |\n",
            "|    clip_range           | 0.1         |\n",
            "|    entropy_loss         | -1.59       |\n",
            "|    explained_variance   | -3.76       |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | -0.0417     |\n",
            "|    n_updates            | 14812       |\n",
            "|    policy_gradient_loss | -0.0135     |\n",
            "|    value_loss           | 1.98e-05    |\n",
            "-----------------------------------------\n",
            "----------------------------------------\n",
            "| time/                   |            |\n",
            "|    fps                  | 591        |\n",
            "|    iterations           | 3705       |\n",
            "|    time_elapsed         | 6416       |\n",
            "|    total_timesteps      | 3793920    |\n",
            "| train/                  |            |\n",
            "|    approx_kl            | 0.00337967 |\n",
            "|    clip_fraction        | 0.108      |\n",
            "|    clip_range           | 0.1        |\n",
            "|    entropy_loss         | -1.58      |\n",
            "|    explained_variance   | -1.6       |\n",
            "|    learning_rate        | 0.00025    |\n",
            "|    loss                 | -0.0385    |\n",
            "|    n_updates            | 14816      |\n",
            "|    policy_gradient_loss | -0.0113    |\n",
            "|    value_loss           | 1.22e-05   |\n",
            "----------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 591          |\n",
            "|    iterations           | 3706         |\n",
            "|    time_elapsed         | 6418         |\n",
            "|    total_timesteps      | 3794944      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0038277633 |\n",
            "|    clip_fraction        | 0.129        |\n",
            "|    clip_range           | 0.1          |\n",
            "|    entropy_loss         | -1.52        |\n",
            "|    explained_variance   | -2.27        |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | -0.0394      |\n",
            "|    n_updates            | 14820        |\n",
            "|    policy_gradient_loss | -0.014       |\n",
            "|    value_loss           | 1.33e-05     |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 591          |\n",
            "|    iterations           | 3707         |\n",
            "|    time_elapsed         | 6420         |\n",
            "|    total_timesteps      | 3795968      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0027453615 |\n",
            "|    clip_fraction        | 0.131        |\n",
            "|    clip_range           | 0.1          |\n",
            "|    entropy_loss         | -1.59        |\n",
            "|    explained_variance   | -3.41        |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | -0.0378      |\n",
            "|    n_updates            | 14824        |\n",
            "|    policy_gradient_loss | -0.014       |\n",
            "|    value_loss           | 1.28e-05     |\n",
            "------------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 591         |\n",
            "|    iterations           | 3708        |\n",
            "|    time_elapsed         | 6421        |\n",
            "|    total_timesteps      | 3796992     |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.004946589 |\n",
            "|    clip_fraction        | 0.14        |\n",
            "|    clip_range           | 0.1         |\n",
            "|    entropy_loss         | -1.58       |\n",
            "|    explained_variance   | -1.09       |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | -0.0315     |\n",
            "|    n_updates            | 14828       |\n",
            "|    policy_gradient_loss | -0.0122     |\n",
            "|    value_loss           | 8.72e-06    |\n",
            "-----------------------------------------\n",
            "----------------------------------------\n",
            "| time/                   |            |\n",
            "|    fps                  | 591        |\n",
            "|    iterations           | 3709       |\n",
            "|    time_elapsed         | 6423       |\n",
            "|    total_timesteps      | 3798016    |\n",
            "| train/                  |            |\n",
            "|    approx_kl            | 0.00485449 |\n",
            "|    clip_fraction        | 0.129      |\n",
            "|    clip_range           | 0.1        |\n",
            "|    entropy_loss         | -1.5       |\n",
            "|    explained_variance   | -1.48      |\n",
            "|    learning_rate        | 0.00025    |\n",
            "|    loss                 | -0.0456    |\n",
            "|    n_updates            | 14832      |\n",
            "|    policy_gradient_loss | -0.0142    |\n",
            "|    value_loss           | 1.21e-05   |\n",
            "----------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 591          |\n",
            "|    iterations           | 3710         |\n",
            "|    time_elapsed         | 6424         |\n",
            "|    total_timesteps      | 3799040      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0039430093 |\n",
            "|    clip_fraction        | 0.114        |\n",
            "|    clip_range           | 0.1          |\n",
            "|    entropy_loss         | -1.53        |\n",
            "|    explained_variance   | -1.79        |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | -0.0398      |\n",
            "|    n_updates            | 14836        |\n",
            "|    policy_gradient_loss | -0.0132      |\n",
            "|    value_loss           | 9.03e-06     |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 591          |\n",
            "|    iterations           | 3711         |\n",
            "|    time_elapsed         | 6426         |\n",
            "|    total_timesteps      | 3800064      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0048022103 |\n",
            "|    clip_fraction        | 0.152        |\n",
            "|    clip_range           | 0.1          |\n",
            "|    entropy_loss         | -1.56        |\n",
            "|    explained_variance   | -2.04        |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | -0.0468      |\n",
            "|    n_updates            | 14840        |\n",
            "|    policy_gradient_loss | -0.0153      |\n",
            "|    value_loss           | 9.61e-06     |\n",
            "------------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 591         |\n",
            "|    iterations           | 3712        |\n",
            "|    time_elapsed         | 6428        |\n",
            "|    total_timesteps      | 3801088     |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.003417424 |\n",
            "|    clip_fraction        | 0.156       |\n",
            "|    clip_range           | 0.1         |\n",
            "|    entropy_loss         | -1.51       |\n",
            "|    explained_variance   | -2.61       |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | -0.0407     |\n",
            "|    n_updates            | 14844       |\n",
            "|    policy_gradient_loss | -0.0132     |\n",
            "|    value_loss           | 9.47e-06    |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 591         |\n",
            "|    iterations           | 3713        |\n",
            "|    time_elapsed         | 6430        |\n",
            "|    total_timesteps      | 3802112     |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.004121621 |\n",
            "|    clip_fraction        | 0.115       |\n",
            "|    clip_range           | 0.1         |\n",
            "|    entropy_loss         | -1.6        |\n",
            "|    explained_variance   | -1.91       |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | -0.0389     |\n",
            "|    n_updates            | 14848       |\n",
            "|    policy_gradient_loss | -0.0142     |\n",
            "|    value_loss           | 7.83e-06    |\n",
            "-----------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 591          |\n",
            "|    iterations           | 3714         |\n",
            "|    time_elapsed         | 6432         |\n",
            "|    total_timesteps      | 3803136      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0035496198 |\n",
            "|    clip_fraction        | 0.134        |\n",
            "|    clip_range           | 0.1          |\n",
            "|    entropy_loss         | -1.54        |\n",
            "|    explained_variance   | -1.29        |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | -0.0424      |\n",
            "|    n_updates            | 14852        |\n",
            "|    policy_gradient_loss | -0.0145      |\n",
            "|    value_loss           | 8.22e-06     |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 591          |\n",
            "|    iterations           | 3715         |\n",
            "|    time_elapsed         | 6434         |\n",
            "|    total_timesteps      | 3804160      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0026232991 |\n",
            "|    clip_fraction        | 0.0923       |\n",
            "|    clip_range           | 0.1          |\n",
            "|    entropy_loss         | -1.57        |\n",
            "|    explained_variance   | 0.000696     |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | -0.0249      |\n",
            "|    n_updates            | 14856        |\n",
            "|    policy_gradient_loss | -0.00889     |\n",
            "|    value_loss           | 0.0156       |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 591          |\n",
            "|    iterations           | 3716         |\n",
            "|    time_elapsed         | 6435         |\n",
            "|    total_timesteps      | 3805184      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0028547223 |\n",
            "|    clip_fraction        | 0.0879       |\n",
            "|    clip_range           | 0.1          |\n",
            "|    entropy_loss         | -1.65        |\n",
            "|    explained_variance   | -0.22        |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | -0.0383      |\n",
            "|    n_updates            | 14860        |\n",
            "|    policy_gradient_loss | -0.00965     |\n",
            "|    value_loss           | 0.000282     |\n",
            "------------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 591         |\n",
            "|    iterations           | 3717        |\n",
            "|    time_elapsed         | 6437        |\n",
            "|    total_timesteps      | 3806208     |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.002580984 |\n",
            "|    clip_fraction        | 0.0588      |\n",
            "|    clip_range           | 0.1         |\n",
            "|    entropy_loss         | -1.62       |\n",
            "|    explained_variance   | 0.0503      |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | -0.0357     |\n",
            "|    n_updates            | 14864       |\n",
            "|    policy_gradient_loss | -0.0106     |\n",
            "|    value_loss           | 9.89e-05    |\n",
            "-----------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 591          |\n",
            "|    iterations           | 3718         |\n",
            "|    time_elapsed         | 6438         |\n",
            "|    total_timesteps      | 3807232      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0032886507 |\n",
            "|    clip_fraction        | 0.0625       |\n",
            "|    clip_range           | 0.1          |\n",
            "|    entropy_loss         | -1.57        |\n",
            "|    explained_variance   | -0.000315    |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | -0.016       |\n",
            "|    n_updates            | 14868        |\n",
            "|    policy_gradient_loss | -0.00614     |\n",
            "|    value_loss           | 0.017        |\n",
            "------------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 591         |\n",
            "|    iterations           | 3719        |\n",
            "|    time_elapsed         | 6440        |\n",
            "|    total_timesteps      | 3808256     |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.005335287 |\n",
            "|    clip_fraction        | 0.123       |\n",
            "|    clip_range           | 0.1         |\n",
            "|    entropy_loss         | -1.59       |\n",
            "|    explained_variance   | -0.508      |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | -0.0454     |\n",
            "|    n_updates            | 14872       |\n",
            "|    policy_gradient_loss | -0.0152     |\n",
            "|    value_loss           | 5.97e-05    |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 591         |\n",
            "|    iterations           | 3720        |\n",
            "|    time_elapsed         | 6442        |\n",
            "|    total_timesteps      | 3809280     |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.005443939 |\n",
            "|    clip_fraction        | 0.141       |\n",
            "|    clip_range           | 0.1         |\n",
            "|    entropy_loss         | -1.49       |\n",
            "|    explained_variance   | -0.0925     |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | -0.0422     |\n",
            "|    n_updates            | 14876       |\n",
            "|    policy_gradient_loss | -0.0155     |\n",
            "|    value_loss           | 4.48e-05    |\n",
            "-----------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 591          |\n",
            "|    iterations           | 3721         |\n",
            "|    time_elapsed         | 6444         |\n",
            "|    total_timesteps      | 3810304      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0042459248 |\n",
            "|    clip_fraction        | 0.14         |\n",
            "|    clip_range           | 0.1          |\n",
            "|    entropy_loss         | -1.56        |\n",
            "|    explained_variance   | -1.43        |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | -0.0286      |\n",
            "|    n_updates            | 14880        |\n",
            "|    policy_gradient_loss | -0.0122      |\n",
            "|    value_loss           | 4.89e-05     |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 591          |\n",
            "|    iterations           | 3722         |\n",
            "|    time_elapsed         | 6446         |\n",
            "|    total_timesteps      | 3811328      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0046503525 |\n",
            "|    clip_fraction        | 0.164        |\n",
            "|    clip_range           | 0.1          |\n",
            "|    entropy_loss         | -1.62        |\n",
            "|    explained_variance   | -0.408       |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | -0.0414      |\n",
            "|    n_updates            | 14884        |\n",
            "|    policy_gradient_loss | -0.0151      |\n",
            "|    value_loss           | 2.61e-05     |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 591          |\n",
            "|    iterations           | 3723         |\n",
            "|    time_elapsed         | 6447         |\n",
            "|    total_timesteps      | 3812352      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0036053564 |\n",
            "|    clip_fraction        | 0.158        |\n",
            "|    clip_range           | 0.1          |\n",
            "|    entropy_loss         | -1.59        |\n",
            "|    explained_variance   | -0.783       |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | -0.0411      |\n",
            "|    n_updates            | 14888        |\n",
            "|    policy_gradient_loss | -0.0108      |\n",
            "|    value_loss           | 2.46e-05     |\n",
            "------------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 591         |\n",
            "|    iterations           | 3724        |\n",
            "|    time_elapsed         | 6449        |\n",
            "|    total_timesteps      | 3813376     |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.003303762 |\n",
            "|    clip_fraction        | 0.152       |\n",
            "|    clip_range           | 0.1         |\n",
            "|    entropy_loss         | -1.57       |\n",
            "|    explained_variance   | -1.85       |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | -0.0426     |\n",
            "|    n_updates            | 14892       |\n",
            "|    policy_gradient_loss | -0.0119     |\n",
            "|    value_loss           | 1.98e-05    |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 591         |\n",
            "|    iterations           | 3725        |\n",
            "|    time_elapsed         | 6450        |\n",
            "|    total_timesteps      | 3814400     |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.002426661 |\n",
            "|    clip_fraction        | 0.111       |\n",
            "|    clip_range           | 0.1         |\n",
            "|    entropy_loss         | -1.62       |\n",
            "|    explained_variance   | -0.923      |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | -0.0414     |\n",
            "|    n_updates            | 14896       |\n",
            "|    policy_gradient_loss | -0.0109     |\n",
            "|    value_loss           | 8.68e-06    |\n",
            "-----------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 591          |\n",
            "|    iterations           | 3726         |\n",
            "|    time_elapsed         | 6452         |\n",
            "|    total_timesteps      | 3815424      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0043679485 |\n",
            "|    clip_fraction        | 0.158        |\n",
            "|    clip_range           | 0.1          |\n",
            "|    entropy_loss         | -1.57        |\n",
            "|    explained_variance   | -0.743       |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | -0.0337      |\n",
            "|    n_updates            | 14900        |\n",
            "|    policy_gradient_loss | -0.0128      |\n",
            "|    value_loss           | 1.05e-05     |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 591          |\n",
            "|    iterations           | 3727         |\n",
            "|    time_elapsed         | 6454         |\n",
            "|    total_timesteps      | 3816448      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0042780573 |\n",
            "|    clip_fraction        | 0.159        |\n",
            "|    clip_range           | 0.1          |\n",
            "|    entropy_loss         | -1.61        |\n",
            "|    explained_variance   | -1.94        |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | -0.0483      |\n",
            "|    n_updates            | 14904        |\n",
            "|    policy_gradient_loss | -0.0144      |\n",
            "|    value_loss           | 1.09e-05     |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 591          |\n",
            "|    iterations           | 3728         |\n",
            "|    time_elapsed         | 6456         |\n",
            "|    total_timesteps      | 3817472      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0033126534 |\n",
            "|    clip_fraction        | 0.126        |\n",
            "|    clip_range           | 0.1          |\n",
            "|    entropy_loss         | -1.53        |\n",
            "|    explained_variance   | -5.14        |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | -0.0443      |\n",
            "|    n_updates            | 14908        |\n",
            "|    policy_gradient_loss | -0.015       |\n",
            "|    value_loss           | 1.11e-05     |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 591          |\n",
            "|    iterations           | 3729         |\n",
            "|    time_elapsed         | 6458         |\n",
            "|    total_timesteps      | 3818496      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0042534703 |\n",
            "|    clip_fraction        | 0.15         |\n",
            "|    clip_range           | 0.1          |\n",
            "|    entropy_loss         | -1.6         |\n",
            "|    explained_variance   | -2.67        |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | -0.0363      |\n",
            "|    n_updates            | 14912        |\n",
            "|    policy_gradient_loss | -0.0116      |\n",
            "|    value_loss           | 9.38e-06     |\n",
            "------------------------------------------\n",
            "----------------------------------------\n",
            "| time/                   |            |\n",
            "|    fps                  | 591        |\n",
            "|    iterations           | 3730       |\n",
            "|    time_elapsed         | 6459       |\n",
            "|    total_timesteps      | 3819520    |\n",
            "| train/                  |            |\n",
            "|    approx_kl            | 0.00412937 |\n",
            "|    clip_fraction        | 0.132      |\n",
            "|    clip_range           | 0.1        |\n",
            "|    entropy_loss         | -1.58      |\n",
            "|    explained_variance   | -0.807     |\n",
            "|    learning_rate        | 0.00025    |\n",
            "|    loss                 | -0.0455    |\n",
            "|    n_updates            | 14916      |\n",
            "|    policy_gradient_loss | -0.0142    |\n",
            "|    value_loss           | 1.15e-05   |\n",
            "----------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 591          |\n",
            "|    iterations           | 3731         |\n",
            "|    time_elapsed         | 6461         |\n",
            "|    total_timesteps      | 3820544      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0039348714 |\n",
            "|    clip_fraction        | 0.161        |\n",
            "|    clip_range           | 0.1          |\n",
            "|    entropy_loss         | -1.63        |\n",
            "|    explained_variance   | -1.9         |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | -0.0411      |\n",
            "|    n_updates            | 14920        |\n",
            "|    policy_gradient_loss | -0.014       |\n",
            "|    value_loss           | 1.06e-05     |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 591          |\n",
            "|    iterations           | 3732         |\n",
            "|    time_elapsed         | 6462         |\n",
            "|    total_timesteps      | 3821568      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0052457973 |\n",
            "|    clip_fraction        | 0.146        |\n",
            "|    clip_range           | 0.1          |\n",
            "|    entropy_loss         | -1.52        |\n",
            "|    explained_variance   | -2.68        |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | -0.0401      |\n",
            "|    n_updates            | 14924        |\n",
            "|    policy_gradient_loss | -0.0119      |\n",
            "|    value_loss           | 1.12e-05     |\n",
            "------------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 591         |\n",
            "|    iterations           | 3733        |\n",
            "|    time_elapsed         | 6464        |\n",
            "|    total_timesteps      | 3822592     |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.003746897 |\n",
            "|    clip_fraction        | 0.136       |\n",
            "|    clip_range           | 0.1         |\n",
            "|    entropy_loss         | -1.62       |\n",
            "|    explained_variance   | -0.625      |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | -0.0379     |\n",
            "|    n_updates            | 14928       |\n",
            "|    policy_gradient_loss | -0.0118     |\n",
            "|    value_loss           | 5.67e-06    |\n",
            "-----------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 591          |\n",
            "|    iterations           | 3734         |\n",
            "|    time_elapsed         | 6466         |\n",
            "|    total_timesteps      | 3823616      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0042958166 |\n",
            "|    clip_fraction        | 0.0706       |\n",
            "|    clip_range           | 0.1          |\n",
            "|    entropy_loss         | -1.62        |\n",
            "|    explained_variance   | 0.00607      |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | -0.0215      |\n",
            "|    n_updates            | 14932        |\n",
            "|    policy_gradient_loss | -0.00427     |\n",
            "|    value_loss           | 0.00527      |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 591          |\n",
            "|    iterations           | 3735         |\n",
            "|    time_elapsed         | 6467         |\n",
            "|    total_timesteps      | 3824640      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0039757583 |\n",
            "|    clip_fraction        | 0.126        |\n",
            "|    clip_range           | 0.1          |\n",
            "|    entropy_loss         | -1.66        |\n",
            "|    explained_variance   | -1.02        |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | -0.0342      |\n",
            "|    n_updates            | 14936        |\n",
            "|    policy_gradient_loss | -0.0114      |\n",
            "|    value_loss           | 0.000154     |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 591          |\n",
            "|    iterations           | 3736         |\n",
            "|    time_elapsed         | 6469         |\n",
            "|    total_timesteps      | 3825664      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0042680944 |\n",
            "|    clip_fraction        | 0.157        |\n",
            "|    clip_range           | 0.1          |\n",
            "|    entropy_loss         | -1.6         |\n",
            "|    explained_variance   | -5.75        |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | -0.0429      |\n",
            "|    n_updates            | 14940        |\n",
            "|    policy_gradient_loss | -0.0131      |\n",
            "|    value_loss           | 7.55e-05     |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 591          |\n",
            "|    iterations           | 3737         |\n",
            "|    time_elapsed         | 6471         |\n",
            "|    total_timesteps      | 3826688      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0038160542 |\n",
            "|    clip_fraction        | 0.0952       |\n",
            "|    clip_range           | 0.1          |\n",
            "|    entropy_loss         | -1.61        |\n",
            "|    explained_variance   | -0.0513      |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | -0.0331      |\n",
            "|    n_updates            | 14944        |\n",
            "|    policy_gradient_loss | -0.00721     |\n",
            "|    value_loss           | 0.001        |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 591          |\n",
            "|    iterations           | 3738         |\n",
            "|    time_elapsed         | 6473         |\n",
            "|    total_timesteps      | 3827712      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0039838282 |\n",
            "|    clip_fraction        | 0.11         |\n",
            "|    clip_range           | 0.1          |\n",
            "|    entropy_loss         | -1.65        |\n",
            "|    explained_variance   | 0.457        |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | -0.0459      |\n",
            "|    n_updates            | 14948        |\n",
            "|    policy_gradient_loss | -0.0132      |\n",
            "|    value_loss           | 4.2e-05      |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 591          |\n",
            "|    iterations           | 3739         |\n",
            "|    time_elapsed         | 6474         |\n",
            "|    total_timesteps      | 3828736      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0023559453 |\n",
            "|    clip_fraction        | 0.0647       |\n",
            "|    clip_range           | 0.1          |\n",
            "|    entropy_loss         | -1.65        |\n",
            "|    explained_variance   | -0.599       |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | -0.0363      |\n",
            "|    n_updates            | 14952        |\n",
            "|    policy_gradient_loss | -0.00996     |\n",
            "|    value_loss           | 7.74e-05     |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 591          |\n",
            "|    iterations           | 3740         |\n",
            "|    time_elapsed         | 6476         |\n",
            "|    total_timesteps      | 3829760      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0038796891 |\n",
            "|    clip_fraction        | 0.115        |\n",
            "|    clip_range           | 0.1          |\n",
            "|    entropy_loss         | -1.68        |\n",
            "|    explained_variance   | -0.778       |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | -0.0316      |\n",
            "|    n_updates            | 14956        |\n",
            "|    policy_gradient_loss | -0.00875     |\n",
            "|    value_loss           | 5.89e-05     |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 591          |\n",
            "|    iterations           | 3741         |\n",
            "|    time_elapsed         | 6477         |\n",
            "|    total_timesteps      | 3830784      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0023077603 |\n",
            "|    clip_fraction        | 0.0701       |\n",
            "|    clip_range           | 0.1          |\n",
            "|    entropy_loss         | -1.68        |\n",
            "|    explained_variance   | 0.0364       |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | -0.0356      |\n",
            "|    n_updates            | 14960        |\n",
            "|    policy_gradient_loss | -0.00989     |\n",
            "|    value_loss           | 1.67e-05     |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 591          |\n",
            "|    iterations           | 3742         |\n",
            "|    time_elapsed         | 6479         |\n",
            "|    total_timesteps      | 3831808      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0020228908 |\n",
            "|    clip_fraction        | 0.0991       |\n",
            "|    clip_range           | 0.1          |\n",
            "|    entropy_loss         | -1.71        |\n",
            "|    explained_variance   | 0.778        |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | -0.0283      |\n",
            "|    n_updates            | 14964        |\n",
            "|    policy_gradient_loss | -0.00797     |\n",
            "|    value_loss           | 4.89e-06     |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 591          |\n",
            "|    iterations           | 3743         |\n",
            "|    time_elapsed         | 6480         |\n",
            "|    total_timesteps      | 3832832      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0044741537 |\n",
            "|    clip_fraction        | 0.111        |\n",
            "|    clip_range           | 0.1          |\n",
            "|    entropy_loss         | -1.68        |\n",
            "|    explained_variance   | 0.415        |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | -0.0334      |\n",
            "|    n_updates            | 14968        |\n",
            "|    policy_gradient_loss | -0.0111      |\n",
            "|    value_loss           | 8.74e-06     |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 591          |\n",
            "|    iterations           | 3744         |\n",
            "|    time_elapsed         | 6483         |\n",
            "|    total_timesteps      | 3833856      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0029005813 |\n",
            "|    clip_fraction        | 0.0688       |\n",
            "|    clip_range           | 0.1          |\n",
            "|    entropy_loss         | -1.67        |\n",
            "|    explained_variance   | -0.884       |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | -0.0229      |\n",
            "|    n_updates            | 14972        |\n",
            "|    policy_gradient_loss | -0.00705     |\n",
            "|    value_loss           | 2.27e-05     |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 591          |\n",
            "|    iterations           | 3745         |\n",
            "|    time_elapsed         | 6484         |\n",
            "|    total_timesteps      | 3834880      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0032215684 |\n",
            "|    clip_fraction        | 0.0815       |\n",
            "|    clip_range           | 0.1          |\n",
            "|    entropy_loss         | -1.66        |\n",
            "|    explained_variance   | -1.07        |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | -0.0381      |\n",
            "|    n_updates            | 14976        |\n",
            "|    policy_gradient_loss | -0.0124      |\n",
            "|    value_loss           | 1.95e-05     |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 591          |\n",
            "|    iterations           | 3746         |\n",
            "|    time_elapsed         | 6486         |\n",
            "|    total_timesteps      | 3835904      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0039727637 |\n",
            "|    clip_fraction        | 0.124        |\n",
            "|    clip_range           | 0.1          |\n",
            "|    entropy_loss         | -1.66        |\n",
            "|    explained_variance   | -0.497       |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | -0.032       |\n",
            "|    n_updates            | 14980        |\n",
            "|    policy_gradient_loss | -0.0115      |\n",
            "|    value_loss           | 1.18e-05     |\n",
            "------------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 591         |\n",
            "|    iterations           | 3747        |\n",
            "|    time_elapsed         | 6487        |\n",
            "|    total_timesteps      | 3836928     |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.004373301 |\n",
            "|    clip_fraction        | 0.122       |\n",
            "|    clip_range           | 0.1         |\n",
            "|    entropy_loss         | -1.68       |\n",
            "|    explained_variance   | -1.5        |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | -0.0358     |\n",
            "|    n_updates            | 14984       |\n",
            "|    policy_gradient_loss | -0.0121     |\n",
            "|    value_loss           | 2.63e-05    |\n",
            "-----------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 591          |\n",
            "|    iterations           | 3748         |\n",
            "|    time_elapsed         | 6489         |\n",
            "|    total_timesteps      | 3837952      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0020464507 |\n",
            "|    clip_fraction        | 0.0354       |\n",
            "|    clip_range           | 0.1          |\n",
            "|    entropy_loss         | -1.66        |\n",
            "|    explained_variance   | -0.00486     |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | -0.0216      |\n",
            "|    n_updates            | 14988        |\n",
            "|    policy_gradient_loss | -0.00844     |\n",
            "|    value_loss           | 0.017        |\n",
            "------------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 591         |\n",
            "|    iterations           | 3749        |\n",
            "|    time_elapsed         | 6490        |\n",
            "|    total_timesteps      | 3838976     |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.003300895 |\n",
            "|    clip_fraction        | 0.0862      |\n",
            "|    clip_range           | 0.1         |\n",
            "|    entropy_loss         | -1.57       |\n",
            "|    explained_variance   | -4.88       |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | -0.0287     |\n",
            "|    n_updates            | 14992       |\n",
            "|    policy_gradient_loss | -0.00901    |\n",
            "|    value_loss           | 2.38e-05    |\n",
            "-----------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 591          |\n",
            "|    iterations           | 3750         |\n",
            "|    time_elapsed         | 6492         |\n",
            "|    total_timesteps      | 3840000      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0032078444 |\n",
            "|    clip_fraction        | 0.0969       |\n",
            "|    clip_range           | 0.1          |\n",
            "|    entropy_loss         | -1.65        |\n",
            "|    explained_variance   | -2.5         |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | -0.0342      |\n",
            "|    n_updates            | 14996        |\n",
            "|    policy_gradient_loss | -0.0111      |\n",
            "|    value_loss           | 9.17e-06     |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 591          |\n",
            "|    iterations           | 3751         |\n",
            "|    time_elapsed         | 6494         |\n",
            "|    total_timesteps      | 3841024      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0017699613 |\n",
            "|    clip_fraction        | 0.0439       |\n",
            "|    clip_range           | 0.1          |\n",
            "|    entropy_loss         | -1.69        |\n",
            "|    explained_variance   | -4.54        |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | -0.0306      |\n",
            "|    n_updates            | 15000        |\n",
            "|    policy_gradient_loss | -0.00833     |\n",
            "|    value_loss           | 7.65e-06     |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 591          |\n",
            "|    iterations           | 3752         |\n",
            "|    time_elapsed         | 6496         |\n",
            "|    total_timesteps      | 3842048      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0031439792 |\n",
            "|    clip_fraction        | 0.157        |\n",
            "|    clip_range           | 0.1          |\n",
            "|    entropy_loss         | -1.66        |\n",
            "|    explained_variance   | -9.05        |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | -0.034       |\n",
            "|    n_updates            | 15004        |\n",
            "|    policy_gradient_loss | -0.0118      |\n",
            "|    value_loss           | 1.11e-05     |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 591          |\n",
            "|    iterations           | 3753         |\n",
            "|    time_elapsed         | 6498         |\n",
            "|    total_timesteps      | 3843072      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0027464938 |\n",
            "|    clip_fraction        | 0.123        |\n",
            "|    clip_range           | 0.1          |\n",
            "|    entropy_loss         | -1.66        |\n",
            "|    explained_variance   | -3.05        |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | -0.0387      |\n",
            "|    n_updates            | 15008        |\n",
            "|    policy_gradient_loss | -0.00852     |\n",
            "|    value_loss           | 9.97e-06     |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 591          |\n",
            "|    iterations           | 3754         |\n",
            "|    time_elapsed         | 6499         |\n",
            "|    total_timesteps      | 3844096      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0035177767 |\n",
            "|    clip_fraction        | 0.144        |\n",
            "|    clip_range           | 0.1          |\n",
            "|    entropy_loss         | -1.58        |\n",
            "|    explained_variance   | -6.02        |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | -0.0432      |\n",
            "|    n_updates            | 15012        |\n",
            "|    policy_gradient_loss | -0.00964     |\n",
            "|    value_loss           | 1.07e-05     |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 591          |\n",
            "|    iterations           | 3755         |\n",
            "|    time_elapsed         | 6501         |\n",
            "|    total_timesteps      | 3845120      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0034807846 |\n",
            "|    clip_fraction        | 0.135        |\n",
            "|    clip_range           | 0.1          |\n",
            "|    entropy_loss         | -1.65        |\n",
            "|    explained_variance   | -4.54        |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | -0.0353      |\n",
            "|    n_updates            | 15016        |\n",
            "|    policy_gradient_loss | -0.011       |\n",
            "|    value_loss           | 6.47e-06     |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 591          |\n",
            "|    iterations           | 3756         |\n",
            "|    time_elapsed         | 6502         |\n",
            "|    total_timesteps      | 3846144      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0037054685 |\n",
            "|    clip_fraction        | 0.164        |\n",
            "|    clip_range           | 0.1          |\n",
            "|    entropy_loss         | -1.66        |\n",
            "|    explained_variance   | 0.00411      |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | -0.0249      |\n",
            "|    n_updates            | 15020        |\n",
            "|    policy_gradient_loss | -0.00694     |\n",
            "|    value_loss           | 0.00774      |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 591          |\n",
            "|    iterations           | 3757         |\n",
            "|    time_elapsed         | 6504         |\n",
            "|    total_timesteps      | 3847168      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0026188984 |\n",
            "|    clip_fraction        | 0.106        |\n",
            "|    clip_range           | 0.1          |\n",
            "|    entropy_loss         | -1.65        |\n",
            "|    explained_variance   | 0.772        |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | -0.0246      |\n",
            "|    n_updates            | 15024        |\n",
            "|    policy_gradient_loss | -0.00849     |\n",
            "|    value_loss           | 7.61e-05     |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 591          |\n",
            "|    iterations           | 3758         |\n",
            "|    time_elapsed         | 6505         |\n",
            "|    total_timesteps      | 3848192      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0018353115 |\n",
            "|    clip_fraction        | 0.145        |\n",
            "|    clip_range           | 0.1          |\n",
            "|    entropy_loss         | -1.67        |\n",
            "|    explained_variance   | 0.52         |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | -0.0406      |\n",
            "|    n_updates            | 15028        |\n",
            "|    policy_gradient_loss | -0.0101      |\n",
            "|    value_loss           | 6.87e-05     |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 591          |\n",
            "|    iterations           | 3759         |\n",
            "|    time_elapsed         | 6507         |\n",
            "|    total_timesteps      | 3849216      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0026786455 |\n",
            "|    clip_fraction        | 0.145        |\n",
            "|    clip_range           | 0.1          |\n",
            "|    entropy_loss         | -1.67        |\n",
            "|    explained_variance   | 0.442        |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | -0.0312      |\n",
            "|    n_updates            | 15032        |\n",
            "|    policy_gradient_loss | -0.00682     |\n",
            "|    value_loss           | 2.83e-05     |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 591          |\n",
            "|    iterations           | 3760         |\n",
            "|    time_elapsed         | 6509         |\n",
            "|    total_timesteps      | 3850240      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0033476704 |\n",
            "|    clip_fraction        | 0.135        |\n",
            "|    clip_range           | 0.1          |\n",
            "|    entropy_loss         | -1.68        |\n",
            "|    explained_variance   | 0.748        |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | -0.0329      |\n",
            "|    n_updates            | 15036        |\n",
            "|    policy_gradient_loss | -0.00718     |\n",
            "|    value_loss           | 1.02e-05     |\n",
            "------------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 591         |\n",
            "|    iterations           | 3761        |\n",
            "|    time_elapsed         | 6511        |\n",
            "|    total_timesteps      | 3851264     |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.003383895 |\n",
            "|    clip_fraction        | 0.0786      |\n",
            "|    clip_range           | 0.1         |\n",
            "|    entropy_loss         | -1.61       |\n",
            "|    explained_variance   | 0.403       |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | -0.0315     |\n",
            "|    n_updates            | 15040       |\n",
            "|    policy_gradient_loss | -0.0108     |\n",
            "|    value_loss           | 1.26e-05    |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 591         |\n",
            "|    iterations           | 3762        |\n",
            "|    time_elapsed         | 6512        |\n",
            "|    total_timesteps      | 3852288     |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.002525625 |\n",
            "|    clip_fraction        | 0.104       |\n",
            "|    clip_range           | 0.1         |\n",
            "|    entropy_loss         | -1.67       |\n",
            "|    explained_variance   | 0.314       |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | -0.0325     |\n",
            "|    n_updates            | 15044       |\n",
            "|    policy_gradient_loss | -0.00815    |\n",
            "|    value_loss           | 1.52e-05    |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 591         |\n",
            "|    iterations           | 3763        |\n",
            "|    time_elapsed         | 6514        |\n",
            "|    total_timesteps      | 3853312     |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.001736975 |\n",
            "|    clip_fraction        | 0.0801      |\n",
            "|    clip_range           | 0.1         |\n",
            "|    entropy_loss         | -1.52       |\n",
            "|    explained_variance   | -0.000655   |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | -0.00509    |\n",
            "|    n_updates            | 15048       |\n",
            "|    policy_gradient_loss | -0.000326   |\n",
            "|    value_loss           | 0.0169      |\n",
            "-----------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 591          |\n",
            "|    iterations           | 3764         |\n",
            "|    time_elapsed         | 6515         |\n",
            "|    total_timesteps      | 3854336      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0021437556 |\n",
            "|    clip_fraction        | 0.102        |\n",
            "|    clip_range           | 0.1          |\n",
            "|    entropy_loss         | -1.62        |\n",
            "|    explained_variance   | -6.57        |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | -0.0364      |\n",
            "|    n_updates            | 15052        |\n",
            "|    policy_gradient_loss | -0.0103      |\n",
            "|    value_loss           | 1.36e-05     |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 591          |\n",
            "|    iterations           | 3765         |\n",
            "|    time_elapsed         | 6517         |\n",
            "|    total_timesteps      | 3855360      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0033992026 |\n",
            "|    clip_fraction        | 0.102        |\n",
            "|    clip_range           | 0.1          |\n",
            "|    entropy_loss         | -1.64        |\n",
            "|    explained_variance   | -10.7        |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | -0.0286      |\n",
            "|    n_updates            | 15056        |\n",
            "|    policy_gradient_loss | -0.00902     |\n",
            "|    value_loss           | 5.93e-06     |\n",
            "------------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 591         |\n",
            "|    iterations           | 3766        |\n",
            "|    time_elapsed         | 6518        |\n",
            "|    total_timesteps      | 3856384     |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.003366982 |\n",
            "|    clip_fraction        | 0.125       |\n",
            "|    clip_range           | 0.1         |\n",
            "|    entropy_loss         | -1.61       |\n",
            "|    explained_variance   | -9.35       |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | -0.0411     |\n",
            "|    n_updates            | 15060       |\n",
            "|    policy_gradient_loss | -0.0118     |\n",
            "|    value_loss           | 9.34e-06    |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 591         |\n",
            "|    iterations           | 3767        |\n",
            "|    time_elapsed         | 6520        |\n",
            "|    total_timesteps      | 3857408     |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.002589128 |\n",
            "|    clip_fraction        | 0.0952      |\n",
            "|    clip_range           | 0.1         |\n",
            "|    entropy_loss         | -1.65       |\n",
            "|    explained_variance   | -5.68       |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | -0.0319     |\n",
            "|    n_updates            | 15064       |\n",
            "|    policy_gradient_loss | -0.00747    |\n",
            "|    value_loss           | 7.48e-06    |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 591         |\n",
            "|    iterations           | 3768        |\n",
            "|    time_elapsed         | 6523        |\n",
            "|    total_timesteps      | 3858432     |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.004461378 |\n",
            "|    clip_fraction        | 0.109       |\n",
            "|    clip_range           | 0.1         |\n",
            "|    entropy_loss         | -1.45       |\n",
            "|    explained_variance   | -11.2       |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | -0.0265     |\n",
            "|    n_updates            | 15068       |\n",
            "|    policy_gradient_loss | -0.00987    |\n",
            "|    value_loss           | 1.11e-05    |\n",
            "-----------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 591          |\n",
            "|    iterations           | 3769         |\n",
            "|    time_elapsed         | 6524         |\n",
            "|    total_timesteps      | 3859456      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0020046306 |\n",
            "|    clip_fraction        | 0.0962       |\n",
            "|    clip_range           | 0.1          |\n",
            "|    entropy_loss         | -1.59        |\n",
            "|    explained_variance   | -4.66        |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | -0.0345      |\n",
            "|    n_updates            | 15072        |\n",
            "|    policy_gradient_loss | -0.00884     |\n",
            "|    value_loss           | 7.97e-06     |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 591          |\n",
            "|    iterations           | 3770         |\n",
            "|    time_elapsed         | 6526         |\n",
            "|    total_timesteps      | 3860480      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0025473158 |\n",
            "|    clip_fraction        | 0.12         |\n",
            "|    clip_range           | 0.1          |\n",
            "|    entropy_loss         | -1.55        |\n",
            "|    explained_variance   | -0.27        |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | -0.0401      |\n",
            "|    n_updates            | 15076        |\n",
            "|    policy_gradient_loss | -0.00995     |\n",
            "|    value_loss           | 6.2e-06      |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 591          |\n",
            "|    iterations           | 3771         |\n",
            "|    time_elapsed         | 6527         |\n",
            "|    total_timesteps      | 3861504      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0024439374 |\n",
            "|    clip_fraction        | 0.119        |\n",
            "|    clip_range           | 0.1          |\n",
            "|    entropy_loss         | -1.62        |\n",
            "|    explained_variance   | 0.342        |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | -0.027       |\n",
            "|    n_updates            | 15080        |\n",
            "|    policy_gradient_loss | -0.00655     |\n",
            "|    value_loss           | 4.18e-06     |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 591          |\n",
            "|    iterations           | 3772         |\n",
            "|    time_elapsed         | 6529         |\n",
            "|    total_timesteps      | 3862528      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0023319349 |\n",
            "|    clip_fraction        | 0.061        |\n",
            "|    clip_range           | 0.1          |\n",
            "|    entropy_loss         | -1.59        |\n",
            "|    explained_variance   | -1.4         |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | -0.0355      |\n",
            "|    n_updates            | 15084        |\n",
            "|    policy_gradient_loss | -0.00896     |\n",
            "|    value_loss           | 5.41e-06     |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 591          |\n",
            "|    iterations           | 3773         |\n",
            "|    time_elapsed         | 6530         |\n",
            "|    total_timesteps      | 3863552      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0037439892 |\n",
            "|    clip_fraction        | 0.115        |\n",
            "|    clip_range           | 0.1          |\n",
            "|    entropy_loss         | -1.58        |\n",
            "|    explained_variance   | -0.493       |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | -0.033       |\n",
            "|    n_updates            | 15088        |\n",
            "|    policy_gradient_loss | -0.0101      |\n",
            "|    value_loss           | 4.61e-06     |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 591          |\n",
            "|    iterations           | 3774         |\n",
            "|    time_elapsed         | 6532         |\n",
            "|    total_timesteps      | 3864576      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0028453676 |\n",
            "|    clip_fraction        | 0.104        |\n",
            "|    clip_range           | 0.1          |\n",
            "|    entropy_loss         | -1.57        |\n",
            "|    explained_variance   | -2.72        |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | -0.0422      |\n",
            "|    n_updates            | 15092        |\n",
            "|    policy_gradient_loss | -0.0107      |\n",
            "|    value_loss           | 7.5e-06      |\n",
            "------------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 591         |\n",
            "|    iterations           | 3775        |\n",
            "|    time_elapsed         | 6534        |\n",
            "|    total_timesteps      | 3865600     |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.002252211 |\n",
            "|    clip_fraction        | 0.141       |\n",
            "|    clip_range           | 0.1         |\n",
            "|    entropy_loss         | -1.61       |\n",
            "|    explained_variance   | -0.639      |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | -0.0319     |\n",
            "|    n_updates            | 15096       |\n",
            "|    policy_gradient_loss | -0.00789    |\n",
            "|    value_loss           | 2.88e-06    |\n",
            "-----------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 591          |\n",
            "|    iterations           | 3776         |\n",
            "|    time_elapsed         | 6536         |\n",
            "|    total_timesteps      | 3866624      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0031497043 |\n",
            "|    clip_fraction        | 0.202        |\n",
            "|    clip_range           | 0.1          |\n",
            "|    entropy_loss         | -1.53        |\n",
            "|    explained_variance   | -0.00404     |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | -0.015       |\n",
            "|    n_updates            | 15100        |\n",
            "|    policy_gradient_loss | -0.00184     |\n",
            "|    value_loss           | 0.00812      |\n",
            "------------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 591         |\n",
            "|    iterations           | 3777        |\n",
            "|    time_elapsed         | 6538        |\n",
            "|    total_timesteps      | 3867648     |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.006456783 |\n",
            "|    clip_fraction        | 0.198       |\n",
            "|    clip_range           | 0.1         |\n",
            "|    entropy_loss         | -1.62       |\n",
            "|    explained_variance   | -0.0269     |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | -0.00463    |\n",
            "|    n_updates            | 15104       |\n",
            "|    policy_gradient_loss | -0.00271    |\n",
            "|    value_loss           | 0.00822     |\n",
            "-----------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 591          |\n",
            "|    iterations           | 3778         |\n",
            "|    time_elapsed         | 6539         |\n",
            "|    total_timesteps      | 3868672      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0023470456 |\n",
            "|    clip_fraction        | 0.0957       |\n",
            "|    clip_range           | 0.1          |\n",
            "|    entropy_loss         | -1.62        |\n",
            "|    explained_variance   | 0.268        |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | -0.031       |\n",
            "|    n_updates            | 15108        |\n",
            "|    policy_gradient_loss | -0.00636     |\n",
            "|    value_loss           | 6e-05        |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 591          |\n",
            "|    iterations           | 3779         |\n",
            "|    time_elapsed         | 6541         |\n",
            "|    total_timesteps      | 3869696      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0028866963 |\n",
            "|    clip_fraction        | 0.118        |\n",
            "|    clip_range           | 0.1          |\n",
            "|    entropy_loss         | -1.65        |\n",
            "|    explained_variance   | 0.602        |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | -0.0331      |\n",
            "|    n_updates            | 15112        |\n",
            "|    policy_gradient_loss | -0.00865     |\n",
            "|    value_loss           | 2.77e-05     |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 591          |\n",
            "|    iterations           | 3780         |\n",
            "|    time_elapsed         | 6542         |\n",
            "|    total_timesteps      | 3870720      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0025389649 |\n",
            "|    clip_fraction        | 0.0942       |\n",
            "|    clip_range           | 0.1          |\n",
            "|    entropy_loss         | -1.48        |\n",
            "|    explained_variance   | 0.301        |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | -0.0277      |\n",
            "|    n_updates            | 15116        |\n",
            "|    policy_gradient_loss | -0.00937     |\n",
            "|    value_loss           | 3.53e-05     |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 591          |\n",
            "|    iterations           | 3781         |\n",
            "|    time_elapsed         | 6544         |\n",
            "|    total_timesteps      | 3871744      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0045947777 |\n",
            "|    clip_fraction        | 0.152        |\n",
            "|    clip_range           | 0.1          |\n",
            "|    entropy_loss         | -1.63        |\n",
            "|    explained_variance   | 0.0212       |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | -0.0217      |\n",
            "|    n_updates            | 15120        |\n",
            "|    policy_gradient_loss | -0.00597     |\n",
            "|    value_loss           | 0.00776      |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 591          |\n",
            "|    iterations           | 3782         |\n",
            "|    time_elapsed         | 6545         |\n",
            "|    total_timesteps      | 3872768      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0039815074 |\n",
            "|    clip_fraction        | 0.0972       |\n",
            "|    clip_range           | 0.1          |\n",
            "|    entropy_loss         | -1.58        |\n",
            "|    explained_variance   | 0.425        |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | -0.0365      |\n",
            "|    n_updates            | 15124        |\n",
            "|    policy_gradient_loss | -0.0112      |\n",
            "|    value_loss           | 0.00016      |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 591          |\n",
            "|    iterations           | 3783         |\n",
            "|    time_elapsed         | 6547         |\n",
            "|    total_timesteps      | 3873792      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0038072446 |\n",
            "|    clip_fraction        | 0.148        |\n",
            "|    clip_range           | 0.1          |\n",
            "|    entropy_loss         | -1.63        |\n",
            "|    explained_variance   | 0.56         |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | -0.0365      |\n",
            "|    n_updates            | 15128        |\n",
            "|    policy_gradient_loss | -0.0116      |\n",
            "|    value_loss           | 8.3e-05      |\n",
            "------------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 591         |\n",
            "|    iterations           | 3784        |\n",
            "|    time_elapsed         | 6549        |\n",
            "|    total_timesteps      | 3874816     |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.005308981 |\n",
            "|    clip_fraction        | 0.14        |\n",
            "|    clip_range           | 0.1         |\n",
            "|    entropy_loss         | -1.48       |\n",
            "|    explained_variance   | 0.668       |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | -0.0246     |\n",
            "|    n_updates            | 15132       |\n",
            "|    policy_gradient_loss | -0.00981    |\n",
            "|    value_loss           | 3.38e-05    |\n",
            "-----------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 591          |\n",
            "|    iterations           | 3785         |\n",
            "|    time_elapsed         | 6551         |\n",
            "|    total_timesteps      | 3875840      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0023622354 |\n",
            "|    clip_fraction        | 0.15         |\n",
            "|    clip_range           | 0.1          |\n",
            "|    entropy_loss         | -1.54        |\n",
            "|    explained_variance   | 0.768        |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | -0.0351      |\n",
            "|    n_updates            | 15136        |\n",
            "|    policy_gradient_loss | -0.0083      |\n",
            "|    value_loss           | 2.38e-05     |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 591          |\n",
            "|    iterations           | 3786         |\n",
            "|    time_elapsed         | 6552         |\n",
            "|    total_timesteps      | 3876864      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0035757637 |\n",
            "|    clip_fraction        | 0.16         |\n",
            "|    clip_range           | 0.1          |\n",
            "|    entropy_loss         | -1.57        |\n",
            "|    explained_variance   | 0.73         |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | -0.0371      |\n",
            "|    n_updates            | 15140        |\n",
            "|    policy_gradient_loss | -0.01        |\n",
            "|    value_loss           | 1.78e-05     |\n",
            "------------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 591         |\n",
            "|    iterations           | 3787        |\n",
            "|    time_elapsed         | 6554        |\n",
            "|    total_timesteps      | 3877888     |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.005366897 |\n",
            "|    clip_fraction        | 0.115       |\n",
            "|    clip_range           | 0.1         |\n",
            "|    entropy_loss         | -1.42       |\n",
            "|    explained_variance   | 0.563       |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | -0.0317     |\n",
            "|    n_updates            | 15144       |\n",
            "|    policy_gradient_loss | -0.012      |\n",
            "|    value_loss           | 1.88e-05    |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 591         |\n",
            "|    iterations           | 3788        |\n",
            "|    time_elapsed         | 6555        |\n",
            "|    total_timesteps      | 3878912     |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.002535063 |\n",
            "|    clip_fraction        | 0.0962      |\n",
            "|    clip_range           | 0.1         |\n",
            "|    entropy_loss         | -1.5        |\n",
            "|    explained_variance   | 0.5         |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | -0.0346     |\n",
            "|    n_updates            | 15148       |\n",
            "|    policy_gradient_loss | -0.0089     |\n",
            "|    value_loss           | 1.84e-05    |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 591         |\n",
            "|    iterations           | 3789        |\n",
            "|    time_elapsed         | 6557        |\n",
            "|    total_timesteps      | 3879936     |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.004233893 |\n",
            "|    clip_fraction        | 0.0996      |\n",
            "|    clip_range           | 0.1         |\n",
            "|    entropy_loss         | -1.52       |\n",
            "|    explained_variance   | 0.629       |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | -0.0328     |\n",
            "|    n_updates            | 15152       |\n",
            "|    policy_gradient_loss | -0.0111     |\n",
            "|    value_loss           | 1.08e-05    |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 591         |\n",
            "|    iterations           | 3790        |\n",
            "|    time_elapsed         | 6559        |\n",
            "|    total_timesteps      | 3880960     |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.003304587 |\n",
            "|    clip_fraction        | 0.106       |\n",
            "|    clip_range           | 0.1         |\n",
            "|    entropy_loss         | -1.51       |\n",
            "|    explained_variance   | 0.203       |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | -0.0364     |\n",
            "|    n_updates            | 15156       |\n",
            "|    policy_gradient_loss | -0.0116     |\n",
            "|    value_loss           | 9.68e-06    |\n",
            "-----------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 591          |\n",
            "|    iterations           | 3791         |\n",
            "|    time_elapsed         | 6561         |\n",
            "|    total_timesteps      | 3881984      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0019882454 |\n",
            "|    clip_fraction        | 0.0645       |\n",
            "|    clip_range           | 0.1          |\n",
            "|    entropy_loss         | -1.48        |\n",
            "|    explained_variance   | -0.981       |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | -0.0336      |\n",
            "|    n_updates            | 15160        |\n",
            "|    policy_gradient_loss | -0.00953     |\n",
            "|    value_loss           | 7.3e-06      |\n",
            "------------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 591         |\n",
            "|    iterations           | 3792        |\n",
            "|    time_elapsed         | 6563        |\n",
            "|    total_timesteps      | 3883008     |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.002536248 |\n",
            "|    clip_fraction        | 0.0564      |\n",
            "|    clip_range           | 0.1         |\n",
            "|    entropy_loss         | -1.46       |\n",
            "|    explained_variance   | -0.495      |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | -0.0307     |\n",
            "|    n_updates            | 15164       |\n",
            "|    policy_gradient_loss | -0.0094     |\n",
            "|    value_loss           | 5.84e-06    |\n",
            "-----------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 591          |\n",
            "|    iterations           | 3793         |\n",
            "|    time_elapsed         | 6564         |\n",
            "|    total_timesteps      | 3884032      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0035268571 |\n",
            "|    clip_fraction        | 0.119        |\n",
            "|    clip_range           | 0.1          |\n",
            "|    entropy_loss         | -1.53        |\n",
            "|    explained_variance   | 0.329        |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | -0.0371      |\n",
            "|    n_updates            | 15168        |\n",
            "|    policy_gradient_loss | -0.0103      |\n",
            "|    value_loss           | 4.42e-06     |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 591          |\n",
            "|    iterations           | 3794         |\n",
            "|    time_elapsed         | 6566         |\n",
            "|    total_timesteps      | 3885056      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0045508146 |\n",
            "|    clip_fraction        | 0.0879       |\n",
            "|    clip_range           | 0.1          |\n",
            "|    entropy_loss         | -1.42        |\n",
            "|    explained_variance   | -1.38        |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | -0.033       |\n",
            "|    n_updates            | 15172        |\n",
            "|    policy_gradient_loss | -0.0122      |\n",
            "|    value_loss           | 1.14e-05     |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 591          |\n",
            "|    iterations           | 3795         |\n",
            "|    time_elapsed         | 6567         |\n",
            "|    total_timesteps      | 3886080      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0031880012 |\n",
            "|    clip_fraction        | 0.0862       |\n",
            "|    clip_range           | 0.1          |\n",
            "|    entropy_loss         | -1.47        |\n",
            "|    explained_variance   | -2.14        |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | -0.0354      |\n",
            "|    n_updates            | 15176        |\n",
            "|    policy_gradient_loss | -0.0133      |\n",
            "|    value_loss           | 1.29e-05     |\n",
            "------------------------------------------\n",
            "----------------------------------------\n",
            "| time/                   |            |\n",
            "|    fps                  | 591        |\n",
            "|    iterations           | 3796       |\n",
            "|    time_elapsed         | 6569       |\n",
            "|    total_timesteps      | 3887104    |\n",
            "| train/                  |            |\n",
            "|    approx_kl            | 0.00166613 |\n",
            "|    clip_fraction        | 0.083      |\n",
            "|    clip_range           | 0.1        |\n",
            "|    entropy_loss         | -1.59      |\n",
            "|    explained_variance   | 0.518      |\n",
            "|    learning_rate        | 0.00025    |\n",
            "|    loss                 | -0.0313    |\n",
            "|    n_updates            | 15180      |\n",
            "|    policy_gradient_loss | -0.00851   |\n",
            "|    value_loss           | 3.46e-06   |\n",
            "----------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 591          |\n",
            "|    iterations           | 3797         |\n",
            "|    time_elapsed         | 6570         |\n",
            "|    total_timesteps      | 3888128      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0028646514 |\n",
            "|    clip_fraction        | 0.0918       |\n",
            "|    clip_range           | 0.1          |\n",
            "|    entropy_loss         | -1.61        |\n",
            "|    explained_variance   | 0.421        |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | -0.036       |\n",
            "|    n_updates            | 15184        |\n",
            "|    policy_gradient_loss | -0.00902     |\n",
            "|    value_loss           | 4.46e-06     |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 591          |\n",
            "|    iterations           | 3798         |\n",
            "|    time_elapsed         | 6572         |\n",
            "|    total_timesteps      | 3889152      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0051811077 |\n",
            "|    clip_fraction        | 0.126        |\n",
            "|    clip_range           | 0.1          |\n",
            "|    entropy_loss         | -1.58        |\n",
            "|    explained_variance   | -0.0407      |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | -0.038       |\n",
            "|    n_updates            | 15188        |\n",
            "|    policy_gradient_loss | -0.0135      |\n",
            "|    value_loss           | 7.15e-06     |\n",
            "------------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 591         |\n",
            "|    iterations           | 3799        |\n",
            "|    time_elapsed         | 6574        |\n",
            "|    total_timesteps      | 3890176     |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.002299164 |\n",
            "|    clip_fraction        | 0.104       |\n",
            "|    clip_range           | 0.1         |\n",
            "|    entropy_loss         | -1.64       |\n",
            "|    explained_variance   | 0.0479      |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | -0.0427     |\n",
            "|    n_updates            | 15192       |\n",
            "|    policy_gradient_loss | -0.0114     |\n",
            "|    value_loss           | 4.68e-06    |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 591         |\n",
            "|    iterations           | 3800        |\n",
            "|    time_elapsed         | 6576        |\n",
            "|    total_timesteps      | 3891200     |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.002999751 |\n",
            "|    clip_fraction        | 0.0703      |\n",
            "|    clip_range           | 0.1         |\n",
            "|    entropy_loss         | -1.53       |\n",
            "|    explained_variance   | -2.43       |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | -0.0375     |\n",
            "|    n_updates            | 15196       |\n",
            "|    policy_gradient_loss | -0.0124     |\n",
            "|    value_loss           | 7.64e-06    |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 591         |\n",
            "|    iterations           | 3801        |\n",
            "|    time_elapsed         | 6577        |\n",
            "|    total_timesteps      | 3892224     |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.002536831 |\n",
            "|    clip_fraction        | 0.0544      |\n",
            "|    clip_range           | 0.1         |\n",
            "|    entropy_loss         | -1.56       |\n",
            "|    explained_variance   | -1.96       |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | -0.0356     |\n",
            "|    n_updates            | 15200       |\n",
            "|    policy_gradient_loss | -0.00989    |\n",
            "|    value_loss           | 4.6e-06     |\n",
            "-----------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 591          |\n",
            "|    iterations           | 3802         |\n",
            "|    time_elapsed         | 6579         |\n",
            "|    total_timesteps      | 3893248      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0034255702 |\n",
            "|    clip_fraction        | 0.133        |\n",
            "|    clip_range           | 0.1          |\n",
            "|    entropy_loss         | -1.59        |\n",
            "|    explained_variance   | -8.94e-06    |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | -0.0254      |\n",
            "|    n_updates            | 15204        |\n",
            "|    policy_gradient_loss | -0.00694     |\n",
            "|    value_loss           | 0.0078       |\n",
            "------------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 591         |\n",
            "|    iterations           | 3803        |\n",
            "|    time_elapsed         | 6580        |\n",
            "|    total_timesteps      | 3894272     |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.002710761 |\n",
            "|    clip_fraction        | 0.0605      |\n",
            "|    clip_range           | 0.1         |\n",
            "|    entropy_loss         | -1.61       |\n",
            "|    explained_variance   | 0.00512     |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | -0.0143     |\n",
            "|    n_updates            | 15208       |\n",
            "|    policy_gradient_loss | -0.00574    |\n",
            "|    value_loss           | 0.0172      |\n",
            "-----------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 591          |\n",
            "|    iterations           | 3804         |\n",
            "|    time_elapsed         | 6582         |\n",
            "|    total_timesteps      | 3895296      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0029966058 |\n",
            "|    clip_fraction        | 0.124        |\n",
            "|    clip_range           | 0.1          |\n",
            "|    entropy_loss         | -1.56        |\n",
            "|    explained_variance   | 0.0967       |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | -0.0369      |\n",
            "|    n_updates            | 15212        |\n",
            "|    policy_gradient_loss | -0.0115      |\n",
            "|    value_loss           | 0.000103     |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 591          |\n",
            "|    iterations           | 3805         |\n",
            "|    time_elapsed         | 6584         |\n",
            "|    total_timesteps      | 3896320      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0029759896 |\n",
            "|    clip_fraction        | 0.11         |\n",
            "|    clip_range           | 0.1          |\n",
            "|    entropy_loss         | -1.52        |\n",
            "|    explained_variance   | -0.462       |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | -0.0285      |\n",
            "|    n_updates            | 15216        |\n",
            "|    policy_gradient_loss | -0.00815     |\n",
            "|    value_loss           | 6.23e-05     |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 591          |\n",
            "|    iterations           | 3806         |\n",
            "|    time_elapsed         | 6585         |\n",
            "|    total_timesteps      | 3897344      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0036199114 |\n",
            "|    clip_fraction        | 0.0884       |\n",
            "|    clip_range           | 0.1          |\n",
            "|    entropy_loss         | -1.62        |\n",
            "|    explained_variance   | 0.535        |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | -0.0425      |\n",
            "|    n_updates            | 15220        |\n",
            "|    policy_gradient_loss | -0.0121      |\n",
            "|    value_loss           | 2.24e-05     |\n",
            "------------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 591         |\n",
            "|    iterations           | 3807        |\n",
            "|    time_elapsed         | 6587        |\n",
            "|    total_timesteps      | 3898368     |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.003668398 |\n",
            "|    clip_fraction        | 0.0933      |\n",
            "|    clip_range           | 0.1         |\n",
            "|    entropy_loss         | -1.62       |\n",
            "|    explained_variance   | 0.512       |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | -0.0422     |\n",
            "|    n_updates            | 15224       |\n",
            "|    policy_gradient_loss | -0.00804    |\n",
            "|    value_loss           | 1.23e-05    |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 591         |\n",
            "|    iterations           | 3808        |\n",
            "|    time_elapsed         | 6589        |\n",
            "|    total_timesteps      | 3899392     |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.002434583 |\n",
            "|    clip_fraction        | 0.0913      |\n",
            "|    clip_range           | 0.1         |\n",
            "|    entropy_loss         | -1.58       |\n",
            "|    explained_variance   | 0.257       |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | -0.0239     |\n",
            "|    n_updates            | 15228       |\n",
            "|    policy_gradient_loss | -0.00881    |\n",
            "|    value_loss           | 1.52e-05    |\n",
            "-----------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 591          |\n",
            "|    iterations           | 3809         |\n",
            "|    time_elapsed         | 6591         |\n",
            "|    total_timesteps      | 3900416      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0017492337 |\n",
            "|    clip_fraction        | 0.103        |\n",
            "|    clip_range           | 0.1          |\n",
            "|    entropy_loss         | -1.52        |\n",
            "|    explained_variance   | 0.000822     |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | -0.0112      |\n",
            "|    n_updates            | 15232        |\n",
            "|    policy_gradient_loss | -0.00536     |\n",
            "|    value_loss           | 0.0251       |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 591          |\n",
            "|    iterations           | 3810         |\n",
            "|    time_elapsed         | 6592         |\n",
            "|    total_timesteps      | 3901440      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0063695814 |\n",
            "|    clip_fraction        | 0.127        |\n",
            "|    clip_range           | 0.1          |\n",
            "|    entropy_loss         | -1.47        |\n",
            "|    explained_variance   | -2.51        |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | -0.038       |\n",
            "|    n_updates            | 15236        |\n",
            "|    policy_gradient_loss | -0.00899     |\n",
            "|    value_loss           | 8.44e-05     |\n",
            "------------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 591         |\n",
            "|    iterations           | 3811        |\n",
            "|    time_elapsed         | 6594        |\n",
            "|    total_timesteps      | 3902464     |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.005105938 |\n",
            "|    clip_fraction        | 0.11        |\n",
            "|    clip_range           | 0.1         |\n",
            "|    entropy_loss         | -1.51       |\n",
            "|    explained_variance   | 0.0715      |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | -0.0356     |\n",
            "|    n_updates            | 15240       |\n",
            "|    policy_gradient_loss | -0.00926    |\n",
            "|    value_loss           | 2.86e-05    |\n",
            "-----------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 591          |\n",
            "|    iterations           | 3812         |\n",
            "|    time_elapsed         | 6595         |\n",
            "|    total_timesteps      | 3903488      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0028691404 |\n",
            "|    clip_fraction        | 0.137        |\n",
            "|    clip_range           | 0.1          |\n",
            "|    entropy_loss         | -1.58        |\n",
            "|    explained_variance   | 0.213        |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | -0.0282      |\n",
            "|    n_updates            | 15244        |\n",
            "|    policy_gradient_loss | -0.0097      |\n",
            "|    value_loss           | 1.83e-05     |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 591          |\n",
            "|    iterations           | 3813         |\n",
            "|    time_elapsed         | 6597         |\n",
            "|    total_timesteps      | 3904512      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0031681124 |\n",
            "|    clip_fraction        | 0.113        |\n",
            "|    clip_range           | 0.1          |\n",
            "|    entropy_loss         | -1.57        |\n",
            "|    explained_variance   | 0.482        |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | -0.0387      |\n",
            "|    n_updates            | 15248        |\n",
            "|    policy_gradient_loss | -0.0112      |\n",
            "|    value_loss           | 1.43e-05     |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 591          |\n",
            "|    iterations           | 3814         |\n",
            "|    time_elapsed         | 6598         |\n",
            "|    total_timesteps      | 3905536      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0044829426 |\n",
            "|    clip_fraction        | 0.102        |\n",
            "|    clip_range           | 0.1          |\n",
            "|    entropy_loss         | -1.54        |\n",
            "|    explained_variance   | 0.522        |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | -0.0399      |\n",
            "|    n_updates            | 15252        |\n",
            "|    policy_gradient_loss | -0.0116      |\n",
            "|    value_loss           | 9.66e-06     |\n",
            "------------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 591         |\n",
            "|    iterations           | 3815        |\n",
            "|    time_elapsed         | 6601        |\n",
            "|    total_timesteps      | 3906560     |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.004110629 |\n",
            "|    clip_fraction        | 0.116       |\n",
            "|    clip_range           | 0.1         |\n",
            "|    entropy_loss         | -1.45       |\n",
            "|    explained_variance   | -0.406      |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | -0.0353     |\n",
            "|    n_updates            | 15256       |\n",
            "|    policy_gradient_loss | -0.0135     |\n",
            "|    value_loss           | 1.21e-05    |\n",
            "-----------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 591          |\n",
            "|    iterations           | 3816         |\n",
            "|    time_elapsed         | 6602         |\n",
            "|    total_timesteps      | 3907584      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0025500273 |\n",
            "|    clip_fraction        | 0.15         |\n",
            "|    clip_range           | 0.1          |\n",
            "|    entropy_loss         | -1.57        |\n",
            "|    explained_variance   | -0.27        |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | -0.0325      |\n",
            "|    n_updates            | 15260        |\n",
            "|    policy_gradient_loss | -0.00856     |\n",
            "|    value_loss           | 1.18e-05     |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 591          |\n",
            "|    iterations           | 3817         |\n",
            "|    time_elapsed         | 6604         |\n",
            "|    total_timesteps      | 3908608      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0027685962 |\n",
            "|    clip_fraction        | 0.0864       |\n",
            "|    clip_range           | 0.1          |\n",
            "|    entropy_loss         | -1.59        |\n",
            "|    explained_variance   | 0.117        |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | -0.0364      |\n",
            "|    n_updates            | 15264        |\n",
            "|    policy_gradient_loss | -0.00917     |\n",
            "|    value_loss           | 6.15e-06     |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 591          |\n",
            "|    iterations           | 3818         |\n",
            "|    time_elapsed         | 6605         |\n",
            "|    total_timesteps      | 3909632      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0057330984 |\n",
            "|    clip_fraction        | 0.166        |\n",
            "|    clip_range           | 0.1          |\n",
            "|    entropy_loss         | -1.45        |\n",
            "|    explained_variance   | -1.81        |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | -0.0409      |\n",
            "|    n_updates            | 15268        |\n",
            "|    policy_gradient_loss | -0.0134      |\n",
            "|    value_loss           | 4.23e-05     |\n",
            "------------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 591         |\n",
            "|    iterations           | 3819        |\n",
            "|    time_elapsed         | 6607        |\n",
            "|    total_timesteps      | 3910656     |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.004316646 |\n",
            "|    clip_fraction        | 0.169       |\n",
            "|    clip_range           | 0.1         |\n",
            "|    entropy_loss         | -1.46       |\n",
            "|    explained_variance   | -2.43       |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | -0.044      |\n",
            "|    n_updates            | 15272       |\n",
            "|    policy_gradient_loss | -0.0128     |\n",
            "|    value_loss           | 2.27e-05    |\n",
            "-----------------------------------------\n",
            "----------------------------------------\n",
            "| time/                   |            |\n",
            "|    fps                  | 591        |\n",
            "|    iterations           | 3820       |\n",
            "|    time_elapsed         | 6608       |\n",
            "|    total_timesteps      | 3911680    |\n",
            "| train/                  |            |\n",
            "|    approx_kl            | 0.00504044 |\n",
            "|    clip_fraction        | 0.143      |\n",
            "|    clip_range           | 0.1        |\n",
            "|    entropy_loss         | -1.57      |\n",
            "|    explained_variance   | -2.42      |\n",
            "|    learning_rate        | 0.00025    |\n",
            "|    loss                 | -0.0481    |\n",
            "|    n_updates            | 15276      |\n",
            "|    policy_gradient_loss | -0.0136    |\n",
            "|    value_loss           | 1.92e-05   |\n",
            "----------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 591          |\n",
            "|    iterations           | 3821         |\n",
            "|    time_elapsed         | 6610         |\n",
            "|    total_timesteps      | 3912704      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0046288087 |\n",
            "|    clip_fraction        | 0.118        |\n",
            "|    clip_range           | 0.1          |\n",
            "|    entropy_loss         | -1.47        |\n",
            "|    explained_variance   | -1.35        |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | -0.0398      |\n",
            "|    n_updates            | 15280        |\n",
            "|    policy_gradient_loss | -0.0112      |\n",
            "|    value_loss           | 1.2e-05      |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 591          |\n",
            "|    iterations           | 3822         |\n",
            "|    time_elapsed         | 6611         |\n",
            "|    total_timesteps      | 3913728      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0042539346 |\n",
            "|    clip_fraction        | 0.13         |\n",
            "|    clip_range           | 0.1          |\n",
            "|    entropy_loss         | -1.47        |\n",
            "|    explained_variance   | -1.62        |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | -0.0376      |\n",
            "|    n_updates            | 15284        |\n",
            "|    policy_gradient_loss | -0.0116      |\n",
            "|    value_loss           | 1.08e-05     |\n",
            "------------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 591         |\n",
            "|    iterations           | 3823        |\n",
            "|    time_elapsed         | 6614        |\n",
            "|    total_timesteps      | 3914752     |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.004892975 |\n",
            "|    clip_fraction        | 0.144       |\n",
            "|    clip_range           | 0.1         |\n",
            "|    entropy_loss         | -1.42       |\n",
            "|    explained_variance   | -3.33       |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | -0.0293     |\n",
            "|    n_updates            | 15288       |\n",
            "|    policy_gradient_loss | -0.00942    |\n",
            "|    value_loss           | 1.27e-05    |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 591         |\n",
            "|    iterations           | 3824        |\n",
            "|    time_elapsed         | 6615        |\n",
            "|    total_timesteps      | 3915776     |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.004929676 |\n",
            "|    clip_fraction        | 0.139       |\n",
            "|    clip_range           | 0.1         |\n",
            "|    entropy_loss         | -1.38       |\n",
            "|    explained_variance   | -6.8        |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | -0.0318     |\n",
            "|    n_updates            | 15292       |\n",
            "|    policy_gradient_loss | -0.0111     |\n",
            "|    value_loss           | 1.22e-05    |\n",
            "-----------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 591          |\n",
            "|    iterations           | 3825         |\n",
            "|    time_elapsed         | 6617         |\n",
            "|    total_timesteps      | 3916800      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0047313496 |\n",
            "|    clip_fraction        | 0.151        |\n",
            "|    clip_range           | 0.1          |\n",
            "|    entropy_loss         | -1.44        |\n",
            "|    explained_variance   | -0.98        |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | -0.0428      |\n",
            "|    n_updates            | 15296        |\n",
            "|    policy_gradient_loss | -0.012       |\n",
            "|    value_loss           | 1.29e-05     |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 591          |\n",
            "|    iterations           | 3826         |\n",
            "|    time_elapsed         | 6619         |\n",
            "|    total_timesteps      | 3917824      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0047487207 |\n",
            "|    clip_fraction        | 0.146        |\n",
            "|    clip_range           | 0.1          |\n",
            "|    entropy_loss         | -1.44        |\n",
            "|    explained_variance   | -10.5        |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | -0.0388      |\n",
            "|    n_updates            | 15300        |\n",
            "|    policy_gradient_loss | -0.0129      |\n",
            "|    value_loss           | 1.47e-05     |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 591          |\n",
            "|    iterations           | 3827         |\n",
            "|    time_elapsed         | 6620         |\n",
            "|    total_timesteps      | 3918848      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0054348623 |\n",
            "|    clip_fraction        | 0.17         |\n",
            "|    clip_range           | 0.1          |\n",
            "|    entropy_loss         | -1.57        |\n",
            "|    explained_variance   | -2.47        |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | -0.0342      |\n",
            "|    n_updates            | 15304        |\n",
            "|    policy_gradient_loss | -0.00918     |\n",
            "|    value_loss           | 6.4e-06      |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 591          |\n",
            "|    iterations           | 3828         |\n",
            "|    time_elapsed         | 6622         |\n",
            "|    total_timesteps      | 3919872      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0033707118 |\n",
            "|    clip_fraction        | 0.153        |\n",
            "|    clip_range           | 0.1          |\n",
            "|    entropy_loss         | -1.56        |\n",
            "|    explained_variance   | -0.256       |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | -0.0251      |\n",
            "|    n_updates            | 15308        |\n",
            "|    policy_gradient_loss | -0.00877     |\n",
            "|    value_loss           | 3.4e-06      |\n",
            "------------------------------------------\n",
            "---------------------------------------\n",
            "| time/                   |           |\n",
            "|    fps                  | 591       |\n",
            "|    iterations           | 3829      |\n",
            "|    time_elapsed         | 6623      |\n",
            "|    total_timesteps      | 3920896   |\n",
            "| train/                  |           |\n",
            "|    approx_kl            | 0.0025664 |\n",
            "|    clip_fraction        | 0.093     |\n",
            "|    clip_range           | 0.1       |\n",
            "|    entropy_loss         | -1.53     |\n",
            "|    explained_variance   | -1.28     |\n",
            "|    learning_rate        | 0.00025   |\n",
            "|    loss                 | -0.0307   |\n",
            "|    n_updates            | 15312     |\n",
            "|    policy_gradient_loss | -0.00794  |\n",
            "|    value_loss           | 3.35e-06  |\n",
            "---------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 591         |\n",
            "|    iterations           | 3830        |\n",
            "|    time_elapsed         | 6625        |\n",
            "|    total_timesteps      | 3921920     |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.003906284 |\n",
            "|    clip_fraction        | 0.114       |\n",
            "|    clip_range           | 0.1         |\n",
            "|    entropy_loss         | -1.5        |\n",
            "|    explained_variance   | -2.47       |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | -0.042      |\n",
            "|    n_updates            | 15316       |\n",
            "|    policy_gradient_loss | -0.0148     |\n",
            "|    value_loss           | 4.02e-06    |\n",
            "-----------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 591          |\n",
            "|    iterations           | 3831         |\n",
            "|    time_elapsed         | 6628         |\n",
            "|    total_timesteps      | 3922944      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0037152746 |\n",
            "|    clip_fraction        | 0.131        |\n",
            "|    clip_range           | 0.1          |\n",
            "|    entropy_loss         | -1.45        |\n",
            "|    explained_variance   | -6.45        |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | -0.0332      |\n",
            "|    n_updates            | 15320        |\n",
            "|    policy_gradient_loss | -0.0118      |\n",
            "|    value_loss           | 6.17e-06     |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 591          |\n",
            "|    iterations           | 3832         |\n",
            "|    time_elapsed         | 6629         |\n",
            "|    total_timesteps      | 3923968      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0036509167 |\n",
            "|    clip_fraction        | 0.128        |\n",
            "|    clip_range           | 0.1          |\n",
            "|    entropy_loss         | -1.46        |\n",
            "|    explained_variance   | -4.87        |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | -0.0374      |\n",
            "|    n_updates            | 15324        |\n",
            "|    policy_gradient_loss | -0.0108      |\n",
            "|    value_loss           | 7.41e-06     |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 591          |\n",
            "|    iterations           | 3833         |\n",
            "|    time_elapsed         | 6631         |\n",
            "|    total_timesteps      | 3924992      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0034072031 |\n",
            "|    clip_fraction        | 0.112        |\n",
            "|    clip_range           | 0.1          |\n",
            "|    entropy_loss         | -1.51        |\n",
            "|    explained_variance   | -1.43        |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | -0.0282      |\n",
            "|    n_updates            | 15328        |\n",
            "|    policy_gradient_loss | -0.00673     |\n",
            "|    value_loss           | 2.72e-06     |\n",
            "------------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 591         |\n",
            "|    iterations           | 3834        |\n",
            "|    time_elapsed         | 6632        |\n",
            "|    total_timesteps      | 3926016     |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.004953472 |\n",
            "|    clip_fraction        | 0.155       |\n",
            "|    clip_range           | 0.1         |\n",
            "|    entropy_loss         | -1.5        |\n",
            "|    explained_variance   | -2.27       |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | -0.0357     |\n",
            "|    n_updates            | 15332       |\n",
            "|    policy_gradient_loss | -0.0103     |\n",
            "|    value_loss           | 4.24e-06    |\n",
            "-----------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 591          |\n",
            "|    iterations           | 3835         |\n",
            "|    time_elapsed         | 6634         |\n",
            "|    total_timesteps      | 3927040      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0029434497 |\n",
            "|    clip_fraction        | 0.111        |\n",
            "|    clip_range           | 0.1          |\n",
            "|    entropy_loss         | -1.52        |\n",
            "|    explained_variance   | -0.0132      |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | -0.0236      |\n",
            "|    n_updates            | 15336        |\n",
            "|    policy_gradient_loss | -0.00719     |\n",
            "|    value_loss           | 0.00706      |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 591          |\n",
            "|    iterations           | 3836         |\n",
            "|    time_elapsed         | 6636         |\n",
            "|    total_timesteps      | 3928064      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0017232527 |\n",
            "|    clip_fraction        | 0.101        |\n",
            "|    clip_range           | 0.1          |\n",
            "|    entropy_loss         | -1.6         |\n",
            "|    explained_variance   | -0.668       |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | -0.0357      |\n",
            "|    n_updates            | 15340        |\n",
            "|    policy_gradient_loss | -0.0104      |\n",
            "|    value_loss           | 4.78e-05     |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 591          |\n",
            "|    iterations           | 3837         |\n",
            "|    time_elapsed         | 6637         |\n",
            "|    total_timesteps      | 3929088      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0036217477 |\n",
            "|    clip_fraction        | 0.116        |\n",
            "|    clip_range           | 0.1          |\n",
            "|    entropy_loss         | -1.54        |\n",
            "|    explained_variance   | -1.96        |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | -0.0335      |\n",
            "|    n_updates            | 15344        |\n",
            "|    policy_gradient_loss | -0.0116      |\n",
            "|    value_loss           | 0.00012      |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 591          |\n",
            "|    iterations           | 3838         |\n",
            "|    time_elapsed         | 6639         |\n",
            "|    total_timesteps      | 3930112      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0058446047 |\n",
            "|    clip_fraction        | 0.128        |\n",
            "|    clip_range           | 0.1          |\n",
            "|    entropy_loss         | -1.57        |\n",
            "|    explained_variance   | -0.542       |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | -0.0437      |\n",
            "|    n_updates            | 15348        |\n",
            "|    policy_gradient_loss | -0.0128      |\n",
            "|    value_loss           | 2.96e-05     |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 591          |\n",
            "|    iterations           | 3839         |\n",
            "|    time_elapsed         | 6641         |\n",
            "|    total_timesteps      | 3931136      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0031470954 |\n",
            "|    clip_fraction        | 0.0781       |\n",
            "|    clip_range           | 0.1          |\n",
            "|    entropy_loss         | -1.61        |\n",
            "|    explained_variance   | -0.851       |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | -0.0438      |\n",
            "|    n_updates            | 15352        |\n",
            "|    policy_gradient_loss | -0.0115      |\n",
            "|    value_loss           | 5.31e-05     |\n",
            "------------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 591         |\n",
            "|    iterations           | 3840        |\n",
            "|    time_elapsed         | 6643        |\n",
            "|    total_timesteps      | 3932160     |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.003021702 |\n",
            "|    clip_fraction        | 0.114       |\n",
            "|    clip_range           | 0.1         |\n",
            "|    entropy_loss         | -1.59       |\n",
            "|    explained_variance   | 0.0782      |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | -0.0413     |\n",
            "|    n_updates            | 15356       |\n",
            "|    policy_gradient_loss | -0.0113     |\n",
            "|    value_loss           | 3.23e-05    |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 591         |\n",
            "|    iterations           | 3841        |\n",
            "|    time_elapsed         | 6644        |\n",
            "|    total_timesteps      | 3933184     |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.004056387 |\n",
            "|    clip_fraction        | 0.116       |\n",
            "|    clip_range           | 0.1         |\n",
            "|    entropy_loss         | -1.59       |\n",
            "|    explained_variance   | -1.34       |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | -0.0384     |\n",
            "|    n_updates            | 15360       |\n",
            "|    policy_gradient_loss | -0.00987    |\n",
            "|    value_loss           | 2.23e-05    |\n",
            "-----------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 591          |\n",
            "|    iterations           | 3842         |\n",
            "|    time_elapsed         | 6646         |\n",
            "|    total_timesteps      | 3934208      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0025700524 |\n",
            "|    clip_fraction        | 0.11         |\n",
            "|    clip_range           | 0.1          |\n",
            "|    entropy_loss         | -1.68        |\n",
            "|    explained_variance   | -0.54        |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | -0.0343      |\n",
            "|    n_updates            | 15364        |\n",
            "|    policy_gradient_loss | -0.00757     |\n",
            "|    value_loss           | 2.5e-05      |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 591          |\n",
            "|    iterations           | 3843         |\n",
            "|    time_elapsed         | 6647         |\n",
            "|    total_timesteps      | 3935232      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0033646056 |\n",
            "|    clip_fraction        | 0.0681       |\n",
            "|    clip_range           | 0.1          |\n",
            "|    entropy_loss         | -1.65        |\n",
            "|    explained_variance   | -2.78        |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | -0.0235      |\n",
            "|    n_updates            | 15368        |\n",
            "|    policy_gradient_loss | -0.00651     |\n",
            "|    value_loss           | 0.000505     |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 591          |\n",
            "|    iterations           | 3844         |\n",
            "|    time_elapsed         | 6649         |\n",
            "|    total_timesteps      | 3936256      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0032039843 |\n",
            "|    clip_fraction        | 0.0847       |\n",
            "|    clip_range           | 0.1          |\n",
            "|    entropy_loss         | -1.56        |\n",
            "|    explained_variance   | -1.82        |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | -0.0276      |\n",
            "|    n_updates            | 15372        |\n",
            "|    policy_gradient_loss | -0.00794     |\n",
            "|    value_loss           | 0.00013      |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 591          |\n",
            "|    iterations           | 3845         |\n",
            "|    time_elapsed         | 6651         |\n",
            "|    total_timesteps      | 3937280      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0018385474 |\n",
            "|    clip_fraction        | 0.0657       |\n",
            "|    clip_range           | 0.1          |\n",
            "|    entropy_loss         | -1.49        |\n",
            "|    explained_variance   | -0.00717     |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | -0.00195     |\n",
            "|    n_updates            | 15376        |\n",
            "|    policy_gradient_loss | -0.00227     |\n",
            "|    value_loss           | 0.0169       |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 591          |\n",
            "|    iterations           | 3846         |\n",
            "|    time_elapsed         | 6653         |\n",
            "|    total_timesteps      | 3938304      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0023361149 |\n",
            "|    clip_fraction        | 0.0789       |\n",
            "|    clip_range           | 0.1          |\n",
            "|    entropy_loss         | -1.47        |\n",
            "|    explained_variance   | 0.0109       |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | -0.0286      |\n",
            "|    n_updates            | 15380        |\n",
            "|    policy_gradient_loss | -0.00704     |\n",
            "|    value_loss           | 0.0078       |\n",
            "------------------------------------------\n",
            "----------------------------------------\n",
            "| time/                   |            |\n",
            "|    fps                  | 591        |\n",
            "|    iterations           | 3847       |\n",
            "|    time_elapsed         | 6655       |\n",
            "|    total_timesteps      | 3939328    |\n",
            "| train/                  |            |\n",
            "|    approx_kl            | 0.00462579 |\n",
            "|    clip_fraction        | 0.127      |\n",
            "|    clip_range           | 0.1        |\n",
            "|    entropy_loss         | -1.51      |\n",
            "|    explained_variance   | -1.41      |\n",
            "|    learning_rate        | 0.00025    |\n",
            "|    loss                 | -0.034     |\n",
            "|    n_updates            | 15384      |\n",
            "|    policy_gradient_loss | -0.0125    |\n",
            "|    value_loss           | 0.000138   |\n",
            "----------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 591          |\n",
            "|    iterations           | 3848         |\n",
            "|    time_elapsed         | 6656         |\n",
            "|    total_timesteps      | 3940352      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0045361426 |\n",
            "|    clip_fraction        | 0.111        |\n",
            "|    clip_range           | 0.1          |\n",
            "|    entropy_loss         | -1.55        |\n",
            "|    explained_variance   | -1.42        |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | -0.0364      |\n",
            "|    n_updates            | 15388        |\n",
            "|    policy_gradient_loss | -0.0122      |\n",
            "|    value_loss           | 0.000129     |\n",
            "------------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 591         |\n",
            "|    iterations           | 3849        |\n",
            "|    time_elapsed         | 6658        |\n",
            "|    total_timesteps      | 3941376     |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.003705526 |\n",
            "|    clip_fraction        | 0.134       |\n",
            "|    clip_range           | 0.1         |\n",
            "|    entropy_loss         | -1.55       |\n",
            "|    explained_variance   | -3.13       |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | -0.0477     |\n",
            "|    n_updates            | 15392       |\n",
            "|    policy_gradient_loss | -0.0129     |\n",
            "|    value_loss           | 3.83e-05    |\n",
            "-----------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 591          |\n",
            "|    iterations           | 3850         |\n",
            "|    time_elapsed         | 6659         |\n",
            "|    total_timesteps      | 3942400      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0041521746 |\n",
            "|    clip_fraction        | 0.0981       |\n",
            "|    clip_range           | 0.1          |\n",
            "|    entropy_loss         | -1.56        |\n",
            "|    explained_variance   | 0.0376       |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | -0.0272      |\n",
            "|    n_updates            | 15396        |\n",
            "|    policy_gradient_loss | -0.00788     |\n",
            "|    value_loss           | 0.00763      |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 591          |\n",
            "|    iterations           | 3851         |\n",
            "|    time_elapsed         | 6661         |\n",
            "|    total_timesteps      | 3943424      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0038568429 |\n",
            "|    clip_fraction        | 0.115        |\n",
            "|    clip_range           | 0.1          |\n",
            "|    entropy_loss         | -1.59        |\n",
            "|    explained_variance   | 0.0136       |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | -0.038       |\n",
            "|    n_updates            | 15400        |\n",
            "|    policy_gradient_loss | -0.0159      |\n",
            "|    value_loss           | 0.000147     |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 591          |\n",
            "|    iterations           | 3852         |\n",
            "|    time_elapsed         | 6663         |\n",
            "|    total_timesteps      | 3944448      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0035715392 |\n",
            "|    clip_fraction        | 0.115        |\n",
            "|    clip_range           | 0.1          |\n",
            "|    entropy_loss         | -1.61        |\n",
            "|    explained_variance   | -0.785       |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | -0.0387      |\n",
            "|    n_updates            | 15404        |\n",
            "|    policy_gradient_loss | -0.0125      |\n",
            "|    value_loss           | 0.000173     |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 591          |\n",
            "|    iterations           | 3853         |\n",
            "|    time_elapsed         | 6664         |\n",
            "|    total_timesteps      | 3945472      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0040704357 |\n",
            "|    clip_fraction        | 0.121        |\n",
            "|    clip_range           | 0.1          |\n",
            "|    entropy_loss         | -1.54        |\n",
            "|    explained_variance   | -1.72        |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | -0.0407      |\n",
            "|    n_updates            | 15408        |\n",
            "|    policy_gradient_loss | -0.012       |\n",
            "|    value_loss           | 0.000216     |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 591          |\n",
            "|    iterations           | 3854         |\n",
            "|    time_elapsed         | 6667         |\n",
            "|    total_timesteps      | 3946496      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0025707653 |\n",
            "|    clip_fraction        | 0.0464       |\n",
            "|    clip_range           | 0.1          |\n",
            "|    entropy_loss         | -1.49        |\n",
            "|    explained_variance   | -0.00709     |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | -0.023       |\n",
            "|    n_updates            | 15412        |\n",
            "|    policy_gradient_loss | -0.00599     |\n",
            "|    value_loss           | 0.0161       |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 591          |\n",
            "|    iterations           | 3855         |\n",
            "|    time_elapsed         | 6668         |\n",
            "|    total_timesteps      | 3947520      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0058745923 |\n",
            "|    clip_fraction        | 0.151        |\n",
            "|    clip_range           | 0.1          |\n",
            "|    entropy_loss         | -1.51        |\n",
            "|    explained_variance   | -6.08        |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | -0.0453      |\n",
            "|    n_updates            | 15416        |\n",
            "|    policy_gradient_loss | -0.0183      |\n",
            "|    value_loss           | 6.54e-05     |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 591          |\n",
            "|    iterations           | 3856         |\n",
            "|    time_elapsed         | 6670         |\n",
            "|    total_timesteps      | 3948544      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0052552945 |\n",
            "|    clip_fraction        | 0.154        |\n",
            "|    clip_range           | 0.1          |\n",
            "|    entropy_loss         | -1.51        |\n",
            "|    explained_variance   | -6.48        |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | -0.0425      |\n",
            "|    n_updates            | 15420        |\n",
            "|    policy_gradient_loss | -0.0129      |\n",
            "|    value_loss           | 3.69e-05     |\n",
            "------------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 591         |\n",
            "|    iterations           | 3857        |\n",
            "|    time_elapsed         | 6671        |\n",
            "|    total_timesteps      | 3949568     |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.007377058 |\n",
            "|    clip_fraction        | 0.18        |\n",
            "|    clip_range           | 0.1         |\n",
            "|    entropy_loss         | -1.47       |\n",
            "|    explained_variance   | 0.0215      |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | -0.0244     |\n",
            "|    n_updates            | 15424       |\n",
            "|    policy_gradient_loss | -0.00891    |\n",
            "|    value_loss           | 0.00804     |\n",
            "-----------------------------------------\n",
            "----------------------------------------\n",
            "| time/                   |            |\n",
            "|    fps                  | 591        |\n",
            "|    iterations           | 3858       |\n",
            "|    time_elapsed         | 6673       |\n",
            "|    total_timesteps      | 3950592    |\n",
            "| train/                  |            |\n",
            "|    approx_kl            | 0.00515824 |\n",
            "|    clip_fraction        | 0.132      |\n",
            "|    clip_range           | 0.1        |\n",
            "|    entropy_loss         | -1.57      |\n",
            "|    explained_variance   | -1.62      |\n",
            "|    learning_rate        | 0.00025    |\n",
            "|    loss                 | -0.0454    |\n",
            "|    n_updates            | 15428      |\n",
            "|    policy_gradient_loss | -0.0139    |\n",
            "|    value_loss           | 9.44e-05   |\n",
            "----------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 591          |\n",
            "|    iterations           | 3859         |\n",
            "|    time_elapsed         | 6675         |\n",
            "|    total_timesteps      | 3951616      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0033093658 |\n",
            "|    clip_fraction        | 0.141        |\n",
            "|    clip_range           | 0.1          |\n",
            "|    entropy_loss         | -1.66        |\n",
            "|    explained_variance   | -1.53        |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | -0.0352      |\n",
            "|    n_updates            | 15432        |\n",
            "|    policy_gradient_loss | -0.0123      |\n",
            "|    value_loss           | 4.82e-05     |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 592          |\n",
            "|    iterations           | 3860         |\n",
            "|    time_elapsed         | 6676         |\n",
            "|    total_timesteps      | 3952640      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0049955174 |\n",
            "|    clip_fraction        | 0.12         |\n",
            "|    clip_range           | 0.1          |\n",
            "|    entropy_loss         | -1.57        |\n",
            "|    explained_variance   | -2.1         |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | -0.0428      |\n",
            "|    n_updates            | 15436        |\n",
            "|    policy_gradient_loss | -0.0148      |\n",
            "|    value_loss           | 6.74e-05     |\n",
            "------------------------------------------\n",
            "----------------------------------------\n",
            "| time/                   |            |\n",
            "|    fps                  | 591        |\n",
            "|    iterations           | 3861       |\n",
            "|    time_elapsed         | 6678       |\n",
            "|    total_timesteps      | 3953664    |\n",
            "| train/                  |            |\n",
            "|    approx_kl            | 0.00444736 |\n",
            "|    clip_fraction        | 0.103      |\n",
            "|    clip_range           | 0.1        |\n",
            "|    entropy_loss         | -1.58      |\n",
            "|    explained_variance   | -5         |\n",
            "|    learning_rate        | 0.00025    |\n",
            "|    loss                 | -0.0482    |\n",
            "|    n_updates            | 15440      |\n",
            "|    policy_gradient_loss | -0.016     |\n",
            "|    value_loss           | 4.56e-05   |\n",
            "----------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 591         |\n",
            "|    iterations           | 3862        |\n",
            "|    time_elapsed         | 6680        |\n",
            "|    total_timesteps      | 3954688     |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.005770167 |\n",
            "|    clip_fraction        | 0.153       |\n",
            "|    clip_range           | 0.1         |\n",
            "|    entropy_loss         | -1.58       |\n",
            "|    explained_variance   | 0.0197      |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | -0.0241     |\n",
            "|    n_updates            | 15444       |\n",
            "|    policy_gradient_loss | -0.00805    |\n",
            "|    value_loss           | 0.00793     |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 591         |\n",
            "|    iterations           | 3863        |\n",
            "|    time_elapsed         | 6682        |\n",
            "|    total_timesteps      | 3955712     |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.003008794 |\n",
            "|    clip_fraction        | 0.0774      |\n",
            "|    clip_range           | 0.1         |\n",
            "|    entropy_loss         | -1.61       |\n",
            "|    explained_variance   | -2.43       |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | -0.0361     |\n",
            "|    n_updates            | 15448       |\n",
            "|    policy_gradient_loss | -0.00632    |\n",
            "|    value_loss           | 0.000145    |\n",
            "-----------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 591          |\n",
            "|    iterations           | 3864         |\n",
            "|    time_elapsed         | 6684         |\n",
            "|    total_timesteps      | 3956736      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0035507802 |\n",
            "|    clip_fraction        | 0.129        |\n",
            "|    clip_range           | 0.1          |\n",
            "|    entropy_loss         | -1.63        |\n",
            "|    explained_variance   | -1.26        |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | -0.0333      |\n",
            "|    n_updates            | 15452        |\n",
            "|    policy_gradient_loss | -0.0103      |\n",
            "|    value_loss           | 6.56e-05     |\n",
            "------------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 591         |\n",
            "|    iterations           | 3865        |\n",
            "|    time_elapsed         | 6685        |\n",
            "|    total_timesteps      | 3957760     |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.004170888 |\n",
            "|    clip_fraction        | 0.0925      |\n",
            "|    clip_range           | 0.1         |\n",
            "|    entropy_loss         | -1.63       |\n",
            "|    explained_variance   | -0.87       |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | -0.0402     |\n",
            "|    n_updates            | 15456       |\n",
            "|    policy_gradient_loss | -0.0126     |\n",
            "|    value_loss           | 5.97e-05    |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 591         |\n",
            "|    iterations           | 3866        |\n",
            "|    time_elapsed         | 6687        |\n",
            "|    total_timesteps      | 3958784     |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.003996251 |\n",
            "|    clip_fraction        | 0.115       |\n",
            "|    clip_range           | 0.1         |\n",
            "|    entropy_loss         | -1.59       |\n",
            "|    explained_variance   | -2.95       |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | -0.0364     |\n",
            "|    n_updates            | 15460       |\n",
            "|    policy_gradient_loss | -0.0137     |\n",
            "|    value_loss           | 4.18e-05    |\n",
            "-----------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 591          |\n",
            "|    iterations           | 3867         |\n",
            "|    time_elapsed         | 6688         |\n",
            "|    total_timesteps      | 3959808      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0026334887 |\n",
            "|    clip_fraction        | 0.115        |\n",
            "|    clip_range           | 0.1          |\n",
            "|    entropy_loss         | -1.62        |\n",
            "|    explained_variance   | -2.15        |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | -0.0428      |\n",
            "|    n_updates            | 15464        |\n",
            "|    policy_gradient_loss | -0.0127      |\n",
            "|    value_loss           | 2.11e-05     |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 592          |\n",
            "|    iterations           | 3868         |\n",
            "|    time_elapsed         | 6690         |\n",
            "|    total_timesteps      | 3960832      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0048975134 |\n",
            "|    clip_fraction        | 0.126        |\n",
            "|    clip_range           | 0.1          |\n",
            "|    entropy_loss         | -1.62        |\n",
            "|    explained_variance   | -1.55        |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | -0.0543      |\n",
            "|    n_updates            | 15468        |\n",
            "|    policy_gradient_loss | -0.0169      |\n",
            "|    value_loss           | 2.87e-05     |\n",
            "------------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 591         |\n",
            "|    iterations           | 3869        |\n",
            "|    time_elapsed         | 6692        |\n",
            "|    total_timesteps      | 3961856     |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.004030805 |\n",
            "|    clip_fraction        | 0.0999      |\n",
            "|    clip_range           | 0.1         |\n",
            "|    entropy_loss         | -1.64       |\n",
            "|    explained_variance   | -1.93       |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | -0.0385     |\n",
            "|    n_updates            | 15472       |\n",
            "|    policy_gradient_loss | -0.0144     |\n",
            "|    value_loss           | 2.03e-05    |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 591         |\n",
            "|    iterations           | 3870        |\n",
            "|    time_elapsed         | 6694        |\n",
            "|    total_timesteps      | 3962880     |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.004229695 |\n",
            "|    clip_fraction        | 0.093       |\n",
            "|    clip_range           | 0.1         |\n",
            "|    entropy_loss         | -1.6        |\n",
            "|    explained_variance   | -1.18       |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | -0.0388     |\n",
            "|    n_updates            | 15476       |\n",
            "|    policy_gradient_loss | -0.013      |\n",
            "|    value_loss           | 3.32e-05    |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 591         |\n",
            "|    iterations           | 3871        |\n",
            "|    time_elapsed         | 6696        |\n",
            "|    total_timesteps      | 3963904     |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.002443403 |\n",
            "|    clip_fraction        | 0.146       |\n",
            "|    clip_range           | 0.1         |\n",
            "|    entropy_loss         | -1.65       |\n",
            "|    explained_variance   | -0.72       |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | -0.0441     |\n",
            "|    n_updates            | 15480       |\n",
            "|    policy_gradient_loss | -0.0131     |\n",
            "|    value_loss           | 1.45e-05    |\n",
            "-----------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 591          |\n",
            "|    iterations           | 3872         |\n",
            "|    time_elapsed         | 6697         |\n",
            "|    total_timesteps      | 3964928      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0039115828 |\n",
            "|    clip_fraction        | 0.121        |\n",
            "|    clip_range           | 0.1          |\n",
            "|    entropy_loss         | -1.68        |\n",
            "|    explained_variance   | -2.74        |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | -0.029       |\n",
            "|    n_updates            | 15484        |\n",
            "|    policy_gradient_loss | -0.0108      |\n",
            "|    value_loss           | 1.47e-05     |\n",
            "------------------------------------------\n",
            "----------------------------------------\n",
            "| time/                   |            |\n",
            "|    fps                  | 591        |\n",
            "|    iterations           | 3873       |\n",
            "|    time_elapsed         | 6699       |\n",
            "|    total_timesteps      | 3965952    |\n",
            "| train/                  |            |\n",
            "|    approx_kl            | 0.00411854 |\n",
            "|    clip_fraction        | 0.162      |\n",
            "|    clip_range           | 0.1        |\n",
            "|    entropy_loss         | -1.64      |\n",
            "|    explained_variance   | -5.57      |\n",
            "|    learning_rate        | 0.00025    |\n",
            "|    loss                 | -0.034     |\n",
            "|    n_updates            | 15488      |\n",
            "|    policy_gradient_loss | -0.0107    |\n",
            "|    value_loss           | 1.42e-05   |\n",
            "----------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 591          |\n",
            "|    iterations           | 3874         |\n",
            "|    time_elapsed         | 6700         |\n",
            "|    total_timesteps      | 3966976      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0034514635 |\n",
            "|    clip_fraction        | 0.0979       |\n",
            "|    clip_range           | 0.1          |\n",
            "|    entropy_loss         | -1.57        |\n",
            "|    explained_variance   | -0.372       |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | -0.045       |\n",
            "|    n_updates            | 15492        |\n",
            "|    policy_gradient_loss | -0.0127      |\n",
            "|    value_loss           | 3.3e-05      |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 592          |\n",
            "|    iterations           | 3875         |\n",
            "|    time_elapsed         | 6702         |\n",
            "|    total_timesteps      | 3968000      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0024608336 |\n",
            "|    clip_fraction        | 0.0859       |\n",
            "|    clip_range           | 0.1          |\n",
            "|    entropy_loss         | -1.65        |\n",
            "|    explained_variance   | -0.54        |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | -0.0396      |\n",
            "|    n_updates            | 15496        |\n",
            "|    policy_gradient_loss | -0.0128      |\n",
            "|    value_loss           | 9.29e-06     |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 592          |\n",
            "|    iterations           | 3876         |\n",
            "|    time_elapsed         | 6704         |\n",
            "|    total_timesteps      | 3969024      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0033843548 |\n",
            "|    clip_fraction        | 0.108        |\n",
            "|    clip_range           | 0.1          |\n",
            "|    entropy_loss         | -1.66        |\n",
            "|    explained_variance   | -0.857       |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | -0.0426      |\n",
            "|    n_updates            | 15500        |\n",
            "|    policy_gradient_loss | -0.013       |\n",
            "|    value_loss           | 9.82e-06     |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 591          |\n",
            "|    iterations           | 3877         |\n",
            "|    time_elapsed         | 6706         |\n",
            "|    total_timesteps      | 3970048      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0033661835 |\n",
            "|    clip_fraction        | 0.127        |\n",
            "|    clip_range           | 0.1          |\n",
            "|    entropy_loss         | -1.65        |\n",
            "|    explained_variance   | -0.00551     |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | -0.0266      |\n",
            "|    n_updates            | 15504        |\n",
            "|    policy_gradient_loss | -0.00626     |\n",
            "|    value_loss           | 0.00798      |\n",
            "------------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 591         |\n",
            "|    iterations           | 3878        |\n",
            "|    time_elapsed         | 6708        |\n",
            "|    total_timesteps      | 3971072     |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.003237445 |\n",
            "|    clip_fraction        | 0.0928      |\n",
            "|    clip_range           | 0.1         |\n",
            "|    entropy_loss         | -1.7        |\n",
            "|    explained_variance   | 0.469       |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | -0.0465     |\n",
            "|    n_updates            | 15508       |\n",
            "|    policy_gradient_loss | -0.0135     |\n",
            "|    value_loss           | 8.79e-05    |\n",
            "-----------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 591          |\n",
            "|    iterations           | 3879         |\n",
            "|    time_elapsed         | 6709         |\n",
            "|    total_timesteps      | 3972096      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0035434181 |\n",
            "|    clip_fraction        | 0.0969       |\n",
            "|    clip_range           | 0.1          |\n",
            "|    entropy_loss         | -1.7         |\n",
            "|    explained_variance   | -0.146       |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | -0.0402      |\n",
            "|    n_updates            | 15512        |\n",
            "|    policy_gradient_loss | -0.00969     |\n",
            "|    value_loss           | 0.000122     |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 591          |\n",
            "|    iterations           | 3880         |\n",
            "|    time_elapsed         | 6711         |\n",
            "|    total_timesteps      | 3973120      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0044115307 |\n",
            "|    clip_fraction        | 0.114        |\n",
            "|    clip_range           | 0.1          |\n",
            "|    entropy_loss         | -1.67        |\n",
            "|    explained_variance   | -1.34        |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | -0.0447      |\n",
            "|    n_updates            | 15516        |\n",
            "|    policy_gradient_loss | -0.0143      |\n",
            "|    value_loss           | 4.86e-05     |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 592          |\n",
            "|    iterations           | 3881         |\n",
            "|    time_elapsed         | 6713         |\n",
            "|    total_timesteps      | 3974144      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0030234319 |\n",
            "|    clip_fraction        | 0.075        |\n",
            "|    clip_range           | 0.1          |\n",
            "|    entropy_loss         | -1.69        |\n",
            "|    explained_variance   | -1.13        |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | -0.0415      |\n",
            "|    n_updates            | 15520        |\n",
            "|    policy_gradient_loss | -0.0121      |\n",
            "|    value_loss           | 2.3e-05      |\n",
            "------------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 592         |\n",
            "|    iterations           | 3882        |\n",
            "|    time_elapsed         | 6714        |\n",
            "|    total_timesteps      | 3975168     |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.004438804 |\n",
            "|    clip_fraction        | 0.109       |\n",
            "|    clip_range           | 0.1         |\n",
            "|    entropy_loss         | -1.66       |\n",
            "|    explained_variance   | -1.61       |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | -0.0471     |\n",
            "|    n_updates            | 15524       |\n",
            "|    policy_gradient_loss | -0.0144     |\n",
            "|    value_loss           | 1.63e-05    |\n",
            "-----------------------------------------\n",
            "----------------------------------------\n",
            "| time/                   |            |\n",
            "|    fps                  | 592        |\n",
            "|    iterations           | 3883       |\n",
            "|    time_elapsed         | 6716       |\n",
            "|    total_timesteps      | 3976192    |\n",
            "| train/                  |            |\n",
            "|    approx_kl            | 0.00329992 |\n",
            "|    clip_fraction        | 0.0815     |\n",
            "|    clip_range           | 0.1        |\n",
            "|    entropy_loss         | -1.73      |\n",
            "|    explained_variance   | -0.0661    |\n",
            "|    learning_rate        | 0.00025    |\n",
            "|    loss                 | -0.0446    |\n",
            "|    n_updates            | 15528      |\n",
            "|    policy_gradient_loss | -0.0116    |\n",
            "|    value_loss           | 1.47e-05   |\n",
            "----------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 592          |\n",
            "|    iterations           | 3884         |\n",
            "|    time_elapsed         | 6718         |\n",
            "|    total_timesteps      | 3977216      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0044160886 |\n",
            "|    clip_fraction        | 0.111        |\n",
            "|    clip_range           | 0.1          |\n",
            "|    entropy_loss         | -1.67        |\n",
            "|    explained_variance   | -0.478       |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | -0.0426      |\n",
            "|    n_updates            | 15532        |\n",
            "|    policy_gradient_loss | -0.0142      |\n",
            "|    value_loss           | 2.11e-05     |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 591          |\n",
            "|    iterations           | 3885         |\n",
            "|    time_elapsed         | 6720         |\n",
            "|    total_timesteps      | 3978240      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0035552252 |\n",
            "|    clip_fraction        | 0.082        |\n",
            "|    clip_range           | 0.1          |\n",
            "|    entropy_loss         | -1.7         |\n",
            "|    explained_variance   | -2.43        |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | -0.0394      |\n",
            "|    n_updates            | 15536        |\n",
            "|    policy_gradient_loss | -0.0114      |\n",
            "|    value_loss           | 1.85e-05     |\n",
            "------------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 591         |\n",
            "|    iterations           | 3886        |\n",
            "|    time_elapsed         | 6722        |\n",
            "|    total_timesteps      | 3979264     |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.004183855 |\n",
            "|    clip_fraction        | 0.107       |\n",
            "|    clip_range           | 0.1         |\n",
            "|    entropy_loss         | -1.63       |\n",
            "|    explained_variance   | -2.73       |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | -0.0492     |\n",
            "|    n_updates            | 15540       |\n",
            "|    policy_gradient_loss | -0.0157     |\n",
            "|    value_loss           | 3.96e-05    |\n",
            "-----------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 591          |\n",
            "|    iterations           | 3887         |\n",
            "|    time_elapsed         | 6723         |\n",
            "|    total_timesteps      | 3980288      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0032699462 |\n",
            "|    clip_fraction        | 0.0911       |\n",
            "|    clip_range           | 0.1          |\n",
            "|    entropy_loss         | -1.68        |\n",
            "|    explained_variance   | -1.01        |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | -0.0454      |\n",
            "|    n_updates            | 15544        |\n",
            "|    policy_gradient_loss | -0.0118      |\n",
            "|    value_loss           | 2.01e-05     |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 591          |\n",
            "|    iterations           | 3888         |\n",
            "|    time_elapsed         | 6725         |\n",
            "|    total_timesteps      | 3981312      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0032198217 |\n",
            "|    clip_fraction        | 0.0964       |\n",
            "|    clip_range           | 0.1          |\n",
            "|    entropy_loss         | -1.67        |\n",
            "|    explained_variance   | -1.57        |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | -0.0562      |\n",
            "|    n_updates            | 15548        |\n",
            "|    policy_gradient_loss | -0.0156      |\n",
            "|    value_loss           | 2.16e-05     |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 592          |\n",
            "|    iterations           | 3889         |\n",
            "|    time_elapsed         | 6726         |\n",
            "|    total_timesteps      | 3982336      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0034200705 |\n",
            "|    clip_fraction        | 0.105        |\n",
            "|    clip_range           | 0.1          |\n",
            "|    entropy_loss         | -1.69        |\n",
            "|    explained_variance   | -2.25        |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | -0.0414      |\n",
            "|    n_updates            | 15552        |\n",
            "|    policy_gradient_loss | -0.0151      |\n",
            "|    value_loss           | 1.19e-05     |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 592          |\n",
            "|    iterations           | 3890         |\n",
            "|    time_elapsed         | 6728         |\n",
            "|    total_timesteps      | 3983360      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0035728517 |\n",
            "|    clip_fraction        | 0.0989       |\n",
            "|    clip_range           | 0.1          |\n",
            "|    entropy_loss         | -1.67        |\n",
            "|    explained_variance   | -2.76        |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | -0.0506      |\n",
            "|    n_updates            | 15556        |\n",
            "|    policy_gradient_loss | -0.0159      |\n",
            "|    value_loss           | 1.35e-05     |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 592          |\n",
            "|    iterations           | 3891         |\n",
            "|    time_elapsed         | 6730         |\n",
            "|    total_timesteps      | 3984384      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0024836087 |\n",
            "|    clip_fraction        | 0.0891       |\n",
            "|    clip_range           | 0.1          |\n",
            "|    entropy_loss         | -1.69        |\n",
            "|    explained_variance   | -1.61        |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | -0.0461      |\n",
            "|    n_updates            | 15560        |\n",
            "|    policy_gradient_loss | -0.0141      |\n",
            "|    value_loss           | 1.2e-05      |\n",
            "------------------------------------------\n",
            "----------------------------------------\n",
            "| time/                   |            |\n",
            "|    fps                  | 591        |\n",
            "|    iterations           | 3892       |\n",
            "|    time_elapsed         | 6732       |\n",
            "|    total_timesteps      | 3985408    |\n",
            "| train/                  |            |\n",
            "|    approx_kl            | 0.00419658 |\n",
            "|    clip_fraction        | 0.122      |\n",
            "|    clip_range           | 0.1        |\n",
            "|    entropy_loss         | -1.71      |\n",
            "|    explained_variance   | -2.43      |\n",
            "|    learning_rate        | 0.00025    |\n",
            "|    loss                 | -0.0424    |\n",
            "|    n_updates            | 15564      |\n",
            "|    policy_gradient_loss | -0.0157    |\n",
            "|    value_loss           | 1.1e-05    |\n",
            "----------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 591          |\n",
            "|    iterations           | 3893         |\n",
            "|    time_elapsed         | 6734         |\n",
            "|    total_timesteps      | 3986432      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0027512312 |\n",
            "|    clip_fraction        | 0.0762       |\n",
            "|    clip_range           | 0.1          |\n",
            "|    entropy_loss         | -1.66        |\n",
            "|    explained_variance   | -1.29        |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | -0.0431      |\n",
            "|    n_updates            | 15568        |\n",
            "|    policy_gradient_loss | -0.0135      |\n",
            "|    value_loss           | 1.1e-05      |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 591          |\n",
            "|    iterations           | 3894         |\n",
            "|    time_elapsed         | 6735         |\n",
            "|    total_timesteps      | 3987456      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0030114516 |\n",
            "|    clip_fraction        | 0.0842       |\n",
            "|    clip_range           | 0.1          |\n",
            "|    entropy_loss         | -1.7         |\n",
            "|    explained_variance   | -1.94        |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | -0.0415      |\n",
            "|    n_updates            | 15572        |\n",
            "|    policy_gradient_loss | -0.0123      |\n",
            "|    value_loss           | 6.47e-06     |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 591          |\n",
            "|    iterations           | 3895         |\n",
            "|    time_elapsed         | 6737         |\n",
            "|    total_timesteps      | 3988480      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0045504184 |\n",
            "|    clip_fraction        | 0.115        |\n",
            "|    clip_range           | 0.1          |\n",
            "|    entropy_loss         | -1.67        |\n",
            "|    explained_variance   | -4.91        |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | -0.0459      |\n",
            "|    n_updates            | 15576        |\n",
            "|    policy_gradient_loss | -0.0147      |\n",
            "|    value_loss           | 1.15e-05     |\n",
            "------------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 592         |\n",
            "|    iterations           | 3896        |\n",
            "|    time_elapsed         | 6738        |\n",
            "|    total_timesteps      | 3989504     |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.004075719 |\n",
            "|    clip_fraction        | 0.0906      |\n",
            "|    clip_range           | 0.1         |\n",
            "|    entropy_loss         | -1.67       |\n",
            "|    explained_variance   | 0.0453      |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | -0.0249     |\n",
            "|    n_updates            | 15580       |\n",
            "|    policy_gradient_loss | -0.0099     |\n",
            "|    value_loss           | 0.00754     |\n",
            "-----------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 592          |\n",
            "|    iterations           | 3897         |\n",
            "|    time_elapsed         | 6740         |\n",
            "|    total_timesteps      | 3990528      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0023020725 |\n",
            "|    clip_fraction        | 0.0408       |\n",
            "|    clip_range           | 0.1          |\n",
            "|    entropy_loss         | -1.64        |\n",
            "|    explained_variance   | -0.0089      |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | -0.0223      |\n",
            "|    n_updates            | 15584        |\n",
            "|    policy_gradient_loss | -0.00724     |\n",
            "|    value_loss           | 0.0172       |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 592          |\n",
            "|    iterations           | 3898         |\n",
            "|    time_elapsed         | 6741         |\n",
            "|    total_timesteps      | 3991552      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0049516093 |\n",
            "|    clip_fraction        | 0.151        |\n",
            "|    clip_range           | 0.1          |\n",
            "|    entropy_loss         | -1.54        |\n",
            "|    explained_variance   | -0.456       |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | -0.0466      |\n",
            "|    n_updates            | 15588        |\n",
            "|    policy_gradient_loss | -0.0155      |\n",
            "|    value_loss           | 9.11e-05     |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 592          |\n",
            "|    iterations           | 3899         |\n",
            "|    time_elapsed         | 6743         |\n",
            "|    total_timesteps      | 3992576      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0041685235 |\n",
            "|    clip_fraction        | 0.121        |\n",
            "|    clip_range           | 0.1          |\n",
            "|    entropy_loss         | -1.58        |\n",
            "|    explained_variance   | -0.0137      |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | -0.0428      |\n",
            "|    n_updates            | 15592        |\n",
            "|    policy_gradient_loss | -0.0149      |\n",
            "|    value_loss           | 4.78e-05     |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 592          |\n",
            "|    iterations           | 3900         |\n",
            "|    time_elapsed         | 6745         |\n",
            "|    total_timesteps      | 3993600      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0037888275 |\n",
            "|    clip_fraction        | 0.0894       |\n",
            "|    clip_range           | 0.1          |\n",
            "|    entropy_loss         | -1.56        |\n",
            "|    explained_variance   | -0.28        |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | -0.0429      |\n",
            "|    n_updates            | 15596        |\n",
            "|    policy_gradient_loss | -0.0133      |\n",
            "|    value_loss           | 2.14e-05     |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 592          |\n",
            "|    iterations           | 3901         |\n",
            "|    time_elapsed         | 6747         |\n",
            "|    total_timesteps      | 3994624      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0048335125 |\n",
            "|    clip_fraction        | 0.12         |\n",
            "|    clip_range           | 0.1          |\n",
            "|    entropy_loss         | -1.58        |\n",
            "|    explained_variance   | -0.0814      |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | -0.0339      |\n",
            "|    n_updates            | 15600        |\n",
            "|    policy_gradient_loss | -0.013       |\n",
            "|    value_loss           | 3.52e-05     |\n",
            "------------------------------------------\n",
            "----------------------------------------\n",
            "| time/                   |            |\n",
            "|    fps                  | 592        |\n",
            "|    iterations           | 3902       |\n",
            "|    time_elapsed         | 6749       |\n",
            "|    total_timesteps      | 3995648    |\n",
            "| train/                  |            |\n",
            "|    approx_kl            | 0.00403394 |\n",
            "|    clip_fraction        | 0.113      |\n",
            "|    clip_range           | 0.1        |\n",
            "|    entropy_loss         | -1.59      |\n",
            "|    explained_variance   | -0.248     |\n",
            "|    learning_rate        | 0.00025    |\n",
            "|    loss                 | -0.0506    |\n",
            "|    n_updates            | 15604      |\n",
            "|    policy_gradient_loss | -0.0156    |\n",
            "|    value_loss           | 3.91e-05   |\n",
            "----------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 592         |\n",
            "|    iterations           | 3903        |\n",
            "|    time_elapsed         | 6750        |\n",
            "|    total_timesteps      | 3996672     |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.004182863 |\n",
            "|    clip_fraction        | 0.151       |\n",
            "|    clip_range           | 0.1         |\n",
            "|    entropy_loss         | -1.6        |\n",
            "|    explained_variance   | -0.279      |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | -0.0518     |\n",
            "|    n_updates            | 15608       |\n",
            "|    policy_gradient_loss | -0.0165     |\n",
            "|    value_loss           | 1.95e-05    |\n",
            "-----------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 592          |\n",
            "|    iterations           | 3904         |\n",
            "|    time_elapsed         | 6752         |\n",
            "|    total_timesteps      | 3997696      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0036225508 |\n",
            "|    clip_fraction        | 0.104        |\n",
            "|    clip_range           | 0.1          |\n",
            "|    entropy_loss         | -1.67        |\n",
            "|    explained_variance   | 0.0836       |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | -0.046       |\n",
            "|    n_updates            | 15612        |\n",
            "|    policy_gradient_loss | -0.0139      |\n",
            "|    value_loss           | 1.33e-05     |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 592          |\n",
            "|    iterations           | 3905         |\n",
            "|    time_elapsed         | 6753         |\n",
            "|    total_timesteps      | 3998720      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0040229033 |\n",
            "|    clip_fraction        | 0.119        |\n",
            "|    clip_range           | 0.1          |\n",
            "|    entropy_loss         | -1.59        |\n",
            "|    explained_variance   | -0.359       |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | -0.0471      |\n",
            "|    n_updates            | 15616        |\n",
            "|    policy_gradient_loss | -0.0155      |\n",
            "|    value_loss           | 1.41e-05     |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 592          |\n",
            "|    iterations           | 3906         |\n",
            "|    time_elapsed         | 6755         |\n",
            "|    total_timesteps      | 3999744      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0040345523 |\n",
            "|    clip_fraction        | 0.121        |\n",
            "|    clip_range           | 0.1          |\n",
            "|    entropy_loss         | -1.55        |\n",
            "|    explained_variance   | -4.14        |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | -0.0464      |\n",
            "|    n_updates            | 15620        |\n",
            "|    policy_gradient_loss | -0.015       |\n",
            "|    value_loss           | 1.65e-05     |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 592          |\n",
            "|    iterations           | 3907         |\n",
            "|    time_elapsed         | 6757         |\n",
            "|    total_timesteps      | 4000768      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0037683314 |\n",
            "|    clip_fraction        | 0.126        |\n",
            "|    clip_range           | 0.1          |\n",
            "|    entropy_loss         | -1.53        |\n",
            "|    explained_variance   | -8.25        |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | -0.0432      |\n",
            "|    n_updates            | 15624        |\n",
            "|    policy_gradient_loss | -0.0147      |\n",
            "|    value_loss           | 1.46e-05     |\n",
            "------------------------------------------\n",
            "Training gereed.\n",
            "Model opgeslagen als ppo_model_warlords_4m\n",
            "Model opgeslagen als /content/drive/MyDrive/MARL_models/warlords_ppo_model_4m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<div style=\"background-color:white; color:black; padding: 10px;\">\n",
        "    <strong>(Julia) PPO Agent (WEET NIET OF DEZE OOK OPRECHT WERKT MET TRAINING)</strong>\n",
        "</div>"
      ],
      "metadata": {
        "id": "cNjPE8PgvRA-"
      },
      "id": "cNjPE8PgvRA-"
    },
    {
      "cell_type": "code",
      "source": [
        "# Model saven\n",
        "save_path = \"/content/drive/MyDrive/MARL_models\"\n",
        "import os\n",
        "\n",
        "# Zorg dat de map bestaat\n",
        "os.makedirs(save_path, exist_ok=True)\n",
        "\n",
        "# Sla model op met een custom naam en pad\n",
        "model_name = os.path.join(save_path, \"warlords_ppo_model\")\n",
        "agent.save(model_name)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0nYFI8LsqF1G",
        "outputId": "067f412f-cd67-4ab5-877f-e87cd35fec68"
      },
      "id": "0nYFI8LsqF1G",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model opgeslagen als /content/drive/MyDrive/MARL_models/warlords_ppo_model\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "agent.load(\"ppo_model_warlords\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ProZJWxRpZuo",
        "outputId": "0ffc531e-c3b1-4ec0-a03d-d40ad18729a9"
      },
      "id": "ProZJWxRpZuo",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model geladen van ppo_model_warlords\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_path = \"/content/drive/MyDrive/MARL_models/warlords_ppo_model.zip\"\n",
        "agent.load(model_path)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YujIDpuSqzCs",
        "outputId": "fc5f939d-264b-4d9c-955e-3697fe4771b4"
      },
      "id": "YujIDpuSqzCs",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model geladen van /content/drive/MyDrive/MARL_models/warlords_ppo_model.zip\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "id": "210914e9",
      "metadata": {
        "id": "210914e9"
      },
      "source": [
        "\n",
        "---\n",
        "<div style=\"background-color:LightBlue; text-align:center; vertical-align:middle; padding:50px 0; margin-top:5px; margin-bottom:5px\">\n",
        "    <h2 id=\"eda-title\" style=\"color:black; font-family: Verdana, sans-serif; font-size: 25px;\"><strong>H5: Training en Hyperparameter Search</strong></h2>\n",
        "</div>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1c0e45d6",
      "metadata": {
        "id": "1c0e45d6"
      },
      "source": [
        "<a name='1.1'></a>\n",
        "<h3>&sect;5.1: Training</h3>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<div style=\"background-color:white; color:black; padding: 10px;\">\n",
        "    <strong>(Rogier) Agent 1: PPO - Proximal Policy Optimization</strong></div>"
      ],
      "metadata": {
        "id": "RhfhmR3x-9DU"
      },
      "id": "RhfhmR3x-9DU"
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Hoe verloopt de training van een PPO-agent?\n",
        "\n",
        "De training van een PPO-agent (Proximal Policy Optimization) in een omgeving zoals Atari Warlords bestaat uit een reeks vaste stappen die gericht zijn op stabiliteit en efficiënt leren. Tijdens elke trainingscyclus verzamelt de agent zogenaamde 'rollouts': sequenties van observaties, acties en rewards die worden gegenereerd door het huidige beleid. Op basis van deze trajecten berekent PPO met Generalized Advantage Estimation (GAE) hoe gunstig elke actie was ten opzichte van de verwachting, wat helpt om het leerproces stabieler en nauwkeuriger te maken.\n",
        "\n",
        "De kern van PPO ligt in het voorzichtig updaten van het beleid. In plaats van grote stappen (die tot instabiliteit kunnen leiden), worden policy-updates beperkt door een clipping-mechanisme. Dit voorkomt dat het geleerde beleid te veel verandert per trainingsstap, waardoor de kans op catastrofaal “vergeten” sterk wordt verminderd. De verzamelde rollouts worden verdeeld over mini-batches en gedurende meerdere epochs gebruikt om zowel het beleid (policy) als de value-functie (critic) te verbeteren. Tegelijkertijd stimuleert PPO via een entropiebonus dat de agent in het begin veel blijft exploreren, wat de kans op het vinden van sterke strategieën vergroot.\n",
        "\n",
        "Tijdens en na de training wordt de agent regelmatig geëvalueerd zonder extra ruis, zodat duidelijk wordt hoe effectief het geleerde beleid is in de praktijk. Door deze aanpak is PPO bijzonder geschikt voor complexe, visuele en multi-agent omgevingen, waarbij gecontroleerd leren en robuuste prestaties essentieel zijn.\n"
      ],
      "metadata": {
        "id": "vO98uFAF_FCz"
      },
      "id": "vO98uFAF_FCz"
    },
    {
      "cell_type": "markdown",
      "source": [
        "<div style=\"background-color:white; color:black; padding: 10px;\">\n",
        "    <strong>Omgeving opzetten</strong>\n",
        "</div>\n",
        "\n",
        "\n",
        "In deze stap initialiseren we de multi-agent Warlords-omgeving met behulp van PettingZoo. We passen verschillende bewerkingen toe op de raw game frames:\n",
        "- `warlords_v3.parallel_env()`: Laadt de 4-speler Warlords-omgeving waarbij alle agents gelijktijdig acties nemen.\n",
        "- `ss.black_death_v3(env)`: Zorgt ervoor dat agents die \"dood\" gaan toch in de omgeving blijven als placeholder, zodat de agent-count altijd gelijk blijft.\n",
        "- `ss.color_reduction_v0(env, mode='full')`: Zet de gekleurde frames om naar grijswaarden, waardoor de inputdimensie kleiner wordt en het leren efficiënter.\n",
        "- `ss.resize_v1(env, x_size=84, y_size=84)`: Schaal de beelden terug naar 84x84 pixels (standaard in Atari-RL-onderzoek).\n",
        "- `ss.frame_stack_v1(env, 4)`: Stapelt de laatste 4 frames, zodat het model ook bewegingsinformatie kan oppikken (belangrijk bij visuele input).\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "W5whiJBiBH11"
      },
      "id": "W5whiJBiBH11"
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. Maak de parallelle multi-agent omgeving\n",
        "env = warlords_v3.parallel_env()            # 4-player Warlords omgeving\n",
        "env = ss.black_death_v3(env)               # Houd agents in env, zelfs na \"dood\"\n",
        "env = ss.color_reduction_v0(env, mode='full')  # Converteer naar grijswaarden:contentReference[oaicite:22]{index=22}\n",
        "env = ss.resize_v1(env, x_size=84, y_size=84)   # Resize frames naar 84x84 pixels\n",
        "env = ss.frame_stack_v1(env, 4)                # Stack 4 opvolgende frames:contentReference[oaicite:23]{index=23}"
      ],
      "metadata": {
        "id": "bm8m3LGworU1"
      },
      "id": "bm8m3LGworU1",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<div style=\"background-color:white; color:black; padding: 10px;\">\n",
        "    <strong>Converteren naar een vectorized env voor Stable-Baselines3</strong>\n",
        "</div>\n",
        "\n",
        "Stable-Baselines3 werkt het best met vectorized environments, waarbij meerdere instanties van de omgeving parallel kunnen draaien:\n",
        "- `ss.pettingzoo_env_to_vec_env_v1(env)`: Zet de PettingZoo-omgeving om naar een formaat dat door SB3 wordt herkend.\n",
        "- `ss.concat_vec_envs_v1(...)`: Combineert meerdere vectorized omgevingen tot één, zodat batchgewijze training mogelijk is (hier draaien 2 parallelle omgevingen op 1 CPU).\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "5sisIiBjE1ji"
      },
      "id": "5sisIiBjE1ji"
    },
    {
      "cell_type": "code",
      "source": [
        "# 2. Converteer naar een vectorized env voor Stable-Baselines3\n",
        "vec_env = ss.pettingzoo_env_to_vec_env_v1(env)\n",
        "vec_env = ss.concat_vec_envs_v1(vec_env, num_vec_envs=2, num_cpus=1, base_class=\"stable_baselines3\")"
      ],
      "metadata": {
        "id": "SNKqddWBotHw"
      },
      "id": "SNKqddWBotHw",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<div style=\"background-color:white; color:black; padding: 10px;\">\n",
        "    <strong>Defineren en trainen van het PPO model</strong>\n",
        "</div>\n",
        "\n",
        "We definiëren het PPO-model dat gebruikmaakt van een convolutioneel neuraal netwerk (CnnPolicy), geschikt voor visuele input zoals Atari-frames:\n",
        "- `PPO(CnnPolicy, vec_env, ...)`: Initialiseer het PPO-algoritme met de eerder gemaakte vectorized environment.\n",
        "- `total_timesteps`: Bepaalt hoe lang het model traint. Meer timesteps betekent meestal beter getrainde agenten.\n",
        "- `model.learn(...)`: Start het daadwerkelijke leerproces. Het model verzamelt data, leert van ervaringen en past het beleid continu aan.\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "vLtNh7tEozmE"
      },
      "id": "vLtNh7tEozmE"
    },
    {
      "cell_type": "code",
      "source": [
        "# 3. Definieer en train het PPO model\n",
        "model = PPO(CnnPolicy, vec_env, verbose=3, batch_size=256)  # CNN-beleid voor visuele input:contentReference[oaicite:24]{index=24}\n",
        "total_timesteps = 10_000_000   # kies het aantal trainingstimesteps\n",
        "print(\"Start training...\")\n",
        "model.learn(total_timesteps=total_timesteps)\n",
        "print(\"Training gereed.\")"
      ],
      "metadata": {
        "id": "rnsPATHcozu8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "77823eb5-fdbc-446e-cd49-2bb76654d325"
      },
      "id": "rnsPATHcozu8",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using cuda device\n",
            "Wrapping the env in a VecTransposeImage.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/stable_baselines3/common/vec_env/base_vec_env.py:78: UserWarning: The `render_mode` attribute is not defined in your environment. It will be set to None.\n",
            "  warnings.warn(\"The `render_mode` attribute is not defined in your environment. It will be set to None.\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Start training...\n",
            "------------------------------\n",
            "| time/              |       |\n",
            "|    fps             | 685   |\n",
            "|    iterations      | 1     |\n",
            "|    time_elapsed    | 23    |\n",
            "|    total_timesteps | 16384 |\n",
            "------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 557         |\n",
            "|    iterations           | 2           |\n",
            "|    time_elapsed         | 58          |\n",
            "|    total_timesteps      | 32768       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.007993929 |\n",
            "|    clip_fraction        | 0.0178      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -1.79       |\n",
            "|    explained_variance   | -1.78       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 0.00604     |\n",
            "|    n_updates            | 10          |\n",
            "|    policy_gradient_loss | -0.00251    |\n",
            "|    value_loss           | 0.00127     |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 525         |\n",
            "|    iterations           | 3           |\n",
            "|    time_elapsed         | 93          |\n",
            "|    total_timesteps      | 49152       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.009628351 |\n",
            "|    clip_fraction        | 0.0651      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -1.78       |\n",
            "|    explained_variance   | 0.272       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | -0.0145     |\n",
            "|    n_updates            | 20          |\n",
            "|    policy_gradient_loss | -0.00841    |\n",
            "|    value_loss           | 0.000545    |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 517         |\n",
            "|    iterations           | 4           |\n",
            "|    time_elapsed         | 126         |\n",
            "|    total_timesteps      | 65536       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.008323721 |\n",
            "|    clip_fraction        | 0.0643      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -1.78       |\n",
            "|    explained_variance   | 0.178       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | -0.0141     |\n",
            "|    n_updates            | 30          |\n",
            "|    policy_gradient_loss | -0.00845    |\n",
            "|    value_loss           | 0.00201     |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 510         |\n",
            "|    iterations           | 5           |\n",
            "|    time_elapsed         | 160         |\n",
            "|    total_timesteps      | 81920       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.009123579 |\n",
            "|    clip_fraction        | 0.0985      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -1.77       |\n",
            "|    explained_variance   | 0.064       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 0.000924    |\n",
            "|    n_updates            | 40          |\n",
            "|    policy_gradient_loss | -0.00882    |\n",
            "|    value_loss           | 0.00163     |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 507         |\n",
            "|    iterations           | 6           |\n",
            "|    time_elapsed         | 193         |\n",
            "|    total_timesteps      | 98304       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.009636432 |\n",
            "|    clip_fraction        | 0.112       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -1.76       |\n",
            "|    explained_variance   | 0.0798      |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | -0.0215     |\n",
            "|    n_updates            | 50          |\n",
            "|    policy_gradient_loss | -0.0105     |\n",
            "|    value_loss           | 0.00246     |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 505         |\n",
            "|    iterations           | 7           |\n",
            "|    time_elapsed         | 227         |\n",
            "|    total_timesteps      | 114688      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.010353488 |\n",
            "|    clip_fraction        | 0.107       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -1.77       |\n",
            "|    explained_variance   | -0.0259     |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | -0.0298     |\n",
            "|    n_updates            | 60          |\n",
            "|    policy_gradient_loss | -0.0138     |\n",
            "|    value_loss           | 0.00114     |\n",
            "-----------------------------------------\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/supersuit/lambda_wrappers/observation_lambda.py\u001b[0m in \u001b[0;36m_modify_observation\u001b[0;34m(self, agent, observation)\u001b[0m\n\u001b[1;32m     67\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 68\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchange_observation_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobservation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mold_obs_space\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0magent\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     69\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: basic_obs_wrapper.<locals>.change_obs() takes 2 positional arguments but 3 were given",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-24-4260403329.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mtotal_timesteps\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m10_000_000\u001b[0m   \u001b[0;31m# kies het aantal trainingstimesteps\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Start training...\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlearn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtotal_timesteps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtotal_timesteps\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Training gereed.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/stable_baselines3/ppo/ppo.py\u001b[0m in \u001b[0;36mlearn\u001b[0;34m(self, total_timesteps, callback, log_interval, tb_log_name, reset_num_timesteps, progress_bar)\u001b[0m\n\u001b[1;32m    309\u001b[0m         \u001b[0mprogress_bar\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbool\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    310\u001b[0m     ) -> SelfPPO:\n\u001b[0;32m--> 311\u001b[0;31m         return super().learn(\n\u001b[0m\u001b[1;32m    312\u001b[0m             \u001b[0mtotal_timesteps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtotal_timesteps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    313\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcallback\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/stable_baselines3/common/on_policy_algorithm.py\u001b[0m in \u001b[0;36mlearn\u001b[0;34m(self, total_timesteps, callback, log_interval, tb_log_name, reset_num_timesteps, progress_bar)\u001b[0m\n\u001b[1;32m    322\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    323\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_timesteps\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mtotal_timesteps\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 324\u001b[0;31m             \u001b[0mcontinue_training\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollect_rollouts\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrollout_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_rollout_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_steps\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    325\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    326\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mcontinue_training\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/stable_baselines3/common/on_policy_algorithm.py\u001b[0m in \u001b[0;36mcollect_rollouts\u001b[0;34m(self, env, callback, rollout_buffer, n_rollout_steps)\u001b[0m\n\u001b[1;32m    216\u001b[0m                     \u001b[0mclipped_actions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mactions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maction_space\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlow\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maction_space\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhigh\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    217\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 218\u001b[0;31m             \u001b[0mnew_obs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrewards\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdones\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minfos\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclipped_actions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    219\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    220\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_timesteps\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_envs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/stable_baselines3/common/vec_env/base_vec_env.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, actions)\u001b[0m\n\u001b[1;32m    220\u001b[0m         \"\"\"\n\u001b[1;32m    221\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mactions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 222\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    223\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    224\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget_images\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mSequence\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/stable_baselines3/common/vec_env/vec_transpose.py\u001b[0m in \u001b[0;36mstep_wait\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     95\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mstep_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mVecEnvStepReturn\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 97\u001b[0;31m         \u001b[0mobservations\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrewards\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdones\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minfos\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvenv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     98\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m         \u001b[0;31m# Transpose the terminal observations\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/supersuit/vector/sb3_vector_wrapper.py\u001b[0m in \u001b[0;36mstep_wait\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mstep_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m         \u001b[0mobservations\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrewards\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mterminations\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtruncations\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minfos\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvenv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m         \u001b[0;31m# Note: SB3 expects dones to be an np.array\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m         dones = np.array(\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/supersuit/vector/concat_vec_env.py\u001b[0m in \u001b[0;36mstep_wait\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     74\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mstep_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 76\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_saved_actions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     77\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     78\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/supersuit/vector/concat_vec_env.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, actions)\u001b[0m\n\u001b[1;32m     82\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mvenv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvec_envs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     83\u001b[0m             data.append(\n\u001b[0;32m---> 84\u001b[0;31m                 venv.step(\n\u001b[0m\u001b[1;32m     85\u001b[0m                     self.concatenate_actions(\n\u001b[1;32m     86\u001b[0m                         \u001b[0mactions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0midx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mvenv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_envs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvenv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_envs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/supersuit/vector/markov_vector_wrapper.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, actions)\u001b[0m\n\u001b[1;32m     68\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0magent\u001b[0m \u001b[0;32min\u001b[0m \u001b[0magent_set\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m         }\n\u001b[0;32m---> 70\u001b[0;31m         \u001b[0mobservations\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrewards\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mterms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtruncs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minfos\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpar_env\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mact_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     71\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m         \u001b[0;31m# adds last observation to info where user can get it\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/supersuit/generic_wrappers/utils/shared_wrapper_util.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, actions)\u001b[0m\n\u001b[1;32m    128\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0magent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maction\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mactions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    129\u001b[0m         }\n\u001b[0;32m--> 130\u001b[0;31m         \u001b[0mobservations\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrewards\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mterminations\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtruncations\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minfos\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mactions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    131\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_modifiers\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0magents\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    132\u001b[0m         observations = {\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pettingzoo/utils/wrappers/base_parallel.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, actions)\u001b[0m\n\u001b[1;32m     32\u001b[0m         \u001b[0mdict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mAgentID\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m     ]:\n\u001b[0;32m---> 34\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mactions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     35\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mrender\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0mstr\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pettingzoo/utils/conversions.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, actions)\u001b[0m\n\u001b[1;32m    212\u001b[0m         \u001b[0mtruncations\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maec_env\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtruncations\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    213\u001b[0m         \u001b[0minfos\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maec_env\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfos\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 214\u001b[0;31m         observations = {\n\u001b[0m\u001b[1;32m    215\u001b[0m             \u001b[0magent\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maec_env\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobserve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0magent\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0magent\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maec_env\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0magents\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    216\u001b[0m         }\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pettingzoo/utils/conversions.py\u001b[0m in \u001b[0;36m<dictcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    213\u001b[0m         \u001b[0minfos\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maec_env\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfos\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    214\u001b[0m         observations = {\n\u001b[0;32m--> 215\u001b[0;31m             \u001b[0magent\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maec_env\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobserve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0magent\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0magent\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maec_env\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0magents\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    216\u001b[0m         }\n\u001b[1;32m    217\u001b[0m         while self.aec_env.agents and (\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/supersuit/utils/base_aec_wrapper.py\u001b[0m in \u001b[0;36mobserve\u001b[0;34m(self, agent)\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mobserve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0magent\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 35\u001b[0;31m         obs = super().observe(\n\u001b[0m\u001b[1;32m     36\u001b[0m             \u001b[0magent\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m         )  # problem is in this line, the obs is sometimes a different size from the obs space\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pettingzoo/utils/wrappers/order_enforcing.py\u001b[0m in \u001b[0;36mobserve\u001b[0;34m(self, agent)\u001b[0m\n\u001b[1;32m     73\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_has_reset\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m             \u001b[0mEnvLogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merror_observe_before_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 75\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobserve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0magent\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     76\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mstate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pettingzoo/utils/wrappers/base.py\u001b[0m in \u001b[0;36mobserve\u001b[0;34m(self, agent)\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mobserve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0magent\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mAgentID\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mObsType\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 41\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobserve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0magent\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     42\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mstate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/supersuit/utils/base_aec_wrapper.py\u001b[0m in \u001b[0;36mobserve\u001b[0;34m(self, agent)\u001b[0m\n\u001b[1;32m     36\u001b[0m             \u001b[0magent\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m         )  # problem is in this line, the obs is sometimes a different size from the obs space\n\u001b[0;32m---> 38\u001b[0;31m         \u001b[0mobservation\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_modify_observation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0magent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     39\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mobservation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/supersuit/lambda_wrappers/observation_lambda.py\u001b[0m in \u001b[0;36m_modify_observation\u001b[0;34m(self, agent, observation)\u001b[0m\n\u001b[1;32m     68\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchange_observation_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobservation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mold_obs_space\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0magent\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchange_observation_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobservation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mold_obs_space\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     71\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/supersuit/generic_wrappers/basic_wrappers.py\u001b[0m in \u001b[0;36mchange_obs\u001b[0;34m(obs, obs_space)\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mchange_obs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobs_space\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchange_observation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobs_space\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparam\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mobservation_lambda_v0\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0menv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchange_obs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchange_space\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/supersuit/utils/basic_transforms/color_reduction.py\u001b[0m in \u001b[0;36mchange_observation\u001b[0;34m(obs, obs_space, color_reduction)\u001b[0m\n\u001b[1;32m     34\u001b[0m         \u001b[0mobs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mobs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcolor_reduction\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"full\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 36\u001b[0;31m         \u001b[0mobs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mobs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m@\u001b[0m \u001b[0mGRAYSCALE_WEIGHTS\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muint8\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     37\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mobs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<div style=\"background-color:white; color:black; padding: 10px;\">\n",
        "    <strong>Opslaan van het getrainde model met timestamp</strong>\n",
        "</div>\n",
        "\n",
        "Na de training slaan we het model op, waarbij automatisch een timestamp aan de bestandsnaam wordt toegevoegd:\n",
        "- `time.strftime(...)`: Maakt een string van de huidige datum en tijd.\n",
        "- `model.save(model_name)`: Slaat het getrainde model op onder een unieke naam, zodat je het later gemakkelijk kunt laden en evalueren.\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "4-c6Bba0EduX"
      },
      "id": "4-c6Bba0EduX"
    },
    {
      "cell_type": "code",
      "source": [
        "# 4. Sla het getrainde model op\n",
        "timestamp = time.strftime(\"%Y%m%d-%H%M%S\")\n",
        "model_name = f\"warlords_ppo_model_{timestamp}\"\n",
        "model.save(model_name)\n",
        "print(f\"Model opgeslagen als {model_name}\")"
      ],
      "metadata": {
        "id": "yrTYXTf_pM8M"
      },
      "id": "yrTYXTf_pM8M",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "import supersuit as ss\n",
        "from stable_baselines3 import PPO\n",
        "from stable_baselines3.ppo import CnnPolicy\n",
        "from pettingzoo.atari import warlords_v3\n",
        "\n",
        "# 1. Maak de parallelle multi-agent omgeving\n",
        "env = warlords_v3.parallel_env()            # 4-player Warlords omgeving\n",
        "env = ss.black_death_v3(env)               # Houd agents in env, zelfs na \"dood\"\n",
        "env = ss.color_reduction_v0(env, mode='full')  # Converteer naar grijswaarden:contentReference[oaicite:22]{index=22}\n",
        "env = ss.resize_v1(env, x_size=84, y_size=84)   # Resize frames naar 84x84 pixels\n",
        "env = ss.frame_stack_v1(env, 4)                # Stack 4 opvolgende frames:contentReference[oaicite:23]{index=23}\n",
        "\n",
        "# 2. Converteer naar een vectorized env voor Stable-Baselines3\n",
        "vec_env = ss.pettingzoo_env_to_vec_env_v1(env)\n",
        "vec_env = ss.concat_vec_envs_v1(vec_env, num_vec_envs=2, num_cpus=1, base_class=\"stable_baselines3\")\n",
        "\n",
        "# 3. Definieer en train het PPO model\n",
        "model = PPO(CnnPolicy, vec_env, verbose=3, batch_size=256)  # CNN-beleid voor visuele input:contentReference[oaicite:24]{index=24}\n",
        "total_timesteps = 2_000_000   # kies het aantal trainingstimesteps\n",
        "print(\"Start training...\")\n",
        "model.learn(total_timesteps=total_timesteps)\n",
        "print(\"Training gereed.\")\n",
        "\n",
        "# 4. Sla het getrainde model op\n",
        "timestamp = time.strftime(\"%Y%m%d-%H%M%S\")\n",
        "model_name = f\"warlords_ppo_model_{timestamp}\"\n",
        "model.save(model_name)\n",
        "print(f\"Model opgeslagen als {model_name}\")\n",
        "\n"
      ],
      "metadata": {
        "id": "KYJjAM6fKnaR"
      },
      "id": "KYJjAM6fKnaR",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<div style=\"background-color:white; color:black; padding: 10px;\">\n",
        "    <strong>Toelichting op de output</strong>\n",
        "</div>"
      ],
      "metadata": {
        "id": "IOVfX0UGpW3h"
      },
      "id": "IOVfX0UGpW3h"
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Interpretatie van de PPO Trainingsoutput\n",
        "\n",
        "Tijdens het trainen van het PPO-model worden verschillende statistieken gelogd. Hieronder lichten we de belangrijkste waarden uit, zodat duidelijk wordt wat ze betekenen en hoe ze geïnterpreteerd kunnen worden:\n",
        "\n",
        "| **Metric**               | **Waarde**      | **Toelichting**                                                                                                                                             |\n",
        "|------------------------- |-----------------|-------------------------------------------------------------------------------------------------------------------------------------------------------------|\n",
        "| **fps**                  | 472             | *Frames per second* – het aantal frames (omgevingsstappen) dat per seconde wordt verwerkt. Een hoge waarde betekent dat het trainen efficiënt verloopt.     |\n",
        "| **iterations**           | 8               | Aantal PPO-updates die zijn uitgevoerd sinds de start van de training.                                                                                      |\n",
        "| **time_elapsed**         | 277             | Totale verstreken tijd (in seconden) sinds het begin van de training.                                                                                       |\n",
        "| **total_timesteps**      | 131072          | Het aantal omgevingsstappen (frames/acties) dat het model tot nu toe heeft gezien.                                                                          |\n",
        "\n",
        "### Train-metrics\n",
        "\n",
        "| **Metric**                   | **Waarde**        | **Toelichting**                                                                                                                                             |\n",
        "|------------------------------|-------------------|-------------------------------------------------------------------------------------------------------------------------------------------------------------|\n",
        "| **approx_kl**                | 0.00897           | Gemiddelde KL-divergence tussen het oude en het nieuwe beleid. Een lage waarde duidt op kleine wijzigingen per update, wat zorgt voor stabiel leren.         |\n",
        "| **clip_fraction**            | 0.088             | Percentage van de policy-updates die beperkt (“geclipped”) werden. Veel clipping betekent dat het model te grote stappen probeert te maken (mogelijk instabiel). |\n",
        "| **clip_range**               | 0.2               | Maximale toegestane relatieve verandering per update (standaard bij PPO).                                                                                   |\n",
        "| **entropy_loss**             | -1.77             | De entropie van het beleid: een maat voor exploratie. Een lagere (meer negatieve) waarde betekent dat het beleid voorspelbaarder wordt (minder exploratie).   |\n",
        "| **explained_variance**       | -0.0209           | Meet hoe goed de value-functie de daadwerkelijke rewards voorspelt (1.0 = perfect, 0 = slecht, <0 = erger dan gokken).                                      |\n",
        "| **learning_rate**            | 0.0003            | De snelheid waarmee het model leert; hogere waardes versnellen leren, maar kunnen leiden tot instabiliteit.                                                 |\n",
        "| **loss**                     | -0.0226           | Totale loss-functie (mix van policy, value en entropy loss) die wordt geminimaliseerd tijdens training.                                                     |\n",
        "| **n_updates**                | 70                | Totaal aantal policy-updates tot nu toe uitgevoerd.                                                                                                         |\n",
        "| **policy_gradient_loss**     | -0.0133           | De bijdrage van de policy-gradient aan de totale loss. Negatiever betekent sterkere updates in de richting van meer reward.                                 |\n",
        "| **value_loss**               | 0.00265           | Fout van de value-functie; hoe kleiner, hoe beter het model toekomstige rewards kan voorspellen.                                                            |\n",
        "\n",
        "---\n",
        "\n",
        "### Richting van de Waarden: Wat wil je zien?\n",
        "\n",
        "- **fps**: Hoger is beter – snellere training.\n",
        "- **iterations / n_updates / total_timesteps**: Hoger betekent meer getraind (maar let op overfitting).\n",
        "- **approx_kl**: Laag (bijv. tussen 0.01 en 0.05) = stabiel leren. Te hoog: beleid verandert te snel en wordt instabiel; te laag: leren gaat traag.\n",
        "- **clip_fraction**: Typisch rond 0.1–0.3. Te hoog kan instabiliteit betekenen, te laag kan duiden op te weinig leereffect.\n",
        "- **entropy_loss**: Minder negatief betekent meer exploratie. Naarmate het model zekerder wordt, daalt de entropie. Een te lage entropie betekent mogelijk te weinig exploratie.\n",
        "- **explained_variance**: Hoger is beter. Richtwaarde: richting 1.0 is perfect, 0 is slecht, <0 betekent dat de value-functie slechter presteert dan gokken.\n",
        "- **learning_rate**: Hogere waardes versnellen het leren maar verhogen het risico op instabiliteit.\n",
        "- **loss / value_loss**: Lager is beter – betekent dat het model beter de returns/value weet te voorspellen en de policy verbetert.\n",
        "\n",
        "#### **Samenvatting**\n",
        "Deze statistieken geven inzicht in hoe snel en stabiel het PPO-model leert. Let vooral op de **KL-divergence** (voor stabiliteit), **clip_fraction** (voor learning dynamics), en **explained_variance** (voor de nauwkeurigheid van de value-voorspelling).\n"
      ],
      "metadata": {
        "id": "fLeX-0iZqR8g"
      },
      "id": "fLeX-0iZqR8g"
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "LbwGRt6gnMVu"
      },
      "id": "LbwGRt6gnMVu",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "459b8c33",
      "metadata": {
        "id": "459b8c33"
      },
      "source": [
        "<a name='1.1'></a>\n",
        "<h3>&sect;5.2: Selectie en tuning van hyperparameters</h3>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "27eb948f",
      "metadata": {
        "id": "27eb948f"
      },
      "source": [
        "a.\tExperimenteer met hyperparameters (zoals bijvoorbeeld learning rates of exploration-exploitation afwegingen). Documenteer dit ook."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Experimenteren met hyperparameters"
      ],
      "metadata": {
        "id": "i-dZCQ0Tvu34"
      },
      "id": "i-dZCQ0Tvu34"
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Hyperparameters**\n",
        "\n",
        "##### ***Overzicht keuzes***\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "| Hyperparameter        | Waarde    | Uitleg                                                                                 |\n",
        "|----------------------|-----------|----------------------------------------------------------------------------------------|\n",
        "| `Policy`              | CnnPolicy | Gebruikt convolutieneurale netwerken, geschikt voor beeldinput zoals bij Atari-games   |\n",
        "| `learning_rate`        | 2.5e-4    | Standaardwaarde voor PPO in Atari-omgevingen; zorgt voor een goede balans tussen snel leren en stabiliteit |\n",
        "| `gamma`                | 0.99      | Kortingfactor; waardeert toekomstige beloningen bijna net zo hoog als directe beloning |\n",
        "| `n_steps`              | 128       | Aantal stappen per update; bepaalt hoeveel ervaringen per batch worden verzameld       |\n",
        "| `batch_size`           | 256       | Grootte van elke batch die wordt gebruikt tijdens het updaten van het beleid           |\n",
        "| `ent_coef (entropie)`  | 0.01      | Coëfficiënt voor exploratie; hogere waarde zorgt voor meer exploratiegedrag            |\n",
        "| `verbose`              | 1         | Zorgt voor gedetailleerde logging tijdens het trainen                                  |\n",
        "\n",
        "#### **Experimenteren met hyperparameters**\n",
        "Tijdens het trainen heb ik geëxperimenteerd met verschillende waarden voor de learning rate, entropie-coëfficiënt en batch size:\n",
        "- **Learning rate:** Een hogere learning rate zorgde voor snellere training, maar maakte het model soms instabiel. 2.5e-4 bleek een goed compromis.\n",
        "- **Entropie-coëfficiënt (ent_coef):** Met een hogere waarde ging de agent meer experimenteren, maar duurde het langer voordat hij goed leerde. 0.01 gaf een goede balans.\n",
        "- **Batch size:** Grotere batches zorgden voor stabielere updates, maar vroegen meer geheugen.\n",
        "\n",
        "De uiteindelijke hyperparameterkeuzes zijn gebaseerd op wat het beste werkte voor deze specifieke omgeving en op basis van literatuur.\n",
        "\n"
      ],
      "metadata": {
        "id": "7glSKPkivIs3"
      },
      "id": "7glSKPkivIs3"
    },
    {
      "cell_type": "markdown",
      "id": "3eff6630",
      "metadata": {
        "id": "3eff6630"
      },
      "source": [
        "\n",
        "---\n",
        "<div style=\"background-color:LightBlue; text-align:center; vertical-align:middle; padding:50px 0; margin-top:5px; margin-bottom:5px\">\n",
        "    <h2 id=\"eda-title\" style=\"color:black; font-family: Verdana, sans-serif; font-size: 25px;\"><strong>H6: Evaluatie en Vergelijking</strong></h2>\n",
        "</div>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b824fae3",
      "metadata": {
        "id": "b824fae3"
      },
      "source": [
        "<a name='1.1'></a>\n",
        "<h3>&sect;6.1: Evaluatie t.o.v. baseline</h3>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bc781412",
      "metadata": {
        "id": "bc781412"
      },
      "source": [
        "b.\tEvalueer de prestaties van je model en vergelijk deze – indien mogelijk – met een baseline. Welke voordelen biedt RL in dit specifieke scenario?"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f5faffea",
      "metadata": {
        "id": "f5faffea"
      },
      "source": [
        "<a name='1.1'></a>\n",
        "<h3>&sect;6.2: Analyse met metrics</h3>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e09b4659",
      "metadata": {
        "id": "e09b4659"
      },
      "source": [
        "c.\tVisualiseer de resultaten met grafieken en andere tools. Denk bijvoorbeeld aan reward-curves en stabiliteit van training."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<div style=\"background-color:white; color:black; padding: 10px;\">\n",
        "    <strong>Metrics Model met 200_000 time stamps</strong>\n",
        "</div>"
      ],
      "metadata": {
        "id": "lWbX5QiCtfVx"
      },
      "id": "lWbX5QiCtfVx"
    },
    {
      "cell_type": "code",
      "source": [
        "# drive 1000000 time step model\n",
        "\n",
        "model_path = \"/content/drive/MyDrive/MARL_models/warlords_ppo_model_4m.zip\"\n",
        "model_name = model_path"
      ],
      "metadata": {
        "id": "bdWCNDWqrqWl"
      },
      "id": "bdWCNDWqrqWl",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import numpy as np\n",
        "\n",
        "# 1. Laad het opgeslagen model\n",
        "model = PPO.load(model_name) # Tijdelijk, hier getrainde model zetten huts\n",
        "\n",
        "# 2. Maak een nieuwe omgeving voor evaluatie (parallel API)\n",
        "eval_env = warlords_v3.parallel_env(render_mode=None)  # geen render, alleen data\n",
        "eval_env = ss.black_death_v3(eval_env)\n",
        "eval_env = ss.color_reduction_v0(eval_env, mode='full')\n",
        "eval_env = ss.resize_v1(eval_env, x_size=84, y_size=84)\n",
        "eval_env = ss.frame_stack_v1(eval_env, 4)\n",
        "\n",
        "# 3. Functie om een episode te spelen met 1 RL agent vs 3 random agents\n",
        "def play_one_episode(env, agent_policy, render=False):\n",
        "    obs, info = env.reset(seed=None)  # <-- Let op: 2 outputs!\n",
        "    episode_rewards = {agent: 0 for agent in env.possible_agents}\n",
        "    step = 0\n",
        "    while True:\n",
        "        actions = {}\n",
        "        for agent, agent_obs in obs.items():\n",
        "            if agent == env.possible_agents[0]:\n",
        "                action, _state = agent_policy.predict(agent_obs, deterministic=True)\n",
        "            else:\n",
        "                action = env.action_space(agent).sample()\n",
        "            actions[agent] = action\n",
        "        obs, rewards, terminations, truncations, infos = env.step(actions)  # <-- 5 outputs\n",
        "        if render:\n",
        "            env.render()\n",
        "        for agent, r in rewards.items():\n",
        "            episode_rewards[agent] += r\n",
        "        if all(terminations.values()) or any(truncations.values()):\n",
        "            break\n",
        "        step += 1\n",
        "    return episode_rewards\n",
        "\n",
        "# 4. Speel meerdere episodes en verzamel resultaten\n",
        "num_test_episodes = 20\n",
        "total_rewards = {agent: 0 for agent in eval_env.possible_agents}\n",
        "wins = {agent: 0 for agent in eval_env.possible_agents}\n",
        "\n",
        "for ep in range(1, num_test_episodes+1):\n",
        "    ep_rewards = play_one_episode(eval_env, model, render=False)\n",
        "    print(f\"Episode {ep} rewards: {ep_rewards}\")\n",
        "    for ag, r in ep_rewards.items():\n",
        "        total_rewards[ag] += r\n",
        "    for ag, r in ep_rewards.items():\n",
        "        if r > 0:  # +1 winnaar\n",
        "            wins[ag] += 1\n",
        "\n",
        "# 5. Bereken gemiddelde reward per agent over alle test-episodes\n",
        "avg_rewards = {agent: total_rewards[agent]/num_test_episodes for agent in total_rewards}\n",
        "print(\"\\nGemiddelde reward per agent over\", num_test_episodes, \"episodes:\")\n",
        "for ag, r in avg_rewards.items():\n",
        "    print(f\"  {ag}: {r:.2f}\")\n",
        "print(\"Aantal keer gewonnen (laatste overlevende) per agent:\", wins)\n"
      ],
      "metadata": {
        "id": "X2fpKsSdtfxm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "823da8a1-630f-4b03-b7f8-dcf904381ccf"
      },
      "id": "X2fpKsSdtfxm",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Episode 1 rewards: {'first_0': np.float64(-1.0), 'second_0': np.float64(1.0), 'third_0': np.float64(-1.0), 'fourth_0': np.float64(-1.0)}\n",
            "Episode 2 rewards: {'first_0': np.float64(-1.0), 'second_0': np.float64(-1.0), 'third_0': np.float64(1.0), 'fourth_0': np.float64(-1.0)}\n",
            "Episode 3 rewards: {'first_0': np.float64(-1.0), 'second_0': np.float64(1.0), 'third_0': np.float64(-1.0), 'fourth_0': np.float64(-1.0)}\n",
            "Episode 4 rewards: {'first_0': np.float64(-1.0), 'second_0': np.float64(-1.0), 'third_0': np.float64(-1.0), 'fourth_0': np.float64(1.0)}\n",
            "Episode 5 rewards: {'first_0': np.float64(-1.0), 'second_0': np.float64(-1.0), 'third_0': np.float64(-1.0), 'fourth_0': np.float64(1.0)}\n",
            "Episode 6 rewards: {'first_0': np.float64(-1.0), 'second_0': np.float64(-1.0), 'third_0': np.float64(-1.0), 'fourth_0': np.float64(1.0)}\n",
            "Episode 7 rewards: {'first_0': np.float64(-1.0), 'second_0': np.float64(-1.0), 'third_0': np.float64(1.0), 'fourth_0': np.float64(-1.0)}\n",
            "Episode 8 rewards: {'first_0': np.float64(-1.0), 'second_0': np.float64(-1.0), 'third_0': np.float64(-1.0), 'fourth_0': np.float64(1.0)}\n",
            "Episode 9 rewards: {'first_0': np.float64(-1.0), 'second_0': np.float64(-1.0), 'third_0': np.float64(-1.0), 'fourth_0': np.float64(1.0)}\n",
            "Episode 10 rewards: {'first_0': np.float64(-1.0), 'second_0': np.float64(1.0), 'third_0': np.float64(-1.0), 'fourth_0': np.float64(-1.0)}\n",
            "Episode 11 rewards: {'first_0': np.float64(1.0), 'second_0': np.float64(-1.0), 'third_0': np.float64(-1.0), 'fourth_0': np.float64(-1.0)}\n",
            "Episode 12 rewards: {'first_0': np.float64(-1.0), 'second_0': np.float64(-1.0), 'third_0': np.float64(1.0), 'fourth_0': np.float64(-1.0)}\n",
            "Episode 13 rewards: {'first_0': np.float64(-1.0), 'second_0': np.float64(1.0), 'third_0': np.float64(-1.0), 'fourth_0': np.float64(-1.0)}\n",
            "Episode 14 rewards: {'first_0': np.float64(-1.0), 'second_0': np.float64(-1.0), 'third_0': np.float64(1.0), 'fourth_0': np.float64(-1.0)}\n",
            "Episode 15 rewards: {'first_0': np.float64(-1.0), 'second_0': np.float64(1.0), 'third_0': np.float64(-1.0), 'fourth_0': np.float64(-1.0)}\n",
            "Episode 16 rewards: {'first_0': np.float64(-1.0), 'second_0': np.float64(-1.0), 'third_0': np.float64(-1.0), 'fourth_0': np.float64(1.0)}\n",
            "Episode 17 rewards: {'first_0': np.float64(-1.0), 'second_0': np.float64(-1.0), 'third_0': np.float64(-1.0), 'fourth_0': np.float64(1.0)}\n",
            "Episode 18 rewards: {'first_0': np.float64(-1.0), 'second_0': np.float64(-1.0), 'third_0': np.float64(1.0), 'fourth_0': np.float64(-1.0)}\n",
            "Episode 19 rewards: {'first_0': np.float64(-1.0), 'second_0': np.float64(-1.0), 'third_0': np.float64(1.0), 'fourth_0': np.float64(-1.0)}\n",
            "Episode 20 rewards: {'first_0': np.float64(-1.0), 'second_0': np.float64(-1.0), 'third_0': np.float64(-1.0), 'fourth_0': np.float64(1.0)}\n",
            "\n",
            "Gemiddelde reward per agent over 20 episodes:\n",
            "  first_0: -0.90\n",
            "  second_0: -0.50\n",
            "  third_0: -0.40\n",
            "  fourth_0: -0.20\n",
            "Aantal keer gewonnen (laatste overlevende) per agent: {'first_0': 1, 'second_0': 5, 'third_0': 6, 'fourth_0': 8}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Hier kijken hoe ik het in een gifje kan krijgen te zien"
      ],
      "metadata": {
        "id": "XKx3SF_Vr7cV"
      },
      "id": "XKx3SF_Vr7cV",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "248de22d",
      "metadata": {
        "id": "248de22d"
      },
      "source": [
        "<a name='1.1'></a>\n",
        "<h3>&sect;6.3: Visualisatie van resultaten</h3>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f653d2a0",
      "metadata": {
        "id": "f653d2a0"
      },
      "source": [
        "c.\tVisualiseer de resultaten met grafieken en andere tools. Denk bijvoorbeeld aan reward-curves en stabiliteit van training."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "935cd0bd",
      "metadata": {
        "id": "935cd0bd"
      },
      "source": [
        "\n",
        "---\n",
        "<div style=\"background-color:LightBlue; text-align:center; vertical-align:middle; padding:50px 0; margin-top:5px; margin-bottom:5px\">\n",
        "    <h2 id=\"eda-title\" style=\"color:black; font-family: Verdana, sans-serif; font-size: 25px;\"><strong>H7: Rapportage en Reflectie</strong></h2>\n",
        "</div>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "067d398a",
      "metadata": {
        "id": "067d398a"
      },
      "source": [
        "<a name='1.1'></a>\n",
        "<h3>&sect;7.1: Methodologie en aanpak</h3>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c40607f0",
      "metadata": {
        "id": "c40607f0"
      },
      "source": [
        "<a name='1.1'></a>\n",
        "<h3>&sect;7.2: Samenvatting van resultaten</h3>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4bc393ce",
      "metadata": {
        "id": "4bc393ce"
      },
      "source": [
        "<a name='1.1'></a>\n",
        "<h3>&sect;7.3: Reflectie op model, prestaties en uitbreidingsmogelijkheden</h3>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5a36e0de",
      "metadata": {
        "id": "5a36e0de"
      },
      "source": [
        "a.\tSchrijf een rapport waarin je je probleemstelling, aanpak, resultaten en conclusies presenteert. Reflecteer op mogelijke uitbreidingen."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "43cf89fe",
      "metadata": {
        "id": "43cf89fe"
      },
      "source": [
        "\n",
        "---\n",
        "<div style=\"background-color:LightBlue; text-align:center; vertical-align:middle; padding:50px 0; margin-top:5px; margin-bottom:5px\">\n",
        "    <h2 id=\"eda-title\" style=\"color:black; font-family: Verdana, sans-serif; font-size: 25px;\"><strong>H8: Literatuurlijst</strong></h2>\n",
        "</div>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Scharwächter, V. (2024, 15 juli). *Probleemanalyse maken voor je scriptie | Betekenis & Voorbeeld.* Scribbr. https://www.scribbr.nl/starten-met-je-scriptie/probleemanalyse/\n",
        "- PPO — Stable Baselines3 2.7.0a0 documentation. (z.d.). https://stable-baselines3.readthedocs.io/en/master/modules/ppo.html"
      ],
      "metadata": {
        "id": "OxRcnCwjrS_6"
      },
      "id": "OxRcnCwjrS_6"
    },
    {
      "cell_type": "markdown",
      "id": "8c2bc62c",
      "metadata": {
        "id": "8c2bc62c"
      },
      "source": [
        "\n",
        "---\n",
        "<div style=\"background-color:LightBlue; text-align:center; vertical-align:middle; padding:50px 0; margin-top:5px; margin-bottom:5px\">\n",
        "    <h2 id=\"eda-title\" style=\"color:black; font-family: Verdana, sans-serif; font-size: 25px;\"><strong>H9: Beoordelingscriteria</strong></h2>\n",
        "</div>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "31b69975",
      "metadata": {
        "id": "31b69975"
      },
      "source": [
        "Je werk wordt beoordeeld op de volgende aspecten:\n",
        "1.\t**Keuze van algoritme en trainingsstrategie**: Is het gekozen algoritme geschikt voor de omgeving? Is de trainingsmethode van de agent relevant voor deze setting? Wordt er rekening gehouden met de aanwezigheid van meerdere agenten?\n",
        "2.\t**Technische diepgang**: Worden neural network-componenten (indien van toepassing) correct toegepast? Is er aandacht voor alle cruciale onderdelen van de DRL-pijplijn (zoals experience replay en policy updates)?\n",
        "3.\t**Implementatie en testen**: Is het multi-agent Reinforcement Learning-algoritme correct geïmplementeerd, met goed gestructureerde en werkende code? Is het getest in een multi-agentomgeving?\n",
        "4.\t**Rapportage**: Zijn de methodologie en keuzes goed onderbouwd met wetenschappelijke literatuur? Is het rapport helder en gestructureerd?\n",
        "5.\t**Reproduceerbaarheid**: Is de code duidelijk, goed gedocumenteerd en eenvoudig te reproduceren?\n",
        "6.\t**Bonuspunten**: Aan het einde van het project neemt je agent het in een toernooi op tegen je klasgenoten. (De details hierover volgen later.) Het winnende team van het toernooi krijgt 5 bonuspunten bovenop het aantal behaalde punten met de opdracht.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d06c3ecc",
      "metadata": {
        "id": "d06c3ecc"
      },
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.0"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}